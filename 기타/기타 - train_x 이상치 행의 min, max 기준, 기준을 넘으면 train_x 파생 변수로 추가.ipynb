{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88c9f79",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784827d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from lightgbm import LGBMRegressor\n",
    "from hyperopt import fmin, hp, tpe, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ab72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69084ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split_X_y(df):    \n",
    "    \"\"\"\n",
    "    @Description: split data into features and labels\n",
    "    @Param: df, pandas dataframe with columns starting with X for features and Y for labels\n",
    "    @Return: features and labels in pandas dataframes\n",
    "    \"\"\"\n",
    "    xs = df.filter(regex='X') # Input : X Feature\n",
    "    ys = df.filter(regex='Y') # Output : Y Feature\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "800347f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_variance(df):\n",
    "    \"\"\"\n",
    "    @Description: check for zero_variance\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Return: names of the columns with zero variance\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        if df[col].var() == 0:\n",
    "            result.append(col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3405de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_correlation(df, n=10):\n",
    "    \"\"\"\n",
    "    @Description: print out top correlated features\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Param2: n, number of lines to print \n",
    "    @Return: pandas series\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    for idx1 in range(0, df.shape[1]):\n",
    "        for idx2 in range(0, idx1+1):\n",
    "            pairs.add((df.columns[idx1], df.columns[idx2]))\n",
    "    corr = df.corr().abs().unstack()\n",
    "    corr = corr.drop(labels=pairs).sort_values(ascending=False)\n",
    "    return corr[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8979dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lg_nrmse(gt, preds):\n",
    "    \"\"\"\n",
    "    @Description: Metric used in this project\n",
    "    @Params1: gt, pandas dataframe\n",
    "    @Param2: preds, pandas dataframe\n",
    "    @Return: nrmse score\n",
    "    \"\"\"\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    preds = pd.DataFrame(preds)\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14):\n",
    "        rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt.iloc[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:15])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70733c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('data/train.csv')\n",
    "\n",
    "test_x = pd.read_csv('data/test.csv')\n",
    "train_x, train_y = dataset_split_X_y(train_x)\n",
    "\n",
    "\n",
    "y_feature_spec_info = pd.read_csv('data/meta/y_feature_spec_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a5961c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_01</th>\n",
       "      <th>Y_02</th>\n",
       "      <th>Y_03</th>\n",
       "      <th>Y_04</th>\n",
       "      <th>Y_05</th>\n",
       "      <th>Y_06</th>\n",
       "      <th>Y_07</th>\n",
       "      <th>Y_08</th>\n",
       "      <th>Y_09</th>\n",
       "      <th>Y_10</th>\n",
       "      <th>Y_11</th>\n",
       "      <th>Y_12</th>\n",
       "      <th>Y_13</th>\n",
       "      <th>Y_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.056</td>\n",
       "      <td>1.456</td>\n",
       "      <td>1.680</td>\n",
       "      <td>10.502</td>\n",
       "      <td>29.632</td>\n",
       "      <td>16.083</td>\n",
       "      <td>4.276</td>\n",
       "      <td>-25.381</td>\n",
       "      <td>-25.529</td>\n",
       "      <td>-22.769</td>\n",
       "      <td>23.792</td>\n",
       "      <td>-25.470</td>\n",
       "      <td>-25.409</td>\n",
       "      <td>-25.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.446</td>\n",
       "      <td>1.184</td>\n",
       "      <td>1.268</td>\n",
       "      <td>18.507</td>\n",
       "      <td>33.179</td>\n",
       "      <td>16.736</td>\n",
       "      <td>3.229</td>\n",
       "      <td>-26.619</td>\n",
       "      <td>-26.523</td>\n",
       "      <td>-22.574</td>\n",
       "      <td>24.691</td>\n",
       "      <td>-26.253</td>\n",
       "      <td>-26.497</td>\n",
       "      <td>-26.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.251</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.782</td>\n",
       "      <td>14.082</td>\n",
       "      <td>31.801</td>\n",
       "      <td>17.080</td>\n",
       "      <td>2.839</td>\n",
       "      <td>-26.238</td>\n",
       "      <td>-26.216</td>\n",
       "      <td>-22.169</td>\n",
       "      <td>24.649</td>\n",
       "      <td>-26.285</td>\n",
       "      <td>-26.215</td>\n",
       "      <td>-26.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.464</td>\n",
       "      <td>1.079</td>\n",
       "      <td>1.052</td>\n",
       "      <td>16.975</td>\n",
       "      <td>34.503</td>\n",
       "      <td>17.143</td>\n",
       "      <td>3.144</td>\n",
       "      <td>-25.426</td>\n",
       "      <td>-25.079</td>\n",
       "      <td>-21.765</td>\n",
       "      <td>24.913</td>\n",
       "      <td>-25.254</td>\n",
       "      <td>-25.021</td>\n",
       "      <td>-25.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.689</td>\n",
       "      <td>15.047</td>\n",
       "      <td>32.602</td>\n",
       "      <td>17.569</td>\n",
       "      <td>3.138</td>\n",
       "      <td>-25.376</td>\n",
       "      <td>-25.242</td>\n",
       "      <td>-21.072</td>\n",
       "      <td>25.299</td>\n",
       "      <td>-25.072</td>\n",
       "      <td>-25.195</td>\n",
       "      <td>-24.974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y_01   Y_02   Y_03    Y_04    Y_05    Y_06   Y_07    Y_08    Y_09    Y_10  \\\n",
       "0  2.056  1.456  1.680  10.502  29.632  16.083  4.276 -25.381 -25.529 -22.769   \n",
       "1  1.446  1.184  1.268  18.507  33.179  16.736  3.229 -26.619 -26.523 -22.574   \n",
       "2  1.251  0.665  0.782  14.082  31.801  17.080  2.839 -26.238 -26.216 -22.169   \n",
       "3  1.464  1.079  1.052  16.975  34.503  17.143  3.144 -25.426 -25.079 -21.765   \n",
       "4  0.983  0.646  0.689  15.047  32.602  17.569  3.138 -25.376 -25.242 -21.072   \n",
       "\n",
       "     Y_11    Y_12    Y_13    Y_14  \n",
       "0  23.792 -25.470 -25.409 -25.304  \n",
       "1  24.691 -26.253 -26.497 -26.438  \n",
       "2  24.649 -26.285 -26.215 -26.370  \n",
       "3  24.913 -25.254 -25.021 -25.345  \n",
       "4  25.299 -25.072 -25.195 -24.974  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "523c25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec_df = y_feature_spec_info\n",
    "df_indicator_y = pd.DataFrame()\n",
    "for idx in range(len(train_spec_df.Feature)):\n",
    "    if train_spec_df.Feature[idx] in train_y.columns:\n",
    "        y_series = ~train_y[train_spec_df.Feature[idx]].between(train_spec_df.iloc[idx, :].Min, train_spec_df.iloc[idx, :].Max)\n",
    "        df_indicator_y = pd.concat([df_indicator_y, y_series.astype(int)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68f1dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = df_indicator_y[df_indicator_y==0]\n",
    "spec_data = df_indicator_y[df_indicator_y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "318fb2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y_01    1476\n",
       "Y_02     558\n",
       "Y_03     464\n",
       "Y_04     500\n",
       "Y_05      91\n",
       "Y_06      10\n",
       "Y_07    1822\n",
       "Y_08      19\n",
       "Y_09      19\n",
       "Y_10       5\n",
       "Y_11       3\n",
       "Y_12      16\n",
       "Y_13      15\n",
       "Y_14      13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9780153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_spec_y_01 = train_x[spec_data['Y_02'] == 1]\n",
    "train_x_normal_y_01 = train_x[normal_data['Y_02'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14d23642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23       64.425\n",
       "37       74.623\n",
       "177      77.682\n",
       "239      69.524\n",
       "246      67.485\n",
       "          ...  \n",
       "39352    66.465\n",
       "39378    68.504\n",
       "39393    68.504\n",
       "39583    67.485\n",
       "39605    66.465\n",
       "Name: X_01, Length: 558, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_spec_y_01['X_01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddc46d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_01\n",
      "min : X_14\n",
      "min : X_15\n",
      "min : X_16\n",
      "min : X_18\n",
      "max : X_51\n",
      "\n",
      "Y_02\n",
      "min : X_49\n",
      "\n",
      "Y_03\n",
      "min : X_49\n",
      "\n",
      "Y_04\n",
      "max : X_37\n",
      "max : X_54\n",
      "\n",
      "Y_05\n",
      "\n",
      "Y_06\n",
      "\n",
      "Y_07\n",
      "min : X_41\n",
      "\n",
      "Y_08\n",
      "\n",
      "Y_09\n",
      "\n",
      "Y_10\n",
      "\n",
      "Y_11\n",
      "\n",
      "Y_12\n",
      "\n",
      "Y_13\n",
      "\n",
      "Y_14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in train_y.columns:\n",
    "    train_x_spec_y_01 = train_x[spec_data[k] == 1]\n",
    "    train_x_normal_y_01 = train_x[normal_data[k] == 0]\n",
    "    print(k)\n",
    "    for i in train_x.columns:\n",
    "        if max(train_x_normal_y_01[i]) < max(train_x_spec_y_01[i]):\n",
    "            print('max :' ,i)\n",
    "        if min(train_x_normal_y_01[i]) > min(train_x_spec_y_01[i]) :\n",
    "            print('min :' ,i)\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1397778d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "      <th>X_16</th>\n",
       "      <th>X_17</th>\n",
       "      <th>X_18</th>\n",
       "      <th>X_19</th>\n",
       "      <th>X_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000366</td>\n",
       "      <td>4.373230</td>\n",
       "      <td>0.143335</td>\n",
       "      <td>13.372203</td>\n",
       "      <td>13.381916</td>\n",
       "      <td>13.463860</td>\n",
       "      <td>13.512590</td>\n",
       "      <td>13.449264</td>\n",
       "      <td>3.240250</td>\n",
       "      <td>3.184512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>0.025332</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.036741</td>\n",
       "      <td>0.023436</td>\n",
       "      <td>0.029094</td>\n",
       "      <td>0.110484</td>\n",
       "      <td>0.105266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.270000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>13.150000</td>\n",
       "      <td>13.230000</td>\n",
       "      <td>13.260000</td>\n",
       "      <td>13.410000</td>\n",
       "      <td>13.260000</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>2.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.360000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>13.350000</td>\n",
       "      <td>13.360000</td>\n",
       "      <td>13.440000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>13.430000</td>\n",
       "      <td>3.160000</td>\n",
       "      <td>3.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.370000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>13.380000</td>\n",
       "      <td>13.470000</td>\n",
       "      <td>13.510000</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>3.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.390000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>13.390000</td>\n",
       "      <td>13.410000</td>\n",
       "      <td>13.490000</td>\n",
       "      <td>13.530000</td>\n",
       "      <td>13.470000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>3.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>13.490000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>13.610000</td>\n",
       "      <td>13.610000</td>\n",
       "      <td>13.570000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.670000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_11          X_12          X_13          X_14          X_15  \\\n",
       "count  39594.000000  39594.000000  39594.000000  39594.000000  39594.000000   \n",
       "mean       0.000366      4.373230      0.143335     13.372203     13.381916   \n",
       "std        0.014148      0.021808      0.025332      0.029867      0.029468   \n",
       "min        0.000000      4.270000      0.050000     13.150000     13.230000   \n",
       "25%        0.000000      4.360000      0.130000     13.350000     13.360000   \n",
       "50%        0.000000      4.370000      0.140000     13.370000     13.380000   \n",
       "75%        0.000000      4.390000      0.160000     13.390000     13.410000   \n",
       "max        0.700000      4.490000      0.280000     13.490000     13.500000   \n",
       "\n",
       "               X_16          X_17          X_18          X_19          X_20  \n",
       "count  39594.000000  39594.000000  39594.000000  39594.000000  39594.000000  \n",
       "mean      13.463860     13.512590     13.449264      3.240250      3.184512  \n",
       "std        0.036741      0.023436      0.029094      0.110484      0.105266  \n",
       "min       13.260000     13.410000     13.260000      2.860000      2.830000  \n",
       "25%       13.440000     13.500000     13.430000      3.160000      3.100000  \n",
       "50%       13.470000     13.510000     13.450000      3.220000      3.180000  \n",
       "75%       13.490000     13.530000     13.470000      3.310000      3.270000  \n",
       "max       13.610000     13.610000     13.570000      3.750000      3.670000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_normal_y_01.iloc[:,10:20].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bee2f61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "      <th>X_16</th>\n",
       "      <th>X_17</th>\n",
       "      <th>X_18</th>\n",
       "      <th>X_19</th>\n",
       "      <th>X_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001075</td>\n",
       "      <td>4.372688</td>\n",
       "      <td>0.145860</td>\n",
       "      <td>13.370358</td>\n",
       "      <td>13.382348</td>\n",
       "      <td>13.461649</td>\n",
       "      <td>13.513799</td>\n",
       "      <td>13.449713</td>\n",
       "      <td>3.268602</td>\n",
       "      <td>3.215072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.020486</td>\n",
       "      <td>0.025122</td>\n",
       "      <td>0.029096</td>\n",
       "      <td>0.029234</td>\n",
       "      <td>0.038131</td>\n",
       "      <td>0.023544</td>\n",
       "      <td>0.028219</td>\n",
       "      <td>0.131336</td>\n",
       "      <td>0.110240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.310000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>13.270000</td>\n",
       "      <td>13.260000</td>\n",
       "      <td>13.350000</td>\n",
       "      <td>13.430000</td>\n",
       "      <td>13.350000</td>\n",
       "      <td>2.910000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.360000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>13.350000</td>\n",
       "      <td>13.360000</td>\n",
       "      <td>13.440000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>13.430000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>3.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.370000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>13.380000</td>\n",
       "      <td>13.460000</td>\n",
       "      <td>13.520000</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>13.390000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>13.490000</td>\n",
       "      <td>13.530000</td>\n",
       "      <td>13.460000</td>\n",
       "      <td>3.380000</td>\n",
       "      <td>3.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>4.440000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>13.460000</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>13.560000</td>\n",
       "      <td>13.570000</td>\n",
       "      <td>13.530000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.450000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X_11        X_12        X_13        X_14        X_15        X_16  \\\n",
       "count  558.000000  558.000000  558.000000  558.000000  558.000000  558.000000   \n",
       "mean     0.001075    4.372688    0.145860   13.370358   13.382348   13.461649   \n",
       "std      0.025400    0.020486    0.025122    0.029096    0.029234    0.038131   \n",
       "min      0.000000    4.310000    0.070000   13.270000   13.260000   13.350000   \n",
       "25%      0.000000    4.360000    0.130000   13.350000   13.360000   13.440000   \n",
       "50%      0.000000    4.370000    0.140000   13.370000   13.380000   13.460000   \n",
       "75%      0.000000    4.380000    0.160000   13.390000   13.400000   13.490000   \n",
       "max      0.600000    4.440000    0.250000   13.460000   13.450000   13.560000   \n",
       "\n",
       "             X_17        X_18        X_19        X_20  \n",
       "count  558.000000  558.000000  558.000000  558.000000  \n",
       "mean    13.513799   13.449713    3.268602    3.215072  \n",
       "std      0.023544    0.028219    0.131336    0.110240  \n",
       "min     13.430000   13.350000    2.910000    2.910000  \n",
       "25%     13.500000   13.430000    3.170000    3.120000  \n",
       "50%     13.520000   13.450000    3.250000    3.230000  \n",
       "75%     13.530000   13.460000    3.380000    3.310000  \n",
       "max     13.570000   13.530000    3.600000    3.450000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_spec_y_01.iloc[:,10:20].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17ce3bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_21</th>\n",
       "      <th>X_22</th>\n",
       "      <th>X_23</th>\n",
       "      <th>X_24</th>\n",
       "      <th>X_25</th>\n",
       "      <th>X_26</th>\n",
       "      <th>X_27</th>\n",
       "      <th>X_28</th>\n",
       "      <th>X_29</th>\n",
       "      <th>X_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.0</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.173867</td>\n",
       "      <td>3.232196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.115659</td>\n",
       "      <td>2.093904</td>\n",
       "      <td>2.090331</td>\n",
       "      <td>2.098221</td>\n",
       "      <td>2.118552</td>\n",
       "      <td>2.173698</td>\n",
       "      <td>1.379079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.106594</td>\n",
       "      <td>0.108809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032451</td>\n",
       "      <td>0.033155</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.038003</td>\n",
       "      <td>0.042768</td>\n",
       "      <td>0.046691</td>\n",
       "      <td>0.029953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.830000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.090000</td>\n",
       "      <td>3.140000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>1.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.160000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>1.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.790000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>2.110000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_21          X_22     X_23          X_24          X_25  \\\n",
       "count  39049.000000  39049.000000  39049.0  39049.000000  39049.000000   \n",
       "mean       3.173867      3.232196      1.0      2.115659      2.093904   \n",
       "std        0.106594      0.108809      0.0      0.032451      0.033155   \n",
       "min        2.830000      2.850000      1.0      1.830000      1.960000   \n",
       "25%        3.090000      3.140000      1.0      2.090000      2.070000   \n",
       "50%        3.160000      3.230000      1.0      2.120000      2.090000   \n",
       "75%        3.250000      3.320000      1.0      2.140000      2.120000   \n",
       "max        3.680000      3.790000      1.0      2.350000      2.350000   \n",
       "\n",
       "               X_26          X_27          X_28          X_29          X_30  \n",
       "count  39049.000000  39049.000000  39049.000000  39049.000000  39049.000000  \n",
       "mean       2.090331      2.098221      2.118552      2.173698      1.379079  \n",
       "std        0.038500      0.038003      0.042768      0.046691      0.029953  \n",
       "min        1.980000      1.990000      1.930000      2.020000      0.570000  \n",
       "25%        2.060000      2.070000      2.090000      2.140000      1.370000  \n",
       "50%        2.090000      2.090000      2.120000      2.170000      1.370000  \n",
       "75%        2.120000      2.120000      2.140000      2.200000      1.380000  \n",
       "max        2.350000      2.350000      2.350000      2.360000      2.110000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_normal_y_01.iloc[:,20:30].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3e2a016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_21</th>\n",
       "      <th>X_22</th>\n",
       "      <th>X_23</th>\n",
       "      <th>X_24</th>\n",
       "      <th>X_25</th>\n",
       "      <th>X_26</th>\n",
       "      <th>X_27</th>\n",
       "      <th>X_28</th>\n",
       "      <th>X_29</th>\n",
       "      <th>X_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.0</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.202491</td>\n",
       "      <td>3.266039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.116720</td>\n",
       "      <td>2.093244</td>\n",
       "      <td>2.093602</td>\n",
       "      <td>2.100197</td>\n",
       "      <td>2.121541</td>\n",
       "      <td>2.175753</td>\n",
       "      <td>1.373065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.121381</td>\n",
       "      <td>0.115769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031665</td>\n",
       "      <td>0.032717</td>\n",
       "      <td>0.039304</td>\n",
       "      <td>0.041560</td>\n",
       "      <td>0.043679</td>\n",
       "      <td>0.046513</td>\n",
       "      <td>0.053234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.880000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.100000</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>1.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.185000</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>1.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.360000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.550000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.190000</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.340000</td>\n",
       "      <td>1.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X_21        X_22   X_23        X_24        X_25        X_26  \\\n",
       "count  558.000000  558.000000  558.0  558.000000  558.000000  558.000000   \n",
       "mean     3.202491    3.266039    1.0    2.116720    2.093244    2.093602   \n",
       "std      0.121381    0.115769    0.0    0.031665    0.032717    0.039304   \n",
       "min      2.880000    3.000000    1.0    2.030000    2.010000    2.010000   \n",
       "25%      3.100000    3.180000    1.0    2.090000    2.070000    2.070000   \n",
       "50%      3.185000    3.280000    1.0    2.120000    2.090000    2.090000   \n",
       "75%      3.300000    3.360000    1.0    2.140000    2.120000    2.120000   \n",
       "max      3.550000    3.600000    1.0    2.190000    2.210000    2.320000   \n",
       "\n",
       "             X_27        X_28        X_29        X_30  \n",
       "count  558.000000  558.000000  558.000000  558.000000  \n",
       "mean     2.100197    2.121541    2.175753    1.373065  \n",
       "std      0.041560    0.043679    0.046513    0.053234  \n",
       "min      2.010000    2.040000    2.090000    0.570000  \n",
       "25%      2.070000    2.090000    2.140000    1.370000  \n",
       "50%      2.100000    2.120000    2.170000    1.370000  \n",
       "75%      2.120000    2.140000    2.200000    1.380000  \n",
       "max      2.350000    2.350000    2.340000    1.510000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_spec_y_01.iloc[:,20:30].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5fdacd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_31</th>\n",
       "      <th>X_32</th>\n",
       "      <th>X_33</th>\n",
       "      <th>X_34</th>\n",
       "      <th>X_35</th>\n",
       "      <th>X_36</th>\n",
       "      <th>X_37</th>\n",
       "      <th>X_38</th>\n",
       "      <th>X_39</th>\n",
       "      <th>X_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.571179</td>\n",
       "      <td>1.362961</td>\n",
       "      <td>1.595846</td>\n",
       "      <td>12.950250</td>\n",
       "      <td>12.920309</td>\n",
       "      <td>12.941730</td>\n",
       "      <td>12.919113</td>\n",
       "      <td>-15.904671</td>\n",
       "      <td>-15.890222</td>\n",
       "      <td>-16.572931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.074738</td>\n",
       "      <td>0.030060</td>\n",
       "      <td>0.107967</td>\n",
       "      <td>0.044023</td>\n",
       "      <td>0.052232</td>\n",
       "      <td>0.047839</td>\n",
       "      <td>0.052295</td>\n",
       "      <td>0.594186</td>\n",
       "      <td>0.747688</td>\n",
       "      <td>0.343985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>12.840000</td>\n",
       "      <td>12.810000</td>\n",
       "      <td>12.840000</td>\n",
       "      <td>12.810000</td>\n",
       "      <td>-17.090000</td>\n",
       "      <td>-17.090000</td>\n",
       "      <td>-17.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.530000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>12.920000</td>\n",
       "      <td>12.870000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>12.870000</td>\n",
       "      <td>-16.160000</td>\n",
       "      <td>-16.160000</td>\n",
       "      <td>-16.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.550000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>12.960000</td>\n",
       "      <td>12.910000</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>12.910000</td>\n",
       "      <td>-15.990000</td>\n",
       "      <td>-15.990000</td>\n",
       "      <td>-16.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>12.990000</td>\n",
       "      <td>12.970000</td>\n",
       "      <td>12.980000</td>\n",
       "      <td>12.970000</td>\n",
       "      <td>-15.750000</td>\n",
       "      <td>-15.750000</td>\n",
       "      <td>-16.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.210000</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>7.810000</td>\n",
       "      <td>13.080000</td>\n",
       "      <td>13.090000</td>\n",
       "      <td>13.090000</td>\n",
       "      <td>13.080000</td>\n",
       "      <td>32.230000</td>\n",
       "      <td>-2.650000</td>\n",
       "      <td>-14.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_31          X_32          X_33          X_34          X_35  \\\n",
       "count  39049.000000  39049.000000  39049.000000  39049.000000  39049.000000   \n",
       "mean       1.571179      1.362961      1.595846     12.950250     12.920309   \n",
       "std        0.074738      0.030060      0.107967      0.044023      0.052232   \n",
       "min        0.600000      0.570000      0.610000     12.840000     12.810000   \n",
       "25%        1.530000      1.350000      1.550000     12.920000     12.870000   \n",
       "50%        1.550000      1.360000      1.570000     12.960000     12.910000   \n",
       "75%        1.600000      1.370000      1.610000     12.990000     12.970000   \n",
       "max        7.210000      2.450000      7.810000     13.080000     13.090000   \n",
       "\n",
       "               X_36          X_37          X_38          X_39          X_40  \n",
       "count  39049.000000  39049.000000  39049.000000  39049.000000  39049.000000  \n",
       "mean      12.941730     12.919113    -15.904671    -15.890222    -16.572931  \n",
       "std        0.047839      0.052295      0.594186      0.747688      0.343985  \n",
       "min       12.840000     12.810000    -17.090000    -17.090000    -17.720000  \n",
       "25%       12.900000     12.870000    -16.160000    -16.160000    -16.810000  \n",
       "50%       12.950000     12.910000    -15.990000    -15.990000    -16.640000  \n",
       "75%       12.980000     12.970000    -15.750000    -15.750000    -16.400000  \n",
       "max       13.090000     13.080000     32.230000     -2.650000    -14.800000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_normal_y_01.iloc[:,30:40].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a08e8daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_31</th>\n",
       "      <th>X_32</th>\n",
       "      <th>X_33</th>\n",
       "      <th>X_34</th>\n",
       "      <th>X_35</th>\n",
       "      <th>X_36</th>\n",
       "      <th>X_37</th>\n",
       "      <th>X_38</th>\n",
       "      <th>X_39</th>\n",
       "      <th>X_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.568495</td>\n",
       "      <td>1.360663</td>\n",
       "      <td>1.587151</td>\n",
       "      <td>12.951685</td>\n",
       "      <td>12.922724</td>\n",
       "      <td>12.941631</td>\n",
       "      <td>12.920914</td>\n",
       "      <td>-15.838423</td>\n",
       "      <td>-15.844373</td>\n",
       "      <td>-16.518315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.057227</td>\n",
       "      <td>0.020243</td>\n",
       "      <td>0.112019</td>\n",
       "      <td>0.044521</td>\n",
       "      <td>0.052634</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.673639</td>\n",
       "      <td>0.670276</td>\n",
       "      <td>0.374343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>12.830000</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>12.810000</td>\n",
       "      <td>-16.760000</td>\n",
       "      <td>-16.760000</td>\n",
       "      <td>-17.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.530000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>12.920000</td>\n",
       "      <td>12.870000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>12.880000</td>\n",
       "      <td>-16.140000</td>\n",
       "      <td>-16.140000</td>\n",
       "      <td>-16.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.550000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>12.960000</td>\n",
       "      <td>12.925000</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>12.920000</td>\n",
       "      <td>-15.940000</td>\n",
       "      <td>-15.960000</td>\n",
       "      <td>-16.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.590000</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>12.990000</td>\n",
       "      <td>12.970000</td>\n",
       "      <td>12.980000</td>\n",
       "      <td>12.970000</td>\n",
       "      <td>-15.640000</td>\n",
       "      <td>-15.650000</td>\n",
       "      <td>-16.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.880000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>13.040000</td>\n",
       "      <td>13.060000</td>\n",
       "      <td>13.040000</td>\n",
       "      <td>13.030000</td>\n",
       "      <td>-2.650000</td>\n",
       "      <td>-2.650000</td>\n",
       "      <td>-15.340000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X_31        X_32        X_33        X_34        X_35        X_36  \\\n",
       "count  558.000000  558.000000  558.000000  558.000000  558.000000  558.000000   \n",
       "mean     1.568495    1.360663    1.587151   12.951685   12.922724   12.941631   \n",
       "std      0.057227    0.020243    0.112019    0.044521    0.052634    0.047217   \n",
       "min      1.500000    1.330000    0.610000   12.850000   12.830000   12.850000   \n",
       "25%      1.530000    1.350000    1.550000   12.920000   12.870000   12.900000   \n",
       "50%      1.550000    1.360000    1.570000   12.960000   12.925000   12.950000   \n",
       "75%      1.590000    1.370000    1.590000   12.990000   12.970000   12.980000   \n",
       "max      1.880000    1.470000    2.160000   13.040000   13.060000   13.040000   \n",
       "\n",
       "             X_37        X_38        X_39        X_40  \n",
       "count  558.000000  558.000000  558.000000  558.000000  \n",
       "mean    12.920914  -15.838423  -15.844373  -16.518315  \n",
       "std      0.052147    0.673639    0.670276    0.374343  \n",
       "min     12.810000  -16.760000  -16.760000  -17.360000  \n",
       "25%     12.880000  -16.140000  -16.140000  -16.790000  \n",
       "50%     12.920000  -15.940000  -15.960000  -16.605000  \n",
       "75%     12.970000  -15.640000  -15.650000  -16.290000  \n",
       "max     13.030000   -2.650000   -2.650000  -15.340000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_spec_y_01.iloc[:,30:40].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a5b2913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_41</th>\n",
       "      <th>X_42</th>\n",
       "      <th>X_43</th>\n",
       "      <th>X_44</th>\n",
       "      <th>X_45</th>\n",
       "      <th>X_46</th>\n",
       "      <th>X_47</th>\n",
       "      <th>X_48</th>\n",
       "      <th>X_49</th>\n",
       "      <th>X_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.0</td>\n",
       "      <td>39049.0</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.186992</td>\n",
       "      <td>21.059368</td>\n",
       "      <td>21.203696</td>\n",
       "      <td>21.160097</td>\n",
       "      <td>0.154520</td>\n",
       "      <td>1468.276166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16678.583539</td>\n",
       "      <td>130.782024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031099</td>\n",
       "      <td>0.040272</td>\n",
       "      <td>0.047227</td>\n",
       "      <td>0.042166</td>\n",
       "      <td>0.046989</td>\n",
       "      <td>2.120836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8552.008319</td>\n",
       "      <td>5.991171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.730000</td>\n",
       "      <td>20.790000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>20.930000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3382.630000</td>\n",
       "      <td>21.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.170000</td>\n",
       "      <td>21.030000</td>\n",
       "      <td>21.170000</td>\n",
       "      <td>21.130000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13108.630000</td>\n",
       "      <td>126.956647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.190000</td>\n",
       "      <td>21.060000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>21.160000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15278.930000</td>\n",
       "      <td>130.732472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.210000</td>\n",
       "      <td>21.090000</td>\n",
       "      <td>21.240000</td>\n",
       "      <td>21.190000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17564.730000</td>\n",
       "      <td>134.547360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.620000</td>\n",
       "      <td>21.440000</td>\n",
       "      <td>21.410000</td>\n",
       "      <td>21.320000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114563.630000</td>\n",
       "      <td>162.619458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_41          X_42          X_43          X_44          X_45  \\\n",
       "count  39049.000000  39049.000000  39049.000000  39049.000000  39049.000000   \n",
       "mean      21.186992     21.059368     21.203696     21.160097      0.154520   \n",
       "std        0.031099      0.040272      0.047227      0.042166      0.046989   \n",
       "min       20.730000     20.790000     20.800000     20.930000      0.000000   \n",
       "25%       21.170000     21.030000     21.170000     21.130000      0.120000   \n",
       "50%       21.190000     21.060000     21.200000     21.160000      0.150000   \n",
       "75%       21.210000     21.090000     21.240000     21.190000      0.190000   \n",
       "max       21.620000     21.440000     21.410000     21.320000      0.420000   \n",
       "\n",
       "               X_46     X_47     X_48           X_49          X_50  \n",
       "count  39049.000000  39049.0  39049.0   39049.000000  39049.000000  \n",
       "mean    1468.276166      1.0      1.0   16678.583539    130.782024  \n",
       "std        2.120836      0.0      0.0    8552.008319      5.991171  \n",
       "min     1457.000000      1.0      1.0    3382.630000     21.800000  \n",
       "25%     1469.000000      1.0      1.0   13108.630000    126.956647  \n",
       "50%     1469.000000      1.0      1.0   15278.930000    130.732472  \n",
       "75%     1469.000000      1.0      1.0   17564.730000    134.547360  \n",
       "max     1469.000000      1.0      1.0  114563.630000    162.619458  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_normal_y_01.iloc[:,40:50].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "54ba2cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_41</th>\n",
       "      <th>X_42</th>\n",
       "      <th>X_43</th>\n",
       "      <th>X_44</th>\n",
       "      <th>X_45</th>\n",
       "      <th>X_46</th>\n",
       "      <th>X_47</th>\n",
       "      <th>X_48</th>\n",
       "      <th>X_49</th>\n",
       "      <th>X_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.186953</td>\n",
       "      <td>21.056971</td>\n",
       "      <td>21.204337</td>\n",
       "      <td>21.160771</td>\n",
       "      <td>0.157849</td>\n",
       "      <td>1468.215054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16560.053513</td>\n",
       "      <td>130.252055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.033132</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.046088</td>\n",
       "      <td>0.042851</td>\n",
       "      <td>0.045367</td>\n",
       "      <td>2.169725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10618.710723</td>\n",
       "      <td>5.878046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.080000</td>\n",
       "      <td>20.890000</td>\n",
       "      <td>21.040000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3341.830000</td>\n",
       "      <td>113.547627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.170000</td>\n",
       "      <td>21.030000</td>\n",
       "      <td>21.170000</td>\n",
       "      <td>21.130000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12175.205000</td>\n",
       "      <td>126.111388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.190000</td>\n",
       "      <td>21.060000</td>\n",
       "      <td>21.210000</td>\n",
       "      <td>21.160000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14783.880000</td>\n",
       "      <td>130.313973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.210000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>21.230000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17264.080000</td>\n",
       "      <td>133.887299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.510000</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>21.370000</td>\n",
       "      <td>21.240000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114211.130000</td>\n",
       "      <td>150.277661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X_41        X_42        X_43        X_44        X_45  \\\n",
       "count  558.000000  558.000000  558.000000  558.000000  558.000000   \n",
       "mean    21.186953   21.056971   21.204337   21.160771    0.157849   \n",
       "std      0.033132    0.041350    0.046088    0.042851    0.045367   \n",
       "min     21.080000   20.890000   21.040000   21.000000    0.040000   \n",
       "25%     21.170000   21.030000   21.170000   21.130000    0.120000   \n",
       "50%     21.190000   21.060000   21.210000   21.160000    0.160000   \n",
       "75%     21.210000   21.080000   21.230000   21.200000    0.190000   \n",
       "max     21.510000   21.250000   21.370000   21.240000    0.290000   \n",
       "\n",
       "              X_46   X_47   X_48           X_49        X_50  \n",
       "count   558.000000  558.0  558.0     558.000000  558.000000  \n",
       "mean   1468.215054    1.0    1.0   16560.053513  130.252055  \n",
       "std       2.169725    0.0    0.0   10618.710723    5.878046  \n",
       "min    1457.000000    1.0    1.0    3341.830000  113.547627  \n",
       "25%    1469.000000    1.0    1.0   12175.205000  126.111388  \n",
       "50%    1469.000000    1.0    1.0   14783.880000  130.313973  \n",
       "75%    1469.000000    1.0    1.0   17264.080000  133.887299  \n",
       "max    1469.000000    1.0    1.0  114211.130000  150.277661  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_spec_y_01.iloc[:,40:50].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "855e670b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_01</th>\n",
       "      <th>X_02</th>\n",
       "      <th>X_03</th>\n",
       "      <th>X_04</th>\n",
       "      <th>X_05</th>\n",
       "      <th>X_06</th>\n",
       "      <th>X_07</th>\n",
       "      <th>X_08</th>\n",
       "      <th>X_09</th>\n",
       "      <th>X_10</th>\n",
       "      <th>...</th>\n",
       "      <th>X_47</th>\n",
       "      <th>X_48</th>\n",
       "      <th>X_49</th>\n",
       "      <th>X_50</th>\n",
       "      <th>X_51</th>\n",
       "      <th>X_52</th>\n",
       "      <th>X_53</th>\n",
       "      <th>X_54</th>\n",
       "      <th>X_55</th>\n",
       "      <th>X_56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.0</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39049.0</td>\n",
       "      <td>39049.0</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>68.411610</td>\n",
       "      <td>103.320167</td>\n",
       "      <td>68.816570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.337957</td>\n",
       "      <td>70.595443</td>\n",
       "      <td>29.394517</td>\n",
       "      <td>164.448757</td>\n",
       "      <td>225.514783</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16678.583539</td>\n",
       "      <td>130.782024</td>\n",
       "      <td>131.459133</td>\n",
       "      <td>138.587340</td>\n",
       "      <td>127.995251</td>\n",
       "      <td>128.017585</td>\n",
       "      <td>137.886895</td>\n",
       "      <td>128.446802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.658364</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>5.154366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.548553</td>\n",
       "      <td>2.260763</td>\n",
       "      <td>7.258563</td>\n",
       "      <td>220.629270</td>\n",
       "      <td>66.638349</td>\n",
       "      <td>0.085533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8552.008319</td>\n",
       "      <td>5.991171</td>\n",
       "      <td>5.941484</td>\n",
       "      <td>6.474068</td>\n",
       "      <td>5.712359</td>\n",
       "      <td>5.441066</td>\n",
       "      <td>6.558856</td>\n",
       "      <td>5.450783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>56.268000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>56.470000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.774000</td>\n",
       "      <td>61.726000</td>\n",
       "      <td>14.140000</td>\n",
       "      <td>38.460000</td>\n",
       "      <td>37.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3382.630000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>21.910000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>21.330000</td>\n",
       "      <td>21.340000</td>\n",
       "      <td>22.980000</td>\n",
       "      <td>21.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>66.465000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>65.070000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.949000</td>\n",
       "      <td>68.864000</td>\n",
       "      <td>27.890000</td>\n",
       "      <td>105.960000</td>\n",
       "      <td>188.630000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13108.630000</td>\n",
       "      <td>126.956647</td>\n",
       "      <td>127.668461</td>\n",
       "      <td>134.471696</td>\n",
       "      <td>124.379934</td>\n",
       "      <td>124.696049</td>\n",
       "      <td>133.751523</td>\n",
       "      <td>125.140644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68.504000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>67.270000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.006000</td>\n",
       "      <td>69.884000</td>\n",
       "      <td>28.840000</td>\n",
       "      <td>115.040000</td>\n",
       "      <td>234.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15278.930000</td>\n",
       "      <td>130.732472</td>\n",
       "      <td>131.356266</td>\n",
       "      <td>138.524881</td>\n",
       "      <td>128.027021</td>\n",
       "      <td>128.103878</td>\n",
       "      <td>137.901829</td>\n",
       "      <td>128.415753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>69.524000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>71.770000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.144000</td>\n",
       "      <td>71.923000</td>\n",
       "      <td>29.870000</td>\n",
       "      <td>132.630000</td>\n",
       "      <td>263.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17564.730000</td>\n",
       "      <td>134.547360</td>\n",
       "      <td>135.173489</td>\n",
       "      <td>142.704385</td>\n",
       "      <td>131.618765</td>\n",
       "      <td>131.499576</td>\n",
       "      <td>142.075490</td>\n",
       "      <td>131.842556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>84.820000</td>\n",
       "      <td>103.321000</td>\n",
       "      <td>89.170000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.160000</td>\n",
       "      <td>87.219000</td>\n",
       "      <td>163.860000</td>\n",
       "      <td>2387.440000</td>\n",
       "      <td>637.490000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114563.630000</td>\n",
       "      <td>162.619458</td>\n",
       "      <td>194.513195</td>\n",
       "      <td>173.438623</td>\n",
       "      <td>152.406630</td>\n",
       "      <td>175.052891</td>\n",
       "      <td>170.155980</td>\n",
       "      <td>155.277538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_01          X_02          X_03     X_04          X_05  \\\n",
       "count  39049.000000  39049.000000  39049.000000  39049.0  39049.000000   \n",
       "mean      68.411610    103.320167     68.816570      1.0    102.337957   \n",
       "std        2.658364      0.000373      5.154366      0.0      0.548553   \n",
       "min       56.268000    103.320000     56.470000      1.0    101.774000   \n",
       "25%       66.465000    103.320000     65.070000      1.0    101.949000   \n",
       "50%       68.504000    103.320000     67.270000      1.0    102.006000   \n",
       "75%       69.524000    103.320000     71.770000      1.0    103.144000   \n",
       "max       84.820000    103.321000     89.170000      1.0    103.160000   \n",
       "\n",
       "               X_06          X_07          X_08          X_09          X_10  \\\n",
       "count  39049.000000  39049.000000  39049.000000  39049.000000  39049.000000   \n",
       "mean      70.595443     29.394517    164.448757    225.514783      0.002407   \n",
       "std        2.260763      7.258563    220.629270     66.638349      0.085533   \n",
       "min       61.726000     14.140000     38.460000     37.580000      0.000000   \n",
       "25%       68.864000     27.890000    105.960000    188.630000      0.000000   \n",
       "50%       69.884000     28.840000    115.040000    234.580000      0.000000   \n",
       "75%       71.923000     29.870000    132.630000    263.960000      0.000000   \n",
       "max       87.219000    163.860000   2387.440000    637.490000      3.600000   \n",
       "\n",
       "       ...     X_47     X_48           X_49          X_50          X_51  \\\n",
       "count  ...  39049.0  39049.0   39049.000000  39049.000000  39049.000000   \n",
       "mean   ...      1.0      1.0   16678.583539    130.782024    131.459133   \n",
       "std    ...      0.0      0.0    8552.008319      5.991171      5.941484   \n",
       "min    ...      1.0      1.0    3382.630000     21.800000     21.910000   \n",
       "25%    ...      1.0      1.0   13108.630000    126.956647    127.668461   \n",
       "50%    ...      1.0      1.0   15278.930000    130.732472    131.356266   \n",
       "75%    ...      1.0      1.0   17564.730000    134.547360    135.173489   \n",
       "max    ...      1.0      1.0  114563.630000    162.619458    194.513195   \n",
       "\n",
       "               X_52          X_53          X_54          X_55          X_56  \n",
       "count  39049.000000  39049.000000  39049.000000  39049.000000  39049.000000  \n",
       "mean     138.587340    127.995251    128.017585    137.886895    128.446802  \n",
       "std        6.474068      5.712359      5.441066      6.558856      5.450783  \n",
       "min       23.100000     21.330000     21.340000     22.980000     21.410000  \n",
       "25%      134.471696    124.379934    124.696049    133.751523    125.140644  \n",
       "50%      138.524881    128.027021    128.103878    137.901829    128.415753  \n",
       "75%      142.704385    131.618765    131.499576    142.075490    131.842556  \n",
       "max      173.438623    152.406630    175.052891    170.155980    155.277538  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_normal_y_01.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0f8017d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_01</th>\n",
       "      <th>X_02</th>\n",
       "      <th>X_03</th>\n",
       "      <th>X_04</th>\n",
       "      <th>X_05</th>\n",
       "      <th>X_06</th>\n",
       "      <th>X_07</th>\n",
       "      <th>X_08</th>\n",
       "      <th>X_09</th>\n",
       "      <th>X_10</th>\n",
       "      <th>...</th>\n",
       "      <th>X_47</th>\n",
       "      <th>X_48</th>\n",
       "      <th>X_49</th>\n",
       "      <th>X_50</th>\n",
       "      <th>X_51</th>\n",
       "      <th>X_52</th>\n",
       "      <th>X_53</th>\n",
       "      <th>X_54</th>\n",
       "      <th>X_55</th>\n",
       "      <th>X_56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.0</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.00000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>558.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>68.442138</td>\n",
       "      <td>103.320149</td>\n",
       "      <td>69.511039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.284437</td>\n",
       "      <td>70.72097</td>\n",
       "      <td>30.315323</td>\n",
       "      <td>164.488692</td>\n",
       "      <td>217.187832</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16560.053513</td>\n",
       "      <td>130.252055</td>\n",
       "      <td>131.337355</td>\n",
       "      <td>138.605408</td>\n",
       "      <td>127.794313</td>\n",
       "      <td>127.770899</td>\n",
       "      <td>137.731848</td>\n",
       "      <td>128.043417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.485748</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>4.877934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531973</td>\n",
       "      <td>2.19123</td>\n",
       "      <td>11.601906</td>\n",
       "      <td>204.086726</td>\n",
       "      <td>72.760905</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10618.710723</td>\n",
       "      <td>5.878046</td>\n",
       "      <td>5.412467</td>\n",
       "      <td>6.170294</td>\n",
       "      <td>5.770202</td>\n",
       "      <td>4.909347</td>\n",
       "      <td>6.064247</td>\n",
       "      <td>4.953707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>58.307000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>60.270000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.815000</td>\n",
       "      <td>63.76600</td>\n",
       "      <td>24.960000</td>\n",
       "      <td>58.380000</td>\n",
       "      <td>37.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3341.830000</td>\n",
       "      <td>113.547627</td>\n",
       "      <td>108.960072</td>\n",
       "      <td>114.213213</td>\n",
       "      <td>109.122007</td>\n",
       "      <td>113.056164</td>\n",
       "      <td>120.323552</td>\n",
       "      <td>101.781635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>66.465000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>65.770000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.932250</td>\n",
       "      <td>68.86400</td>\n",
       "      <td>28.192500</td>\n",
       "      <td>107.277500</td>\n",
       "      <td>176.275000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12175.205000</td>\n",
       "      <td>126.111388</td>\n",
       "      <td>127.694327</td>\n",
       "      <td>134.810781</td>\n",
       "      <td>123.699215</td>\n",
       "      <td>124.752235</td>\n",
       "      <td>133.336472</td>\n",
       "      <td>124.771286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68.504000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>68.870000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.998000</td>\n",
       "      <td>70.90400</td>\n",
       "      <td>28.885000</td>\n",
       "      <td>115.565000</td>\n",
       "      <td>226.360000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14783.880000</td>\n",
       "      <td>130.313973</td>\n",
       "      <td>131.157730</td>\n",
       "      <td>138.598226</td>\n",
       "      <td>127.528109</td>\n",
       "      <td>127.865219</td>\n",
       "      <td>137.789589</td>\n",
       "      <td>128.311512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>69.524000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>72.645000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.136750</td>\n",
       "      <td>71.92300</td>\n",
       "      <td>29.967500</td>\n",
       "      <td>128.570000</td>\n",
       "      <td>264.917500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17264.080000</td>\n",
       "      <td>133.887299</td>\n",
       "      <td>134.592182</td>\n",
       "      <td>142.458873</td>\n",
       "      <td>131.542738</td>\n",
       "      <td>130.825727</td>\n",
       "      <td>141.862725</td>\n",
       "      <td>131.575552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.682000</td>\n",
       "      <td>103.321000</td>\n",
       "      <td>84.070000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.160000</td>\n",
       "      <td>78.04200</td>\n",
       "      <td>163.860000</td>\n",
       "      <td>2358.070000</td>\n",
       "      <td>619.900000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114211.130000</td>\n",
       "      <td>150.277661</td>\n",
       "      <td>147.817028</td>\n",
       "      <td>158.631830</td>\n",
       "      <td>145.078482</td>\n",
       "      <td>144.995846</td>\n",
       "      <td>155.575505</td>\n",
       "      <td>140.942455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X_01        X_02        X_03   X_04        X_05       X_06  \\\n",
       "count  558.000000  558.000000  558.000000  558.0  558.000000  558.00000   \n",
       "mean    68.442138  103.320149   69.511039    1.0  102.284437   70.72097   \n",
       "std      2.485748    0.000356    4.877934    0.0    0.531973    2.19123   \n",
       "min     58.307000  103.320000   60.270000    1.0  101.815000   63.76600   \n",
       "25%     66.465000  103.320000   65.770000    1.0  101.932250   68.86400   \n",
       "50%     68.504000  103.320000   68.870000    1.0  101.998000   70.90400   \n",
       "75%     69.524000  103.320000   72.645000    1.0  103.136750   71.92300   \n",
       "max     77.682000  103.321000   84.070000    1.0  103.160000   78.04200   \n",
       "\n",
       "             X_07         X_08        X_09        X_10  ...   X_47   X_48  \\\n",
       "count  558.000000   558.000000  558.000000  558.000000  ...  558.0  558.0   \n",
       "mean    30.315323   164.488692  217.187832    0.005376  ...    1.0    1.0   \n",
       "std     11.601906   204.086726   72.760905    0.127000  ...    0.0    0.0   \n",
       "min     24.960000    58.380000   37.580000    0.000000  ...    1.0    1.0   \n",
       "25%     28.192500   107.277500  176.275000    0.000000  ...    1.0    1.0   \n",
       "50%     28.885000   115.565000  226.360000    0.000000  ...    1.0    1.0   \n",
       "75%     29.967500   128.570000  264.917500    0.000000  ...    1.0    1.0   \n",
       "max    163.860000  2358.070000  619.900000    3.000000  ...    1.0    1.0   \n",
       "\n",
       "                X_49        X_50        X_51        X_52        X_53  \\\n",
       "count     558.000000  558.000000  558.000000  558.000000  558.000000   \n",
       "mean    16560.053513  130.252055  131.337355  138.605408  127.794313   \n",
       "std     10618.710723    5.878046    5.412467    6.170294    5.770202   \n",
       "min      3341.830000  113.547627  108.960072  114.213213  109.122007   \n",
       "25%     12175.205000  126.111388  127.694327  134.810781  123.699215   \n",
       "50%     14783.880000  130.313973  131.157730  138.598226  127.528109   \n",
       "75%     17264.080000  133.887299  134.592182  142.458873  131.542738   \n",
       "max    114211.130000  150.277661  147.817028  158.631830  145.078482   \n",
       "\n",
       "             X_54        X_55        X_56  \n",
       "count  558.000000  558.000000  558.000000  \n",
       "mean   127.770899  137.731848  128.043417  \n",
       "std      4.909347    6.064247    4.953707  \n",
       "min    113.056164  120.323552  101.781635  \n",
       "25%    124.752235  133.336472  124.771286  \n",
       "50%    127.865219  137.789589  128.311512  \n",
       "75%    130.825727  141.862725  131.575552  \n",
       "max    144.995846  155.575505  140.942455  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_spec_y_01.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c6c7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_iqr_upper(tmp, i):\n",
    "    data = tmp[i]\n",
    "    \n",
    "    print(np.percentile(data,75))\n",
    "    print(np.percentile(data,25))\n",
    "    q25, q75 = np.percentile(data, 25), np.percentile(data,75)\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    print('변수 명 : ',i)\n",
    "    print('IQR : ', iqr)\n",
    "    print('lower bound : ', lower)\n",
    "    print('upper bound : ', upper)\n",
    "    print(np.where(train_x['X_57'] == 1, 1, np.where(data>upper, 1, 0)))\n",
    "    \n",
    "    train_x['X_57'] = np.where(train_x['X_57'] == 1, 1, np.where(data>upper, 1, 0))\n",
    "    \n",
    "    print(\"tmp['X_57'].value_counts() : \", train_x['X_57'].value_counts());\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05bcfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_iqr_lower(tmp, i):\n",
    "    data = tmp[i]\n",
    "    \n",
    "    print(np.percentile(data,75))\n",
    "    print(np.percentile(data,25))\n",
    "    q25, q75 = np.percentile(data, 25), np.percentile(data,75)\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    print('변수 명 : ',i)\n",
    "    print('IQR : ', iqr)\n",
    "    print('lower bound : ', lower)\n",
    "    print('upper bound : ', upper)\n",
    "    train_x['X_57'] = np.where(train_x['X_57'] == 1, 1, np.where(data<lower, 1, 0))\n",
    "    \n",
    "    print(\"tmp['X_57'].value_counts() : \", train_x['X_57'].value_counts());\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11d186e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_57 = [0 for i in range(0, train_x.shape[0])]\n",
    "len(X_57)\n",
    "X_57 = pd.DataFrame(X_57)\n",
    "train_x['X_57'] = X_57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2c7314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차 시도 (y와 corr 기준) fixed 2 !!!!!!!!!!\n",
    "cols_lower = [\"X_14\",\"X_15\",\"X_16\", \"X_18\",\"X_41\", \"X_49\"]\n",
    "cols_upper = [\"X_51\",  \"X_37\", \"X_54\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a75304b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차 시도 (y와 corr 기준) fixed 2 !!!!!!!!!!\n",
    "cols = [\"X_14\",\"X_15\", \"X_17\", \"X_18\", \"X_19\", \"X_20\", \"X_21\",\"X_22\",\n",
    "        \"X_24\", \"X_25\", \"X_26\", \"X_27\", \"X_28\",\"X_29\", \"X_39\", \"X_40\",\"X_41\",\"X_42\",\"X_43\", \"X_44\",\"X_45\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9516e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"X_11\", \"X_14\",\"X_15\", \"X_16\", \"X_17\", \"X_18\", \"X_19\", \"X_20\", \"X_21\",\"X_22\",\n",
    "        \"X_24\", \"X_25\", \"X_26\", \"X_27\", \"X_28\",\"X_29\", \n",
    "        \"X_30\", \"X_31\", \"X_32\", \"X_33\",\n",
    "        \"X_34\", \"X_35\", \"X_36\", \"X_37\", \n",
    "        \"X_39\", \"X_40\",\"X_41\",\"X_42\",\"X_43\", \"X_44\",\"X_45\"\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90e68e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols_upper:\n",
    "    q25, q75 = np.percentile(train_x[i], 25), np.percentile(train_x[i],75)\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    train_x['X_57'] = np.where(train_x['X_57'] == 1, 1, np.where(train_x[i]>upper, 1, 0))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61bb25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols_lower:\n",
    "    q25, q75 = np.percentile(train_x[i], 25), np.percentile(train_x[i],75)\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    train_x['X_57'] = np.where(train_x['X_57'] == 1, 1, np.where(train_x[i]<lower, 1, 0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa2c7c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    38357\n",
       "1     1250\n",
       "Name: X_57, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x['X_57'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f3072a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_57 = [0 for i in range(0, test_x.shape[0])]\n",
    "X_57 = pd.DataFrame(X_57)\n",
    "test_x['X_57'] = X_57\n",
    "\n",
    "for i in cols_upper:\n",
    "    q25, q75 = np.percentile(test_x[i], 25), np.percentile(test_x[i],75)\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    test_x['X_57'] = np.where(test_x['X_57'] == 1, 1, np.where(test_x[i]>upper, 1, 0))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b67077d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols_lower:\n",
    "    q25, q75 = np.percentile(test_x[i], 25), np.percentile(test_x[i],75)\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    test_x['X_57'] = np.where(test_x['X_57'] == 1, 1, np.where(test_x[i]<lower, 1, 0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2065a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols_with_zero_variance = zero_variance(train_x)\n",
    "train_x = train_x.drop(cols_with_zero_variance, axis = 1)\n",
    "test_x = test_x.drop(cols_with_zero_variance, axis = 1)\n",
    "\n",
    "highly_correlated = [i[1] for i in get_top_correlation(train_x, 3).index]\n",
    "#train_x = train_x.drop(highly_correlated, axis = 1)\n",
    "\n",
    "#test_x = test_x.drop(highly_correlated, axis = 1)\n",
    "#test_x = test_x.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6aa03409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'min_child_samples': int(params['min_child_samples']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'subsample': '{:.3f}'.format(params['subsample']),\n",
    "        'min_split_gain': '{:.3f}'.format(params['min_split_gain']),\n",
    "        'scale_pos_weight': '{:.3f}'.format(params['scale_pos_weight']),\n",
    "        'reg_alpha': '{:.3f}'.format(params['reg_alpha']),\n",
    "        'reg_lambda': '{:.3f}'.format(params['reg_lambda']),\n",
    "        'learning_rate': '{:.3f}'.format(params['learning_rate']),\n",
    "        \n",
    "    }\n",
    "    \n",
    "    model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **params))\n",
    "    \n",
    "    loss = -cross_val_score(model, train_x, train_y, cv=10, scoring=make_scorer(lg_nrmse, greater_is_better=False)).mean()\n",
    "    print(\"NRMSE Loss {:.5f} params {}\".format(loss, params))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2148240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 1.94459 params {'n_estimators': 1334, 'max_depth': 47, 'num_leaves': 20, 'min_child_samples': 240, 'colsample_bytree': '0.715', 'subsample': '0.657', 'min_split_gain': '0.655', 'scale_pos_weight': '4.117', 'reg_alpha': '22.649', 'reg_lambda': '55.509', 'learning_rate': '0.042'}\n",
      "NRMSE Loss 1.94481 params {'n_estimators': 1508, 'max_depth': 13, 'num_leaves': 90, 'min_child_samples': 110, 'colsample_bytree': '0.538', 'subsample': '0.901', 'min_split_gain': '0.652', 'scale_pos_weight': '7.202', 'reg_alpha': '1.693', 'reg_lambda': '75.762', 'learning_rate': '0.159'}\n",
      "NRMSE Loss 1.95297 params {'n_estimators': 232, 'max_depth': 67, 'num_leaves': 80, 'min_child_samples': 170, 'colsample_bytree': '0.387', 'subsample': '0.902', 'min_split_gain': '0.436', 'scale_pos_weight': '8.879', 'reg_alpha': '86.379', 'reg_lambda': '88.854', 'learning_rate': '0.039'}\n",
      "NRMSE Loss 1.95513 params {'n_estimators': 580, 'max_depth': 27, 'num_leaves': 60, 'min_child_samples': 120, 'colsample_bytree': '0.746', 'subsample': '0.876', 'min_split_gain': '0.176', 'scale_pos_weight': '8.211', 'reg_alpha': '86.702', 'reg_lambda': '25.897', 'learning_rate': '0.367'}\n",
      "NRMSE Loss 1.95391 params {'n_estimators': 870, 'max_depth': 74, 'num_leaves': 40, 'min_child_samples': 240, 'colsample_bytree': '0.410', 'subsample': '0.422', 'min_split_gain': '0.621', 'scale_pos_weight': '6.373', 'reg_alpha': '69.258', 'reg_lambda': '78.324', 'learning_rate': '0.264'}\n",
      "NRMSE Loss 1.95673 params {'n_estimators': 1392, 'max_depth': 63, 'num_leaves': 90, 'min_child_samples': 90, 'colsample_bytree': '0.376', 'subsample': '0.722', 'min_split_gain': '0.193', 'scale_pos_weight': '8.946', 'reg_alpha': '99.473', 'reg_lambda': '1.047', 'learning_rate': '0.389'}\n",
      "NRMSE Loss 1.94716 params {'n_estimators': 580, 'max_depth': 22, 'num_leaves': 70, 'min_child_samples': 30, 'colsample_bytree': '0.405', 'subsample': '0.727', 'min_split_gain': '0.219', 'scale_pos_weight': '4.841', 'reg_alpha': '73.952', 'reg_lambda': '35.964', 'learning_rate': '0.135'}\n",
      "NRMSE Loss 1.94448 params {'n_estimators': 348, 'max_depth': 43, 'num_leaves': 30, 'min_child_samples': 110, 'colsample_bytree': '0.534', 'subsample': '0.533', 'min_split_gain': '0.334', 'scale_pos_weight': '6.948', 'reg_alpha': '45.064', 'reg_lambda': '65.236', 'learning_rate': '0.056'}\n",
      "NRMSE Loss 1.94985 params {'n_estimators': 1160, 'max_depth': 47, 'num_leaves': 60, 'min_child_samples': 120, 'colsample_bytree': '0.694', 'subsample': '0.717', 'min_split_gain': '0.533', 'scale_pos_weight': '6.427', 'reg_alpha': '82.742', 'reg_lambda': '45.374', 'learning_rate': '0.011'}\n",
      "NRMSE Loss 1.93142 params {'n_estimators': 464, 'max_depth': 75, 'num_leaves': 70, 'min_child_samples': 50, 'colsample_bytree': '0.788', 'subsample': '0.949', 'min_split_gain': '0.162', 'scale_pos_weight': '5.934', 'reg_alpha': '1.526', 'reg_lambda': '70.520', 'learning_rate': '0.045'}\n",
      "NRMSE Loss 1.94640 params {'n_estimators': 986, 'max_depth': 44, 'num_leaves': 90, 'min_child_samples': 260, 'colsample_bytree': '0.748', 'subsample': '0.794', 'min_split_gain': '0.340', 'scale_pos_weight': '5.407', 'reg_alpha': '8.407', 'reg_lambda': '22.070', 'learning_rate': '0.125'}\n",
      "NRMSE Loss 1.96262 params {'n_estimators': 1044, 'max_depth': 49, 'num_leaves': 50, 'min_child_samples': 140, 'colsample_bytree': '0.854', 'subsample': '0.658', 'min_split_gain': '0.409', 'scale_pos_weight': '9.229', 'reg_alpha': '33.783', 'reg_lambda': '56.004', 'learning_rate': '0.454'}\n",
      "NRMSE Loss 1.95013 params {'n_estimators': 754, 'max_depth': 12, 'num_leaves': 60, 'min_child_samples': 210, 'colsample_bytree': '0.533', 'subsample': '0.594', 'min_split_gain': '0.220', 'scale_pos_weight': '9.762', 'reg_alpha': '93.720', 'reg_lambda': '51.486', 'learning_rate': '0.101'}\n",
      "NRMSE Loss 1.94378 params {'n_estimators': 232, 'max_depth': 8, 'num_leaves': 60, 'min_child_samples': 140, 'colsample_bytree': '0.830', 'subsample': '0.735', 'min_split_gain': '0.008', 'scale_pos_weight': '5.962', 'reg_alpha': '76.454', 'reg_lambda': '36.735', 'learning_rate': '0.050'}\n",
      "NRMSE Loss 1.93359 params {'n_estimators': 870, 'max_depth': 75, 'num_leaves': 50, 'min_child_samples': 190, 'colsample_bytree': '0.757', 'subsample': '0.405', 'min_split_gain': '0.017', 'scale_pos_weight': '8.855', 'reg_alpha': '15.020', 'reg_lambda': '30.290', 'learning_rate': '0.022'}\n",
      "NRMSE Loss 1.95653 params {'n_estimators': 696, 'max_depth': 59, 'num_leaves': 50, 'min_child_samples': 260, 'colsample_bytree': '0.450', 'subsample': '0.447', 'min_split_gain': '0.645', 'scale_pos_weight': '7.572', 'reg_alpha': '92.295', 'reg_lambda': '46.259', 'learning_rate': '0.318'}\n",
      "NRMSE Loss 1.93286 params {'n_estimators': 522, 'max_depth': 52, 'num_leaves': 90, 'min_child_samples': 90, 'colsample_bytree': '0.758', 'subsample': '0.705', 'min_split_gain': '0.281', 'scale_pos_weight': '2.045', 'reg_alpha': '3.613', 'reg_lambda': '92.924', 'learning_rate': '0.023'}\n",
      "NRMSE Loss 1.94203 params {'n_estimators': 580, 'max_depth': 31, 'num_leaves': 40, 'min_child_samples': 20, 'colsample_bytree': '0.375', 'subsample': '0.744', 'min_split_gain': '0.396', 'scale_pos_weight': '7.031', 'reg_alpha': '33.102', 'reg_lambda': '99.326', 'learning_rate': '0.049'}\n",
      "NRMSE Loss 1.95558 params {'n_estimators': 986, 'max_depth': 74, 'num_leaves': 60, 'min_child_samples': 90, 'colsample_bytree': '0.518', 'subsample': '0.775', 'min_split_gain': '0.203', 'scale_pos_weight': '8.605', 'reg_alpha': '73.138', 'reg_lambda': '64.505', 'learning_rate': '0.403'}\n",
      "NRMSE Loss 1.93437 params {'n_estimators': 1450, 'max_depth': 65, 'num_leaves': 40, 'min_child_samples': 110, 'colsample_bytree': '0.370', 'subsample': '0.407', 'min_split_gain': '0.125', 'scale_pos_weight': '5.457', 'reg_alpha': '7.912', 'reg_lambda': '32.531', 'learning_rate': '0.034'}\n",
      "NRMSE Loss 1.93159 params {'n_estimators': 348, 'max_depth': 98, 'num_leaves': 100, 'min_child_samples': 50, 'colsample_bytree': '0.638', 'subsample': '0.967', 'min_split_gain': '0.086', 'scale_pos_weight': '1.790', 'reg_alpha': '1.058', 'reg_lambda': '98.243', 'learning_rate': '0.018'}\n",
      "NRMSE Loss 1.95917 params {'n_estimators': 116, 'max_depth': 98, 'num_leaves': 100, 'min_child_samples': 50, 'colsample_bytree': '0.934', 'subsample': '0.994', 'min_split_gain': '0.081', 'scale_pos_weight': '1.682', 'reg_alpha': '56.097', 'reg_lambda': '80.683', 'learning_rate': '0.013'}\n",
      "NRMSE Loss 1.93559 params {'n_estimators': 406, 'max_depth': 100, 'num_leaves': 80, 'min_child_samples': 50, 'colsample_bytree': '0.637', 'subsample': '0.963', 'min_split_gain': '0.086', 'scale_pos_weight': '2.996', 'reg_alpha': '19.260', 'reg_lambda': '95.475', 'learning_rate': '0.018'}\n",
      "NRMSE Loss 1.93688 params {'n_estimators': 116, 'max_depth': 90, 'num_leaves': 100, 'min_child_samples': 50, 'colsample_bytree': '0.998', 'subsample': '0.838', 'min_split_gain': '0.049', 'scale_pos_weight': '3.458', 'reg_alpha': '26.490', 'reg_lambda': '69.245', 'learning_rate': '0.082'}\n",
      "NRMSE Loss 1.93029 params {'n_estimators': 406, 'max_depth': 87, 'num_leaves': 70, 'min_child_samples': 10, 'colsample_bytree': '0.830', 'subsample': '0.955', 'min_split_gain': '0.134', 'scale_pos_weight': '2.707', 'reg_alpha': '0.181', 'reg_lambda': '84.918', 'learning_rate': '0.029'}\n",
      "NRMSE Loss 1.94184 params {'n_estimators': 406, 'max_depth': 87, 'num_leaves': 70, 'min_child_samples': 20, 'colsample_bytree': '0.854', 'subsample': '0.943', 'min_split_gain': '0.264', 'scale_pos_weight': '4.401', 'reg_alpha': '47.301', 'reg_lambda': '71.619', 'learning_rate': '0.027'}\n",
      "NRMSE Loss 1.94292 params {'n_estimators': 232, 'max_depth': 85, 'num_leaves': 70, 'min_child_samples': 70, 'colsample_bytree': '0.927', 'subsample': '0.834', 'min_split_gain': '0.126', 'scale_pos_weight': '1.030', 'reg_alpha': '59.479', 'reg_lambda': '81.827', 'learning_rate': '0.071'}\n",
      "NRMSE Loss 1.93293 params {'n_estimators': 696, 'max_depth': 81, 'num_leaves': 80, 'min_child_samples': 10, 'colsample_bytree': '0.993', 'subsample': '0.989', 'min_split_gain': '0.144', 'scale_pos_weight': '3.068', 'reg_alpha': '12.470', 'reg_lambda': '85.621', 'learning_rate': '0.031'}\n",
      "NRMSE Loss 1.93987 params {'n_estimators': 522, 'max_depth': 93, 'num_leaves': 70, 'min_child_samples': 70, 'colsample_bytree': '0.820', 'subsample': '0.532', 'min_split_gain': '0.281', 'scale_pos_weight': '3.814', 'reg_alpha': '25.499', 'reg_lambda': '59.097', 'learning_rate': '0.014'}\n",
      "NRMSE Loss 1.94802 params {'n_estimators': 464, 'max_depth': 80, 'num_leaves': 80, 'min_child_samples': 30, 'colsample_bytree': '0.926', 'subsample': '0.926', 'min_split_gain': '0.482', 'scale_pos_weight': '4.811', 'reg_alpha': '34.800', 'reg_lambda': '3.845', 'learning_rate': '0.181'}\n",
      "NRMSE Loss 1.94063 params {'n_estimators': 232, 'max_depth': 56, 'num_leaves': 70, 'min_child_samples': 10, 'colsample_bytree': '0.593', 'subsample': '0.847', 'min_split_gain': '0.254', 'scale_pos_weight': '2.477', 'reg_alpha': '40.379', 'reg_lambda': '87.848', 'learning_rate': '0.065'}\n",
      "NRMSE Loss 1.94252 params {'n_estimators': 696, 'max_depth': 68, 'num_leaves': 80, 'min_child_samples': 170, 'colsample_bytree': '0.680', 'subsample': '0.307', 'min_split_gain': '0.003', 'scale_pos_weight': '1.156', 'reg_alpha': '0.986', 'reg_lambda': '73.994', 'learning_rate': '0.040'}\n",
      "NRMSE Loss 1.93839 params {'n_estimators': 290, 'max_depth': 93, 'num_leaves': 50, 'min_child_samples': 290, 'colsample_bytree': '0.892', 'subsample': '0.899', 'min_split_gain': '0.056', 'scale_pos_weight': '4.169', 'reg_alpha': '17.787', 'reg_lambda': '62.435', 'learning_rate': '0.092'}\n",
      "NRMSE Loss 1.94225 params {'n_estimators': 116, 'max_depth': 82, 'num_leaves': 30, 'min_child_samples': 80, 'colsample_bytree': '0.802', 'subsample': '0.642', 'min_split_gain': '0.149', 'scale_pos_weight': '8.001', 'reg_alpha': '24.247', 'reg_lambda': '10.836', 'learning_rate': '0.202'}\n",
      "NRMSE Loss 1.93501 params {'n_estimators': 812, 'max_depth': 36, 'num_leaves': 80, 'min_child_samples': 150, 'colsample_bytree': '0.585', 'subsample': '0.900', 'min_split_gain': '0.321', 'scale_pos_weight': '6.090', 'reg_alpha': '7.088', 'reg_lambda': '89.920', 'learning_rate': '0.026'}\n",
      " 18%|███████▋                                    | 35/200 [58:30<4:35:48, 100.29s/trial, best loss: 1.9302891200974455]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m space \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m : hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1500\u001b[39m, \u001b[38;5;241m58\u001b[39m),\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m0.01\u001b[39m), np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m0.5\u001b[39m)),\n\u001b[0;32m     13\u001b[0m }\n\u001b[1;32m---> 15\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_rng\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Input \u001b[1;32mIn [68]\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      2\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \n\u001b[0;32m     15\u001b[0m }\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiOutputRegressor(LGBMRegressor(n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams))\n\u001b[1;32m---> 19\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlg_nrmse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNRMSE Loss \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m params \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss, params))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\multioutput.py:202\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    200\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\multioutput.py:44\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     42\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py:895\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y,\n\u001b[0;32m    889\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    890\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    891\u001b[0m         eval_init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    892\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    893\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 895\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    285\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m    286\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    287\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[0;32m    288\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[0;32m    289\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[0;32m    290\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m--> 292\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m evaluation_result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 3021\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 100, 1500, 58),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 100, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 100, 10),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 10, 300, 10),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'subsample': hp.uniform('subsample', 0.3, 1.0),\n",
    "    'min_split_gain': hp.uniform('min_split_gain', 0, 0.7),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 10),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 100),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 100),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "}\n",
    "\n",
    "best = fmin(fn = objective,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 200,\n",
    "            rstate=np.random.default_rng(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **best))\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a1a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "for idx, col in enumerate(submit.columns):\n",
    "    if col=='ID':\n",
    "        continue\n",
    "    submit[col] = preds[:,idx-1]\n",
    "submit.to_csv('./submission_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff53b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
