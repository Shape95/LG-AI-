{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88c9f79",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784827d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from lightgbm import LGBMRegressor\n",
    "from hyperopt import fmin, hp, tpe, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ab72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69084ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split_X_y(df):    \n",
    "    \"\"\"\n",
    "    @Description: split data into features and labels\n",
    "    @Param: df, pandas dataframe with columns starting with X for features and Y for labels\n",
    "    @Return: features and labels in pandas dataframes\n",
    "    \"\"\"\n",
    "    xs = df.filter(regex='X') # Input : X Feature\n",
    "    ys = df.filter(regex='Y') # Output : Y Feature\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "800347f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_variance(df):\n",
    "    \"\"\"\n",
    "    @Description: check for zero_variance\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Return: names of the columns with zero variance\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        if df[col].var() == 0:\n",
    "            result.append(col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3405de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_correlation(df, n=10):\n",
    "    \"\"\"\n",
    "    @Description: print out top correlated features\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Param2: n, number of lines to print \n",
    "    @Return: pandas series\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    for idx1 in range(0, df.shape[1]):\n",
    "        for idx2 in range(0, idx1+1):\n",
    "            pairs.add((df.columns[idx1], df.columns[idx2]))\n",
    "    corr = df.corr().abs().unstack()\n",
    "    corr = corr.drop(labels=pairs).sort_values(ascending=False)\n",
    "    return corr[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8979dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lg_nrmse(gt, preds):\n",
    "    \"\"\"\n",
    "    @Description: Metric used in this project\n",
    "    @Params1: gt, pandas dataframe\n",
    "    @Param2: preds, pandas dataframe\n",
    "    @Return: nrmse score\n",
    "    \"\"\"\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    preds = pd.DataFrame(preds)\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14):\n",
    "        rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt.iloc[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:15])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70733c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('data/train.csv')\n",
    "\n",
    "test_x = pd.read_csv('data/test.csv')\n",
    "train_x, train_y = dataset_split_X_y(train_x)\n",
    "\n",
    "\n",
    "y_feature_spec_info = pd.read_csv('data/meta/y_feature_spec_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a5961c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_01</th>\n",
       "      <th>Y_02</th>\n",
       "      <th>Y_03</th>\n",
       "      <th>Y_04</th>\n",
       "      <th>Y_05</th>\n",
       "      <th>Y_06</th>\n",
       "      <th>Y_07</th>\n",
       "      <th>Y_08</th>\n",
       "      <th>Y_09</th>\n",
       "      <th>Y_10</th>\n",
       "      <th>Y_11</th>\n",
       "      <th>Y_12</th>\n",
       "      <th>Y_13</th>\n",
       "      <th>Y_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.056</td>\n",
       "      <td>1.456</td>\n",
       "      <td>1.680</td>\n",
       "      <td>10.502</td>\n",
       "      <td>29.632</td>\n",
       "      <td>16.083</td>\n",
       "      <td>4.276</td>\n",
       "      <td>-25.381</td>\n",
       "      <td>-25.529</td>\n",
       "      <td>-22.769</td>\n",
       "      <td>23.792</td>\n",
       "      <td>-25.470</td>\n",
       "      <td>-25.409</td>\n",
       "      <td>-25.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.446</td>\n",
       "      <td>1.184</td>\n",
       "      <td>1.268</td>\n",
       "      <td>18.507</td>\n",
       "      <td>33.179</td>\n",
       "      <td>16.736</td>\n",
       "      <td>3.229</td>\n",
       "      <td>-26.619</td>\n",
       "      <td>-26.523</td>\n",
       "      <td>-22.574</td>\n",
       "      <td>24.691</td>\n",
       "      <td>-26.253</td>\n",
       "      <td>-26.497</td>\n",
       "      <td>-26.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.251</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.782</td>\n",
       "      <td>14.082</td>\n",
       "      <td>31.801</td>\n",
       "      <td>17.080</td>\n",
       "      <td>2.839</td>\n",
       "      <td>-26.238</td>\n",
       "      <td>-26.216</td>\n",
       "      <td>-22.169</td>\n",
       "      <td>24.649</td>\n",
       "      <td>-26.285</td>\n",
       "      <td>-26.215</td>\n",
       "      <td>-26.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.464</td>\n",
       "      <td>1.079</td>\n",
       "      <td>1.052</td>\n",
       "      <td>16.975</td>\n",
       "      <td>34.503</td>\n",
       "      <td>17.143</td>\n",
       "      <td>3.144</td>\n",
       "      <td>-25.426</td>\n",
       "      <td>-25.079</td>\n",
       "      <td>-21.765</td>\n",
       "      <td>24.913</td>\n",
       "      <td>-25.254</td>\n",
       "      <td>-25.021</td>\n",
       "      <td>-25.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.689</td>\n",
       "      <td>15.047</td>\n",
       "      <td>32.602</td>\n",
       "      <td>17.569</td>\n",
       "      <td>3.138</td>\n",
       "      <td>-25.376</td>\n",
       "      <td>-25.242</td>\n",
       "      <td>-21.072</td>\n",
       "      <td>25.299</td>\n",
       "      <td>-25.072</td>\n",
       "      <td>-25.195</td>\n",
       "      <td>-24.974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y_01   Y_02   Y_03    Y_04    Y_05    Y_06   Y_07    Y_08    Y_09    Y_10  \\\n",
       "0  2.056  1.456  1.680  10.502  29.632  16.083  4.276 -25.381 -25.529 -22.769   \n",
       "1  1.446  1.184  1.268  18.507  33.179  16.736  3.229 -26.619 -26.523 -22.574   \n",
       "2  1.251  0.665  0.782  14.082  31.801  17.080  2.839 -26.238 -26.216 -22.169   \n",
       "3  1.464  1.079  1.052  16.975  34.503  17.143  3.144 -25.426 -25.079 -21.765   \n",
       "4  0.983  0.646  0.689  15.047  32.602  17.569  3.138 -25.376 -25.242 -21.072   \n",
       "\n",
       "     Y_11    Y_12    Y_13    Y_14  \n",
       "0  23.792 -25.470 -25.409 -25.304  \n",
       "1  24.691 -26.253 -26.497 -26.438  \n",
       "2  24.649 -26.285 -26.215 -26.370  \n",
       "3  24.913 -25.254 -25.021 -25.345  \n",
       "4  25.299 -25.072 -25.195 -24.974  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d55973a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = ['X_14', 'X_15', 'X_16', 'X_17', 'X_18']\n",
    "group2 = ['X_19', 'X_20', 'X_21', 'X_22']\n",
    "group3 = ['X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29']\n",
    "group4 = ['X_41','X_42', 'X_43', 'X_44']\n",
    "group5 = ['X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55', 'X_56']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6062cd29",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_ \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mmax\u001b[39m(train_x[i]):\n\u001b[0;32m      7\u001b[0m         max_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(train_x[i])\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m min_ \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[43mtrain_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m):\n\u001b[0;32m      9\u001b[0m         min_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(train_x[i])\n\u001b[0;32m     10\u001b[0m lst\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mabs\u001b[39m(max_ \u001b[38;5;241m-\u001b[39m min_))\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\pandas\\core\\frame.py:3463\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3460\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)):\n\u001b[0;32m   3461\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_column_array(i)\n\u001b[1;32m-> 3463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   3464\u001b[0m     check_deprecated_indexers(key)\n\u001b[0;32m   3465\u001b[0m     key \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(key)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for k in range(len(train_x)):\n",
    "    for i in group1:\n",
    "        max_ = 0\n",
    "        min_ = 1000000\n",
    "        if max_ < max(train_x[i]):\n",
    "            max_ = max(train_x[i])\n",
    "        if min_ > min(train_x[i]):\n",
    "            min_ = min(train_x[i])\n",
    "    lst.append(abs(max_ - min_))\n",
    "\n",
    "X_57 = pd.DataFrame(lst)\n",
    "X_57 = pd.concat([X_57, pd.DataFrame(lst)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97bf6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae50c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(train_x)):\n",
    "    for i in group2:\n",
    "        max_ = 0\n",
    "        min_ = 1000000\n",
    "        if max_ < max(train_x[i]):\n",
    "            max_ = max(train_x[i])\n",
    "        if min_ > min(train_x[i]):\n",
    "            min_ = min(train_x[i])\n",
    "        lst.append(abs(max_ - min_))\n",
    "\n",
    "X_58 = pd.DataFrame(lst)\n",
    "X_58 = pd.concat([X_57, pd.DataFrame(lst)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(train_x)):\n",
    "    for i in group3:\n",
    "        max_ = 0\n",
    "        min_ = 1000000\n",
    "        if max_ < max(train_x[i]):\n",
    "            max_ = max(train_x[i])\n",
    "        if min_ > min(train_x[i]):\n",
    "            min_ = min(train_x[i])\n",
    "        lst.append(abs(max_ - min_))\n",
    "\n",
    "X_59 = pd.DataFrame(lst)\n",
    "X_59 = pd.concat([train_x, pd.DataFrame(lst)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977448b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(train_x)):\n",
    "    for i in group4:\n",
    "        max_ = 0\n",
    "        min_ = 1000000\n",
    "        if max_ < max(train_x[i]):\n",
    "            max_ = max(train_x[i])\n",
    "        if min_ > min(train_x[i]):\n",
    "            min_ = min(train_x[i])\n",
    "        lst.append(abs(max_ - min_))\n",
    "\n",
    "X_60 = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(train_x)):\n",
    "    for i in group5:\n",
    "        max_ = 0\n",
    "        min_ = 1000000\n",
    "        if max_ < max(train_x[i]):\n",
    "            max_ = max(train_x[i])\n",
    "        if min_ > min(train_x[i]):\n",
    "            min_ = min(train_x[i])\n",
    "        lst.append(abs(max_ - min_))\n",
    "\n",
    "X_61 = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d21ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ddec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d86f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523c25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec_df = y_feature_spec_info\n",
    "df_indicator_y = pd.DataFrame()\n",
    "for idx in range(len(train_spec_df.Feature)):\n",
    "    if train_spec_df.Feature[idx] in train_y.columns:\n",
    "        y_series = ~train_y[train_spec_df.Feature[idx]].between(train_spec_df.iloc[idx, :].Min, train_spec_df.iloc[idx, :].Max)\n",
    "        df_indicator_y = pd.concat([df_indicator_y, y_series.astype(int)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f1dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = df_indicator_y[df_indicator_y==0]\n",
    "spec_data = df_indicator_y[df_indicator_y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "318fb2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y_01    1476\n",
       "Y_02     558\n",
       "Y_03     464\n",
       "Y_04     500\n",
       "Y_05      91\n",
       "Y_06      10\n",
       "Y_07    1822\n",
       "Y_08      19\n",
       "Y_09      19\n",
       "Y_10       5\n",
       "Y_11       3\n",
       "Y_12      16\n",
       "Y_13      15\n",
       "Y_14      13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9780153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_spec_y_01 = train_x[spec_data['Y_02'] == 1]\n",
    "train_x_normal_y_01 = train_x[normal_data['Y_02'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddc46d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_01\n",
      "min : X_14\n",
      "min : X_15\n",
      "min : X_16\n",
      "min : X_18\n",
      "max : X_51\n",
      "\n",
      "Y_02\n",
      "min : X_49\n",
      "\n",
      "Y_03\n",
      "min : X_49\n",
      "\n",
      "Y_04\n",
      "max : X_37\n",
      "max : X_54\n",
      "\n",
      "Y_05\n",
      "\n",
      "Y_06\n",
      "\n",
      "Y_07\n",
      "min : X_41\n",
      "\n",
      "Y_08\n",
      "\n",
      "Y_09\n",
      "\n",
      "Y_10\n",
      "\n",
      "Y_11\n",
      "\n",
      "Y_12\n",
      "\n",
      "Y_13\n",
      "\n",
      "Y_14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in train_y.columns:\n",
    "    train_x_spec_y_01 = train_x[spec_data[k] == 1]\n",
    "    train_x_normal_y_01 = train_x[normal_data[k] == 0]\n",
    "    print(k)\n",
    "    for i in train_x.columns:\n",
    "        if max(train_x_normal_y_01[i]) < max(train_x_spec_y_01[i]):\n",
    "            print('max :' ,i)\n",
    "        if min(train_x_normal_y_01[i]) > min(train_x_spec_y_01[i]) :\n",
    "            print('min :' ,i)\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1397778d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "      <th>X_16</th>\n",
       "      <th>X_17</th>\n",
       "      <th>X_18</th>\n",
       "      <th>X_19</th>\n",
       "      <th>X_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000366</td>\n",
       "      <td>4.373230</td>\n",
       "      <td>0.143335</td>\n",
       "      <td>13.372203</td>\n",
       "      <td>13.381916</td>\n",
       "      <td>13.463860</td>\n",
       "      <td>13.512590</td>\n",
       "      <td>13.449264</td>\n",
       "      <td>3.240250</td>\n",
       "      <td>3.184512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>0.025332</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.036741</td>\n",
       "      <td>0.023436</td>\n",
       "      <td>0.029094</td>\n",
       "      <td>0.110484</td>\n",
       "      <td>0.105266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.270000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>13.150000</td>\n",
       "      <td>13.230000</td>\n",
       "      <td>13.260000</td>\n",
       "      <td>13.410000</td>\n",
       "      <td>13.260000</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>2.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.360000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>13.350000</td>\n",
       "      <td>13.360000</td>\n",
       "      <td>13.440000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>13.430000</td>\n",
       "      <td>3.160000</td>\n",
       "      <td>3.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.370000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>13.380000</td>\n",
       "      <td>13.470000</td>\n",
       "      <td>13.510000</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>3.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.390000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>13.390000</td>\n",
       "      <td>13.410000</td>\n",
       "      <td>13.490000</td>\n",
       "      <td>13.530000</td>\n",
       "      <td>13.470000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>3.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>13.490000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>13.610000</td>\n",
       "      <td>13.610000</td>\n",
       "      <td>13.570000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.670000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_11          X_12          X_13          X_14          X_15  \\\n",
       "count  39594.000000  39594.000000  39594.000000  39594.000000  39594.000000   \n",
       "mean       0.000366      4.373230      0.143335     13.372203     13.381916   \n",
       "std        0.014148      0.021808      0.025332      0.029867      0.029468   \n",
       "min        0.000000      4.270000      0.050000     13.150000     13.230000   \n",
       "25%        0.000000      4.360000      0.130000     13.350000     13.360000   \n",
       "50%        0.000000      4.370000      0.140000     13.370000     13.380000   \n",
       "75%        0.000000      4.390000      0.160000     13.390000     13.410000   \n",
       "max        0.700000      4.490000      0.280000     13.490000     13.500000   \n",
       "\n",
       "               X_16          X_17          X_18          X_19          X_20  \n",
       "count  39594.000000  39594.000000  39594.000000  39594.000000  39594.000000  \n",
       "mean      13.463860     13.512590     13.449264      3.240250      3.184512  \n",
       "std        0.036741      0.023436      0.029094      0.110484      0.105266  \n",
       "min       13.260000     13.410000     13.260000      2.860000      2.830000  \n",
       "25%       13.440000     13.500000     13.430000      3.160000      3.100000  \n",
       "50%       13.470000     13.510000     13.450000      3.220000      3.180000  \n",
       "75%       13.490000     13.530000     13.470000      3.310000      3.270000  \n",
       "max       13.610000     13.610000     13.570000      3.750000      3.670000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_normal_y_01.iloc[:,10:20].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bee2f61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "      <th>X_16</th>\n",
       "      <th>X_17</th>\n",
       "      <th>X_18</th>\n",
       "      <th>X_19</th>\n",
       "      <th>X_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.366923</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>13.368462</td>\n",
       "      <td>13.375385</td>\n",
       "      <td>13.463077</td>\n",
       "      <td>13.509231</td>\n",
       "      <td>13.447692</td>\n",
       "      <td>3.176154</td>\n",
       "      <td>3.126923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013775</td>\n",
       "      <td>0.030149</td>\n",
       "      <td>0.026092</td>\n",
       "      <td>0.030445</td>\n",
       "      <td>0.038597</td>\n",
       "      <td>0.023260</td>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.083620</td>\n",
       "      <td>0.090865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>13.410000</td>\n",
       "      <td>13.480000</td>\n",
       "      <td>13.410000</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>3.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.360000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>13.350000</td>\n",
       "      <td>13.350000</td>\n",
       "      <td>13.430000</td>\n",
       "      <td>13.490000</td>\n",
       "      <td>13.430000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>3.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.370000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>13.390000</td>\n",
       "      <td>13.470000</td>\n",
       "      <td>13.510000</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>3.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>13.390000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>13.480000</td>\n",
       "      <td>13.520000</td>\n",
       "      <td>13.470000</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>3.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>13.410000</td>\n",
       "      <td>13.410000</td>\n",
       "      <td>13.530000</td>\n",
       "      <td>13.550000</td>\n",
       "      <td>13.490000</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>3.360000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X_11       X_12       X_13       X_14       X_15       X_16       X_17  \\\n",
       "count  13.0  13.000000  13.000000  13.000000  13.000000  13.000000  13.000000   \n",
       "mean    0.0   4.366923   0.143846  13.368462  13.375385  13.463077  13.509231   \n",
       "std     0.0   0.013775   0.030149   0.026092   0.030445   0.038597   0.023260   \n",
       "min     0.0   4.340000   0.100000  13.330000  13.330000  13.410000  13.480000   \n",
       "25%     0.0   4.360000   0.120000  13.350000  13.350000  13.430000  13.490000   \n",
       "50%     0.0   4.370000   0.140000  13.370000  13.390000  13.470000  13.510000   \n",
       "75%     0.0   4.380000   0.160000  13.390000  13.400000  13.480000  13.520000   \n",
       "max     0.0   4.380000   0.190000  13.410000  13.410000  13.530000  13.550000   \n",
       "\n",
       "            X_18       X_19       X_20  \n",
       "count  13.000000  13.000000  13.000000  \n",
       "mean   13.447692   3.176154   3.126923  \n",
       "std     0.027127   0.083620   0.090865  \n",
       "min    13.410000   3.090000   3.030000  \n",
       "25%    13.430000   3.130000   3.060000  \n",
       "50%    13.450000   3.150000   3.110000  \n",
       "75%    13.470000   3.210000   3.150000  \n",
       "max    13.490000   3.420000   3.360000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_spec_y_01.iloc[:,10:20].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17ce3bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_21</th>\n",
       "      <th>X_22</th>\n",
       "      <th>X_23</th>\n",
       "      <th>X_24</th>\n",
       "      <th>X_25</th>\n",
       "      <th>X_26</th>\n",
       "      <th>X_27</th>\n",
       "      <th>X_28</th>\n",
       "      <th>X_29</th>\n",
       "      <th>X_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.0</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "      <td>39594.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.174288</td>\n",
       "      <td>3.232693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.115674</td>\n",
       "      <td>2.093895</td>\n",
       "      <td>2.090377</td>\n",
       "      <td>2.098248</td>\n",
       "      <td>2.118591</td>\n",
       "      <td>2.173727</td>\n",
       "      <td>1.378992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.106865</td>\n",
       "      <td>0.108984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032443</td>\n",
       "      <td>0.033150</td>\n",
       "      <td>0.038517</td>\n",
       "      <td>0.038060</td>\n",
       "      <td>0.042783</td>\n",
       "      <td>0.046691</td>\n",
       "      <td>0.030408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.830000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.090000</td>\n",
       "      <td>3.140000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>1.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.160000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>1.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.790000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>2.110000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_21          X_22     X_23          X_24          X_25  \\\n",
       "count  39594.000000  39594.000000  39594.0  39594.000000  39594.000000   \n",
       "mean       3.174288      3.232693      1.0      2.115674      2.093895   \n",
       "std        0.106865      0.108984      0.0      0.032443      0.033150   \n",
       "min        2.830000      2.850000      1.0      1.830000      1.960000   \n",
       "25%        3.090000      3.140000      1.0      2.090000      2.070000   \n",
       "50%        3.160000      3.230000      1.0      2.120000      2.090000   \n",
       "75%        3.250000      3.320000      1.0      2.140000      2.120000   \n",
       "max        3.680000      3.790000      1.0      2.350000      2.350000   \n",
       "\n",
       "               X_26          X_27          X_28          X_29          X_30  \n",
       "count  39594.000000  39594.000000  39594.000000  39594.000000  39594.000000  \n",
       "mean       2.090377      2.098248      2.118591      2.173727      1.378992  \n",
       "std        0.038517      0.038060      0.042783      0.046691      0.030408  \n",
       "min        1.980000      1.990000      1.930000      2.020000      0.570000  \n",
       "25%        2.060000      2.070000      2.090000      2.140000      1.370000  \n",
       "50%        2.090000      2.090000      2.120000      2.170000      1.370000  \n",
       "75%        2.120000      2.120000      2.140000      2.200000      1.380000  \n",
       "max        2.350000      2.350000      2.350000      2.360000      2.110000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_normal_y_01.iloc[:,20:30].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3e2a016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_21</th>\n",
       "      <th>X_22</th>\n",
       "      <th>X_23</th>\n",
       "      <th>X_24</th>\n",
       "      <th>X_25</th>\n",
       "      <th>X_26</th>\n",
       "      <th>X_27</th>\n",
       "      <th>X_28</th>\n",
       "      <th>X_29</th>\n",
       "      <th>X_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.121538</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.116154</td>\n",
       "      <td>2.093846</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.101538</td>\n",
       "      <td>2.127692</td>\n",
       "      <td>2.173846</td>\n",
       "      <td>1.387692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.108155</td>\n",
       "      <td>0.079791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021424</td>\n",
       "      <td>0.027850</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>0.024099</td>\n",
       "      <td>0.040652</td>\n",
       "      <td>0.040319</td>\n",
       "      <td>0.040652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.060000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>1.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.080000</td>\n",
       "      <td>3.120000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>1.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.090000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>1.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.140000</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>2.190000</td>\n",
       "      <td>1.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.450000</td>\n",
       "      <td>3.370000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            X_21       X_22  X_23       X_24       X_25       X_26       X_27  \\\n",
       "count  13.000000  13.000000  13.0  13.000000  13.000000  13.000000  13.000000   \n",
       "mean    3.121538   3.170000   1.0   2.116154   2.093846   2.090000   2.101538   \n",
       "std     0.108155   0.079791   0.0   0.021424   0.027850   0.020412   0.024099   \n",
       "min     3.000000   3.060000   1.0   2.090000   2.040000   2.070000   2.060000   \n",
       "25%     3.080000   3.120000   1.0   2.100000   2.080000   2.070000   2.080000   \n",
       "50%     3.090000   3.170000   1.0   2.110000   2.100000   2.090000   2.100000   \n",
       "75%     3.140000   3.190000   1.0   2.130000   2.120000   2.110000   2.130000   \n",
       "max     3.450000   3.370000   1.0   2.160000   2.130000   2.130000   2.130000   \n",
       "\n",
       "            X_28       X_29       X_30  \n",
       "count  13.000000  13.000000  13.000000  \n",
       "mean    2.127692   2.173846   1.387692  \n",
       "std     0.040652   0.040319   0.040652  \n",
       "min     2.060000   2.120000   1.350000  \n",
       "25%     2.110000   2.150000   1.370000  \n",
       "50%     2.130000   2.170000   1.380000  \n",
       "75%     2.140000   2.190000   1.380000  \n",
       "max     2.230000   2.260000   1.510000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_spec_y_01.iloc[:,20:30].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5fdacd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_31</th>\n",
       "      <th>X_32</th>\n",
       "      <th>X_33</th>\n",
       "      <th>X_34</th>\n",
       "      <th>X_35</th>\n",
       "      <th>X_36</th>\n",
       "      <th>X_37</th>\n",
       "      <th>X_38</th>\n",
       "      <th>X_39</th>\n",
       "      <th>X_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.571179</td>\n",
       "      <td>1.362961</td>\n",
       "      <td>1.595846</td>\n",
       "      <td>12.950250</td>\n",
       "      <td>12.920309</td>\n",
       "      <td>12.941730</td>\n",
       "      <td>12.919113</td>\n",
       "      <td>-15.904671</td>\n",
       "      <td>-15.890222</td>\n",
       "      <td>-16.572931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.074738</td>\n",
       "      <td>0.030060</td>\n",
       "      <td>0.107967</td>\n",
       "      <td>0.044023</td>\n",
       "      <td>0.052232</td>\n",
       "      <td>0.047839</td>\n",
       "      <td>0.052295</td>\n",
       "      <td>0.594186</td>\n",
       "      <td>0.747688</td>\n",
       "      <td>0.343985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>12.840000</td>\n",
       "      <td>12.810000</td>\n",
       "      <td>12.840000</td>\n",
       "      <td>12.810000</td>\n",
       "      <td>-17.090000</td>\n",
       "      <td>-17.090000</td>\n",
       "      <td>-17.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.530000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>12.920000</td>\n",
       "      <td>12.870000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>12.870000</td>\n",
       "      <td>-16.160000</td>\n",
       "      <td>-16.160000</td>\n",
       "      <td>-16.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.550000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>12.960000</td>\n",
       "      <td>12.910000</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>12.910000</td>\n",
       "      <td>-15.990000</td>\n",
       "      <td>-15.990000</td>\n",
       "      <td>-16.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>12.990000</td>\n",
       "      <td>12.970000</td>\n",
       "      <td>12.980000</td>\n",
       "      <td>12.970000</td>\n",
       "      <td>-15.750000</td>\n",
       "      <td>-15.750000</td>\n",
       "      <td>-16.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.210000</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>7.810000</td>\n",
       "      <td>13.080000</td>\n",
       "      <td>13.090000</td>\n",
       "      <td>13.090000</td>\n",
       "      <td>13.080000</td>\n",
       "      <td>32.230000</td>\n",
       "      <td>-2.650000</td>\n",
       "      <td>-14.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_31          X_32          X_33          X_34          X_35  \\\n",
       "count  39049.000000  39049.000000  39049.000000  39049.000000  39049.000000   \n",
       "mean       1.571179      1.362961      1.595846     12.950250     12.920309   \n",
       "std        0.074738      0.030060      0.107967      0.044023      0.052232   \n",
       "min        0.600000      0.570000      0.610000     12.840000     12.810000   \n",
       "25%        1.530000      1.350000      1.550000     12.920000     12.870000   \n",
       "50%        1.550000      1.360000      1.570000     12.960000     12.910000   \n",
       "75%        1.600000      1.370000      1.610000     12.990000     12.970000   \n",
       "max        7.210000      2.450000      7.810000     13.080000     13.090000   \n",
       "\n",
       "               X_36          X_37          X_38          X_39          X_40  \n",
       "count  39049.000000  39049.000000  39049.000000  39049.000000  39049.000000  \n",
       "mean      12.941730     12.919113    -15.904671    -15.890222    -16.572931  \n",
       "std        0.047839      0.052295      0.594186      0.747688      0.343985  \n",
       "min       12.840000     12.810000    -17.090000    -17.090000    -17.720000  \n",
       "25%       12.900000     12.870000    -16.160000    -16.160000    -16.810000  \n",
       "50%       12.950000     12.910000    -15.990000    -15.990000    -16.640000  \n",
       "75%       12.980000     12.970000    -15.750000    -15.750000    -16.400000  \n",
       "max       13.090000     13.080000     32.230000     -2.650000    -14.800000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_normal_y_01.iloc[:,30:40].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a08e8daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_31</th>\n",
       "      <th>X_32</th>\n",
       "      <th>X_33</th>\n",
       "      <th>X_34</th>\n",
       "      <th>X_35</th>\n",
       "      <th>X_36</th>\n",
       "      <th>X_37</th>\n",
       "      <th>X_38</th>\n",
       "      <th>X_39</th>\n",
       "      <th>X_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.568495</td>\n",
       "      <td>1.360663</td>\n",
       "      <td>1.587151</td>\n",
       "      <td>12.951685</td>\n",
       "      <td>12.922724</td>\n",
       "      <td>12.941631</td>\n",
       "      <td>12.920914</td>\n",
       "      <td>-15.838423</td>\n",
       "      <td>-15.844373</td>\n",
       "      <td>-16.518315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.057227</td>\n",
       "      <td>0.020243</td>\n",
       "      <td>0.112019</td>\n",
       "      <td>0.044521</td>\n",
       "      <td>0.052634</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.673639</td>\n",
       "      <td>0.670276</td>\n",
       "      <td>0.374343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>12.830000</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>12.810000</td>\n",
       "      <td>-16.760000</td>\n",
       "      <td>-16.760000</td>\n",
       "      <td>-17.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.530000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>12.920000</td>\n",
       "      <td>12.870000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>12.880000</td>\n",
       "      <td>-16.140000</td>\n",
       "      <td>-16.140000</td>\n",
       "      <td>-16.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.550000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>12.960000</td>\n",
       "      <td>12.925000</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>12.920000</td>\n",
       "      <td>-15.940000</td>\n",
       "      <td>-15.960000</td>\n",
       "      <td>-16.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.590000</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>12.990000</td>\n",
       "      <td>12.970000</td>\n",
       "      <td>12.980000</td>\n",
       "      <td>12.970000</td>\n",
       "      <td>-15.640000</td>\n",
       "      <td>-15.650000</td>\n",
       "      <td>-16.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.880000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>13.040000</td>\n",
       "      <td>13.060000</td>\n",
       "      <td>13.040000</td>\n",
       "      <td>13.030000</td>\n",
       "      <td>-2.650000</td>\n",
       "      <td>-2.650000</td>\n",
       "      <td>-15.340000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X_31        X_32        X_33        X_34        X_35        X_36  \\\n",
       "count  558.000000  558.000000  558.000000  558.000000  558.000000  558.000000   \n",
       "mean     1.568495    1.360663    1.587151   12.951685   12.922724   12.941631   \n",
       "std      0.057227    0.020243    0.112019    0.044521    0.052634    0.047217   \n",
       "min      1.500000    1.330000    0.610000   12.850000   12.830000   12.850000   \n",
       "25%      1.530000    1.350000    1.550000   12.920000   12.870000   12.900000   \n",
       "50%      1.550000    1.360000    1.570000   12.960000   12.925000   12.950000   \n",
       "75%      1.590000    1.370000    1.590000   12.990000   12.970000   12.980000   \n",
       "max      1.880000    1.470000    2.160000   13.040000   13.060000   13.040000   \n",
       "\n",
       "             X_37        X_38        X_39        X_40  \n",
       "count  558.000000  558.000000  558.000000  558.000000  \n",
       "mean    12.920914  -15.838423  -15.844373  -16.518315  \n",
       "std      0.052147    0.673639    0.670276    0.374343  \n",
       "min     12.810000  -16.760000  -16.760000  -17.360000  \n",
       "25%     12.880000  -16.140000  -16.140000  -16.790000  \n",
       "50%     12.920000  -15.940000  -15.960000  -16.605000  \n",
       "75%     12.970000  -15.640000  -15.650000  -16.290000  \n",
       "max     13.030000   -2.650000   -2.650000  -15.340000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_spec_y_01.iloc[:,30:40].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a5b2913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_41</th>\n",
       "      <th>X_42</th>\n",
       "      <th>X_43</th>\n",
       "      <th>X_44</th>\n",
       "      <th>X_45</th>\n",
       "      <th>X_46</th>\n",
       "      <th>X_47</th>\n",
       "      <th>X_48</th>\n",
       "      <th>X_49</th>\n",
       "      <th>X_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.0</td>\n",
       "      <td>39049.0</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.186992</td>\n",
       "      <td>21.059368</td>\n",
       "      <td>21.203696</td>\n",
       "      <td>21.160097</td>\n",
       "      <td>0.154520</td>\n",
       "      <td>1468.276166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16678.583539</td>\n",
       "      <td>130.782024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031099</td>\n",
       "      <td>0.040272</td>\n",
       "      <td>0.047227</td>\n",
       "      <td>0.042166</td>\n",
       "      <td>0.046989</td>\n",
       "      <td>2.120836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8552.008319</td>\n",
       "      <td>5.991171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.730000</td>\n",
       "      <td>20.790000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>20.930000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3382.630000</td>\n",
       "      <td>21.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.170000</td>\n",
       "      <td>21.030000</td>\n",
       "      <td>21.170000</td>\n",
       "      <td>21.130000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13108.630000</td>\n",
       "      <td>126.956647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.190000</td>\n",
       "      <td>21.060000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>21.160000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15278.930000</td>\n",
       "      <td>130.732472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.210000</td>\n",
       "      <td>21.090000</td>\n",
       "      <td>21.240000</td>\n",
       "      <td>21.190000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17564.730000</td>\n",
       "      <td>134.547360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.620000</td>\n",
       "      <td>21.440000</td>\n",
       "      <td>21.410000</td>\n",
       "      <td>21.320000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114563.630000</td>\n",
       "      <td>162.619458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_41          X_42          X_43          X_44          X_45  \\\n",
       "count  39049.000000  39049.000000  39049.000000  39049.000000  39049.000000   \n",
       "mean      21.186992     21.059368     21.203696     21.160097      0.154520   \n",
       "std        0.031099      0.040272      0.047227      0.042166      0.046989   \n",
       "min       20.730000     20.790000     20.800000     20.930000      0.000000   \n",
       "25%       21.170000     21.030000     21.170000     21.130000      0.120000   \n",
       "50%       21.190000     21.060000     21.200000     21.160000      0.150000   \n",
       "75%       21.210000     21.090000     21.240000     21.190000      0.190000   \n",
       "max       21.620000     21.440000     21.410000     21.320000      0.420000   \n",
       "\n",
       "               X_46     X_47     X_48           X_49          X_50  \n",
       "count  39049.000000  39049.0  39049.0   39049.000000  39049.000000  \n",
       "mean    1468.276166      1.0      1.0   16678.583539    130.782024  \n",
       "std        2.120836      0.0      0.0    8552.008319      5.991171  \n",
       "min     1457.000000      1.0      1.0    3382.630000     21.800000  \n",
       "25%     1469.000000      1.0      1.0   13108.630000    126.956647  \n",
       "50%     1469.000000      1.0      1.0   15278.930000    130.732472  \n",
       "75%     1469.000000      1.0      1.0   17564.730000    134.547360  \n",
       "max     1469.000000      1.0      1.0  114563.630000    162.619458  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_normal_y_01.iloc[:,40:50].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "54ba2cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_41</th>\n",
       "      <th>X_42</th>\n",
       "      <th>X_43</th>\n",
       "      <th>X_44</th>\n",
       "      <th>X_45</th>\n",
       "      <th>X_46</th>\n",
       "      <th>X_47</th>\n",
       "      <th>X_48</th>\n",
       "      <th>X_49</th>\n",
       "      <th>X_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.186953</td>\n",
       "      <td>21.056971</td>\n",
       "      <td>21.204337</td>\n",
       "      <td>21.160771</td>\n",
       "      <td>0.157849</td>\n",
       "      <td>1468.215054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16560.053513</td>\n",
       "      <td>130.252055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.033132</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.046088</td>\n",
       "      <td>0.042851</td>\n",
       "      <td>0.045367</td>\n",
       "      <td>2.169725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10618.710723</td>\n",
       "      <td>5.878046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.080000</td>\n",
       "      <td>20.890000</td>\n",
       "      <td>21.040000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3341.830000</td>\n",
       "      <td>113.547627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.170000</td>\n",
       "      <td>21.030000</td>\n",
       "      <td>21.170000</td>\n",
       "      <td>21.130000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12175.205000</td>\n",
       "      <td>126.111388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.190000</td>\n",
       "      <td>21.060000</td>\n",
       "      <td>21.210000</td>\n",
       "      <td>21.160000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14783.880000</td>\n",
       "      <td>130.313973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.210000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>21.230000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17264.080000</td>\n",
       "      <td>133.887299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.510000</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>21.370000</td>\n",
       "      <td>21.240000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114211.130000</td>\n",
       "      <td>150.277661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X_41        X_42        X_43        X_44        X_45  \\\n",
       "count  558.000000  558.000000  558.000000  558.000000  558.000000   \n",
       "mean    21.186953   21.056971   21.204337   21.160771    0.157849   \n",
       "std      0.033132    0.041350    0.046088    0.042851    0.045367   \n",
       "min     21.080000   20.890000   21.040000   21.000000    0.040000   \n",
       "25%     21.170000   21.030000   21.170000   21.130000    0.120000   \n",
       "50%     21.190000   21.060000   21.210000   21.160000    0.160000   \n",
       "75%     21.210000   21.080000   21.230000   21.200000    0.190000   \n",
       "max     21.510000   21.250000   21.370000   21.240000    0.290000   \n",
       "\n",
       "              X_46   X_47   X_48           X_49        X_50  \n",
       "count   558.000000  558.0  558.0     558.000000  558.000000  \n",
       "mean   1468.215054    1.0    1.0   16560.053513  130.252055  \n",
       "std       2.169725    0.0    0.0   10618.710723    5.878046  \n",
       "min    1457.000000    1.0    1.0    3341.830000  113.547627  \n",
       "25%    1469.000000    1.0    1.0   12175.205000  126.111388  \n",
       "50%    1469.000000    1.0    1.0   14783.880000  130.313973  \n",
       "75%    1469.000000    1.0    1.0   17264.080000  133.887299  \n",
       "max    1469.000000    1.0    1.0  114211.130000  150.277661  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_spec_y_01.iloc[:,40:50].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "855e670b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_01</th>\n",
       "      <th>X_02</th>\n",
       "      <th>X_03</th>\n",
       "      <th>X_04</th>\n",
       "      <th>X_05</th>\n",
       "      <th>X_06</th>\n",
       "      <th>X_07</th>\n",
       "      <th>X_08</th>\n",
       "      <th>X_09</th>\n",
       "      <th>X_10</th>\n",
       "      <th>...</th>\n",
       "      <th>X_47</th>\n",
       "      <th>X_48</th>\n",
       "      <th>X_49</th>\n",
       "      <th>X_50</th>\n",
       "      <th>X_51</th>\n",
       "      <th>X_52</th>\n",
       "      <th>X_53</th>\n",
       "      <th>X_54</th>\n",
       "      <th>X_55</th>\n",
       "      <th>X_56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.0</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39049.0</td>\n",
       "      <td>39049.0</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "      <td>39049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>68.411610</td>\n",
       "      <td>103.320167</td>\n",
       "      <td>68.816570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.337957</td>\n",
       "      <td>70.595443</td>\n",
       "      <td>29.394517</td>\n",
       "      <td>164.448757</td>\n",
       "      <td>225.514783</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16678.583539</td>\n",
       "      <td>130.782024</td>\n",
       "      <td>131.459133</td>\n",
       "      <td>138.587340</td>\n",
       "      <td>127.995251</td>\n",
       "      <td>128.017585</td>\n",
       "      <td>137.886895</td>\n",
       "      <td>128.446802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.658364</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>5.154366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.548553</td>\n",
       "      <td>2.260763</td>\n",
       "      <td>7.258563</td>\n",
       "      <td>220.629270</td>\n",
       "      <td>66.638349</td>\n",
       "      <td>0.085533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8552.008319</td>\n",
       "      <td>5.991171</td>\n",
       "      <td>5.941484</td>\n",
       "      <td>6.474068</td>\n",
       "      <td>5.712359</td>\n",
       "      <td>5.441066</td>\n",
       "      <td>6.558856</td>\n",
       "      <td>5.450783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>56.268000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>56.470000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.774000</td>\n",
       "      <td>61.726000</td>\n",
       "      <td>14.140000</td>\n",
       "      <td>38.460000</td>\n",
       "      <td>37.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3382.630000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>21.910000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>21.330000</td>\n",
       "      <td>21.340000</td>\n",
       "      <td>22.980000</td>\n",
       "      <td>21.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>66.465000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>65.070000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.949000</td>\n",
       "      <td>68.864000</td>\n",
       "      <td>27.890000</td>\n",
       "      <td>105.960000</td>\n",
       "      <td>188.630000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13108.630000</td>\n",
       "      <td>126.956647</td>\n",
       "      <td>127.668461</td>\n",
       "      <td>134.471696</td>\n",
       "      <td>124.379934</td>\n",
       "      <td>124.696049</td>\n",
       "      <td>133.751523</td>\n",
       "      <td>125.140644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68.504000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>67.270000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.006000</td>\n",
       "      <td>69.884000</td>\n",
       "      <td>28.840000</td>\n",
       "      <td>115.040000</td>\n",
       "      <td>234.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15278.930000</td>\n",
       "      <td>130.732472</td>\n",
       "      <td>131.356266</td>\n",
       "      <td>138.524881</td>\n",
       "      <td>128.027021</td>\n",
       "      <td>128.103878</td>\n",
       "      <td>137.901829</td>\n",
       "      <td>128.415753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>69.524000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>71.770000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.144000</td>\n",
       "      <td>71.923000</td>\n",
       "      <td>29.870000</td>\n",
       "      <td>132.630000</td>\n",
       "      <td>263.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17564.730000</td>\n",
       "      <td>134.547360</td>\n",
       "      <td>135.173489</td>\n",
       "      <td>142.704385</td>\n",
       "      <td>131.618765</td>\n",
       "      <td>131.499576</td>\n",
       "      <td>142.075490</td>\n",
       "      <td>131.842556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>84.820000</td>\n",
       "      <td>103.321000</td>\n",
       "      <td>89.170000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.160000</td>\n",
       "      <td>87.219000</td>\n",
       "      <td>163.860000</td>\n",
       "      <td>2387.440000</td>\n",
       "      <td>637.490000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114563.630000</td>\n",
       "      <td>162.619458</td>\n",
       "      <td>194.513195</td>\n",
       "      <td>173.438623</td>\n",
       "      <td>152.406630</td>\n",
       "      <td>175.052891</td>\n",
       "      <td>170.155980</td>\n",
       "      <td>155.277538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_01          X_02          X_03     X_04          X_05  \\\n",
       "count  39049.000000  39049.000000  39049.000000  39049.0  39049.000000   \n",
       "mean      68.411610    103.320167     68.816570      1.0    102.337957   \n",
       "std        2.658364      0.000373      5.154366      0.0      0.548553   \n",
       "min       56.268000    103.320000     56.470000      1.0    101.774000   \n",
       "25%       66.465000    103.320000     65.070000      1.0    101.949000   \n",
       "50%       68.504000    103.320000     67.270000      1.0    102.006000   \n",
       "75%       69.524000    103.320000     71.770000      1.0    103.144000   \n",
       "max       84.820000    103.321000     89.170000      1.0    103.160000   \n",
       "\n",
       "               X_06          X_07          X_08          X_09          X_10  \\\n",
       "count  39049.000000  39049.000000  39049.000000  39049.000000  39049.000000   \n",
       "mean      70.595443     29.394517    164.448757    225.514783      0.002407   \n",
       "std        2.260763      7.258563    220.629270     66.638349      0.085533   \n",
       "min       61.726000     14.140000     38.460000     37.580000      0.000000   \n",
       "25%       68.864000     27.890000    105.960000    188.630000      0.000000   \n",
       "50%       69.884000     28.840000    115.040000    234.580000      0.000000   \n",
       "75%       71.923000     29.870000    132.630000    263.960000      0.000000   \n",
       "max       87.219000    163.860000   2387.440000    637.490000      3.600000   \n",
       "\n",
       "       ...     X_47     X_48           X_49          X_50          X_51  \\\n",
       "count  ...  39049.0  39049.0   39049.000000  39049.000000  39049.000000   \n",
       "mean   ...      1.0      1.0   16678.583539    130.782024    131.459133   \n",
       "std    ...      0.0      0.0    8552.008319      5.991171      5.941484   \n",
       "min    ...      1.0      1.0    3382.630000     21.800000     21.910000   \n",
       "25%    ...      1.0      1.0   13108.630000    126.956647    127.668461   \n",
       "50%    ...      1.0      1.0   15278.930000    130.732472    131.356266   \n",
       "75%    ...      1.0      1.0   17564.730000    134.547360    135.173489   \n",
       "max    ...      1.0      1.0  114563.630000    162.619458    194.513195   \n",
       "\n",
       "               X_52          X_53          X_54          X_55          X_56  \n",
       "count  39049.000000  39049.000000  39049.000000  39049.000000  39049.000000  \n",
       "mean     138.587340    127.995251    128.017585    137.886895    128.446802  \n",
       "std        6.474068      5.712359      5.441066      6.558856      5.450783  \n",
       "min       23.100000     21.330000     21.340000     22.980000     21.410000  \n",
       "25%      134.471696    124.379934    124.696049    133.751523    125.140644  \n",
       "50%      138.524881    128.027021    128.103878    137.901829    128.415753  \n",
       "75%      142.704385    131.618765    131.499576    142.075490    131.842556  \n",
       "max      173.438623    152.406630    175.052891    170.155980    155.277538  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_normal_y_01.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0f8017d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_01</th>\n",
       "      <th>X_02</th>\n",
       "      <th>X_03</th>\n",
       "      <th>X_04</th>\n",
       "      <th>X_05</th>\n",
       "      <th>X_06</th>\n",
       "      <th>X_07</th>\n",
       "      <th>X_08</th>\n",
       "      <th>X_09</th>\n",
       "      <th>X_10</th>\n",
       "      <th>...</th>\n",
       "      <th>X_47</th>\n",
       "      <th>X_48</th>\n",
       "      <th>X_49</th>\n",
       "      <th>X_50</th>\n",
       "      <th>X_51</th>\n",
       "      <th>X_52</th>\n",
       "      <th>X_53</th>\n",
       "      <th>X_54</th>\n",
       "      <th>X_55</th>\n",
       "      <th>X_56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.0</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.00000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>558.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>558.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>68.442138</td>\n",
       "      <td>103.320149</td>\n",
       "      <td>69.511039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.284437</td>\n",
       "      <td>70.72097</td>\n",
       "      <td>30.315323</td>\n",
       "      <td>164.488692</td>\n",
       "      <td>217.187832</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16560.053513</td>\n",
       "      <td>130.252055</td>\n",
       "      <td>131.337355</td>\n",
       "      <td>138.605408</td>\n",
       "      <td>127.794313</td>\n",
       "      <td>127.770899</td>\n",
       "      <td>137.731848</td>\n",
       "      <td>128.043417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.485748</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>4.877934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531973</td>\n",
       "      <td>2.19123</td>\n",
       "      <td>11.601906</td>\n",
       "      <td>204.086726</td>\n",
       "      <td>72.760905</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10618.710723</td>\n",
       "      <td>5.878046</td>\n",
       "      <td>5.412467</td>\n",
       "      <td>6.170294</td>\n",
       "      <td>5.770202</td>\n",
       "      <td>4.909347</td>\n",
       "      <td>6.064247</td>\n",
       "      <td>4.953707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>58.307000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>60.270000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.815000</td>\n",
       "      <td>63.76600</td>\n",
       "      <td>24.960000</td>\n",
       "      <td>58.380000</td>\n",
       "      <td>37.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3341.830000</td>\n",
       "      <td>113.547627</td>\n",
       "      <td>108.960072</td>\n",
       "      <td>114.213213</td>\n",
       "      <td>109.122007</td>\n",
       "      <td>113.056164</td>\n",
       "      <td>120.323552</td>\n",
       "      <td>101.781635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>66.465000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>65.770000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.932250</td>\n",
       "      <td>68.86400</td>\n",
       "      <td>28.192500</td>\n",
       "      <td>107.277500</td>\n",
       "      <td>176.275000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12175.205000</td>\n",
       "      <td>126.111388</td>\n",
       "      <td>127.694327</td>\n",
       "      <td>134.810781</td>\n",
       "      <td>123.699215</td>\n",
       "      <td>124.752235</td>\n",
       "      <td>133.336472</td>\n",
       "      <td>124.771286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68.504000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>68.870000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.998000</td>\n",
       "      <td>70.90400</td>\n",
       "      <td>28.885000</td>\n",
       "      <td>115.565000</td>\n",
       "      <td>226.360000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14783.880000</td>\n",
       "      <td>130.313973</td>\n",
       "      <td>131.157730</td>\n",
       "      <td>138.598226</td>\n",
       "      <td>127.528109</td>\n",
       "      <td>127.865219</td>\n",
       "      <td>137.789589</td>\n",
       "      <td>128.311512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>69.524000</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>72.645000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.136750</td>\n",
       "      <td>71.92300</td>\n",
       "      <td>29.967500</td>\n",
       "      <td>128.570000</td>\n",
       "      <td>264.917500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17264.080000</td>\n",
       "      <td>133.887299</td>\n",
       "      <td>134.592182</td>\n",
       "      <td>142.458873</td>\n",
       "      <td>131.542738</td>\n",
       "      <td>130.825727</td>\n",
       "      <td>141.862725</td>\n",
       "      <td>131.575552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.682000</td>\n",
       "      <td>103.321000</td>\n",
       "      <td>84.070000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.160000</td>\n",
       "      <td>78.04200</td>\n",
       "      <td>163.860000</td>\n",
       "      <td>2358.070000</td>\n",
       "      <td>619.900000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114211.130000</td>\n",
       "      <td>150.277661</td>\n",
       "      <td>147.817028</td>\n",
       "      <td>158.631830</td>\n",
       "      <td>145.078482</td>\n",
       "      <td>144.995846</td>\n",
       "      <td>155.575505</td>\n",
       "      <td>140.942455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X_01        X_02        X_03   X_04        X_05       X_06  \\\n",
       "count  558.000000  558.000000  558.000000  558.0  558.000000  558.00000   \n",
       "mean    68.442138  103.320149   69.511039    1.0  102.284437   70.72097   \n",
       "std      2.485748    0.000356    4.877934    0.0    0.531973    2.19123   \n",
       "min     58.307000  103.320000   60.270000    1.0  101.815000   63.76600   \n",
       "25%     66.465000  103.320000   65.770000    1.0  101.932250   68.86400   \n",
       "50%     68.504000  103.320000   68.870000    1.0  101.998000   70.90400   \n",
       "75%     69.524000  103.320000   72.645000    1.0  103.136750   71.92300   \n",
       "max     77.682000  103.321000   84.070000    1.0  103.160000   78.04200   \n",
       "\n",
       "             X_07         X_08        X_09        X_10  ...   X_47   X_48  \\\n",
       "count  558.000000   558.000000  558.000000  558.000000  ...  558.0  558.0   \n",
       "mean    30.315323   164.488692  217.187832    0.005376  ...    1.0    1.0   \n",
       "std     11.601906   204.086726   72.760905    0.127000  ...    0.0    0.0   \n",
       "min     24.960000    58.380000   37.580000    0.000000  ...    1.0    1.0   \n",
       "25%     28.192500   107.277500  176.275000    0.000000  ...    1.0    1.0   \n",
       "50%     28.885000   115.565000  226.360000    0.000000  ...    1.0    1.0   \n",
       "75%     29.967500   128.570000  264.917500    0.000000  ...    1.0    1.0   \n",
       "max    163.860000  2358.070000  619.900000    3.000000  ...    1.0    1.0   \n",
       "\n",
       "                X_49        X_50        X_51        X_52        X_53  \\\n",
       "count     558.000000  558.000000  558.000000  558.000000  558.000000   \n",
       "mean    16560.053513  130.252055  131.337355  138.605408  127.794313   \n",
       "std     10618.710723    5.878046    5.412467    6.170294    5.770202   \n",
       "min      3341.830000  113.547627  108.960072  114.213213  109.122007   \n",
       "25%     12175.205000  126.111388  127.694327  134.810781  123.699215   \n",
       "50%     14783.880000  130.313973  131.157730  138.598226  127.528109   \n",
       "75%     17264.080000  133.887299  134.592182  142.458873  131.542738   \n",
       "max    114211.130000  150.277661  147.817028  158.631830  145.078482   \n",
       "\n",
       "             X_54        X_55        X_56  \n",
       "count  558.000000  558.000000  558.000000  \n",
       "mean   127.770899  137.731848  128.043417  \n",
       "std      4.909347    6.064247    4.953707  \n",
       "min    113.056164  120.323552  101.781635  \n",
       "25%    124.752235  133.336472  124.771286  \n",
       "50%    127.865219  137.789589  128.311512  \n",
       "75%    130.825727  141.862725  131.575552  \n",
       "max    144.995846  155.575505  140.942455  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_spec_y_01.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919844ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c6c7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_iqr_upper(tmp, i):\n",
    "    data = tmp[i]\n",
    "    \n",
    "    print(np.percentile(data,75))\n",
    "    print(np.percentile(data,25))\n",
    "    q25, q75 = np.percentile(data, 25), np.percentile(data,75)\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    print('변수 명 : ',i)\n",
    "    print('IQR : ', iqr)\n",
    "    print('lower bound : ', lower)\n",
    "    print('upper bound : ', upper)\n",
    "    print(np.where(train_x['X_57'] == 1, 1, np.where(data>upper, 1, 0)))\n",
    "    \n",
    "    train_x['X_57'] = np.where(train_x['X_57'] == 1, 1, np.where(data>upper, 1, 0))\n",
    "    \n",
    "    print(\"tmp['X_57'].value_counts() : \", train_x['X_57'].value_counts());\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05bcfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_iqr_lower(tmp, i):\n",
    "    data = tmp[i]\n",
    "    \n",
    "    print(np.percentile(data,75))\n",
    "    print(np.percentile(data,25))\n",
    "    q25, q75 = np.percentile(data, 25), np.percentile(data,75)\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    print('변수 명 : ',i)\n",
    "    print('IQR : ', iqr)\n",
    "    print('lower bound : ', lower)\n",
    "    print('upper bound : ', upper)\n",
    "    train_x['X_57'] = np.where(train_x['X_57'] == 1, 1, np.where(data<lower, 1, 0))\n",
    "    \n",
    "    print(\"tmp['X_57'].value_counts() : \", train_x['X_57'].value_counts());\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11d186e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_57 = [0 for i in range(0, train_x.shape[0])]\n",
    "len(X_57)\n",
    "X_57 = pd.DataFrame(X_57)\n",
    "train_x['X_57'] = X_57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2c7314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차 시도 (y와 corr 기준) fixed 2 !!!!!!!!!!\n",
    "cols_lower = [\"X_14\",\"X_15\",\"X_16\", \"X_18\",\"X_41\", \"X_49\"]\n",
    "cols_upper = [\"X_51\",  \"X_37\", \"X_54\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a75304b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차 시도 (y와 corr 기준) fixed 2 !!!!!!!!!!\n",
    "cols = [\"X_14\",\"X_15\", \"X_17\", \"X_18\", \"X_19\", \"X_20\", \"X_21\",\"X_22\",\n",
    "        \"X_24\", \"X_25\", \"X_26\", \"X_27\", \"X_28\",\"X_29\", \"X_39\", \"X_40\",\"X_41\",\"X_42\",\"X_43\", \"X_44\",\"X_45\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9516e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"X_11\", \"X_14\",\"X_15\", \"X_16\", \"X_17\", \"X_18\", \"X_19\", \"X_20\", \"X_21\",\"X_22\",\n",
    "        \"X_24\", \"X_25\", \"X_26\", \"X_27\", \"X_28\",\"X_29\", \n",
    "        \"X_30\", \"X_31\", \"X_32\", \"X_33\",\n",
    "        \"X_34\", \"X_35\", \"X_36\", \"X_37\", \n",
    "        \"X_39\", \"X_40\",\"X_41\",\"X_42\",\"X_43\", \"X_44\",\"X_45\"\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90e68e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols_upper:\n",
    "    q25, q75 = np.percentile(train_x[i], 25), np.percentile(train_x[i],75)\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    upper = max(train_x_spec_y_01[i])\n",
    "    train_x['X_57'] = np.where(train_x['X_57'] == 1, 1, np.where(train_x[i]>upper, 1, 0))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "61bb25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols_lower:\n",
    "    q25, q75 = np.percentile(train_x[i], 25), np.percentile(train_x[i],75)\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    lower  = min(train_x_spec_y_01[i])\n",
    "    train_x['X_57'] = np.where(train_x['X_57'] == 1, 1, np.where(train_x[i]<lower, 1, 0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd84e360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22351\n",
       "1    17256\n",
       "Name: X_57, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x['X_57'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6beb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_57 = [0 for i in range(0, test_x.shape[0])]\n",
    "X_57 = pd.DataFrame(X_57)\n",
    "test_x['X_57'] = X_57\n",
    "\n",
    "for i in cols_upper:\n",
    "    q25, q75 = np.percentile(test_x[i], 25), np.percentile(test_x[i],75)\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    test_x['X_57'] = np.where(test_x['X_57'] == 1, 1, np.where(test_x[i]>upper, 1, 0))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a6feb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols_lower:\n",
    "    q25, q75 = np.percentile(test_x[i], 25), np.percentile(test_x[i],75)\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    test_x['X_57'] = np.where(test_x['X_57'] == 1, 1, np.where(test_x[i]<lower, 1, 0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9623b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_spec_y_01 = train_x[spec_data['Y_02'] == 1]\n",
    "train_x_normal_y_01 = train_x[normal_data['Y_02'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e173446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_01    39594\n",
      "X_02    39594\n",
      "X_03    39594\n",
      "X_04    39594\n",
      "X_05    39594\n",
      "X_06    39594\n",
      "X_07    39594\n",
      "X_08    39594\n",
      "X_09    39594\n",
      "X_10    39594\n",
      "X_11    39594\n",
      "X_12    39594\n",
      "X_13    39594\n",
      "X_14    39594\n",
      "X_15    39594\n",
      "X_16    39594\n",
      "X_17    39594\n",
      "X_18    39594\n",
      "X_19    39594\n",
      "X_20    39594\n",
      "X_21    39594\n",
      "X_22    39594\n",
      "X_23    39594\n",
      "X_24    39594\n",
      "X_25    39594\n",
      "X_26    39594\n",
      "X_27    39594\n",
      "X_28    39594\n",
      "X_29    39594\n",
      "X_30    39594\n",
      "X_31    39594\n",
      "X_32    39594\n",
      "X_33    39594\n",
      "X_34    39594\n",
      "X_35    39594\n",
      "X_36    39594\n",
      "X_37    39594\n",
      "X_38    39594\n",
      "X_39    39594\n",
      "X_40    39594\n",
      "X_41    39594\n",
      "X_42    39594\n",
      "X_43    39594\n",
      "X_44    39594\n",
      "X_45    39594\n",
      "X_46    39594\n",
      "X_47    39594\n",
      "X_48    39594\n",
      "X_49    39594\n",
      "X_50    39594\n",
      "X_51    39594\n",
      "X_52    39594\n",
      "X_53    39594\n",
      "X_54    39594\n",
      "X_55    39594\n",
      "X_56    39594\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_x_normal_y_01.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a3e54a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ai\\envs\\dacon\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\ai\\envs\\dacon\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train_x_spec_y_01['X_49'], color = 'blue')\n",
    "sns.distplot(train_x_normal_y_01['X_49'], color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6ee6b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X_01    1250\n",
       "X_02    1250\n",
       "X_03    1250\n",
       "X_04    1250\n",
       "X_05    1250\n",
       "X_06    1250\n",
       "X_07    1250\n",
       "X_08    1250\n",
       "X_09    1250\n",
       "X_10    1250\n",
       "X_11    1250\n",
       "X_12    1250\n",
       "X_13    1250\n",
       "X_14    1250\n",
       "X_15    1250\n",
       "X_16    1250\n",
       "X_17    1250\n",
       "X_18    1250\n",
       "X_19    1250\n",
       "X_20    1250\n",
       "X_21    1250\n",
       "X_22    1250\n",
       "X_23    1250\n",
       "X_24    1250\n",
       "X_25    1250\n",
       "X_26    1250\n",
       "X_27    1250\n",
       "X_28    1250\n",
       "X_29    1250\n",
       "X_30    1250\n",
       "X_31    1250\n",
       "X_32    1250\n",
       "X_33    1250\n",
       "X_34    1250\n",
       "X_35    1250\n",
       "X_36    1250\n",
       "X_37    1250\n",
       "X_38    1250\n",
       "X_39    1250\n",
       "X_40    1250\n",
       "X_41    1250\n",
       "X_42    1250\n",
       "X_43    1250\n",
       "X_44    1250\n",
       "X_45    1250\n",
       "X_46    1250\n",
       "X_47    1250\n",
       "X_48    1250\n",
       "X_49    1250\n",
       "X_50    1250\n",
       "X_51    1250\n",
       "X_52    1250\n",
       "X_53    1250\n",
       "X_54    1250\n",
       "X_55    1250\n",
       "X_56    1250\n",
       "X_57    1250\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[train_x['X_57'] == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2065a961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_11', 'X_18', 'X_18', 'X_21', 'X_15', 'X_22', 'X_26']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cols_with_zero_variance = zero_variance(train_x)\n",
    "train_x = train_x.drop(cols_with_zero_variance, axis = 1)\n",
    "test_x = test_x.drop(cols_with_zero_variance, axis = 1)\n",
    "\n",
    "#highly_correlated = [i[1] for i in get_top_correlation(train_x, 7).index]\n",
    "print(highly_correlated)\n",
    "#train_x = train_x.drop(highly_correlated, axis = 1)\n",
    "\n",
    "#test_x = test_x.drop(highly_correlated, axis = 1)\n",
    "test_x = test_x.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16c92aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = ['X_14', 'X_15', 'X_16',  'X_18']\n",
    "group2 = [ 'X_20', 'X_21', 'X_22']\n",
    "group3 = ['X_24',  'X_26', 'X_27', 'X_28', 'X_29']\n",
    "group4 = ['X_41','X_42', 'X_44']\n",
    "group5 = ['X_50', 'X_51',  'X_53', 'X_54', 'X_55', 'X_56']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4399e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.drop(group1, axis=1)\n",
    "train_x = train_x.drop(group2, axis=1)\n",
    "train_x = train_x.drop(group3, axis=1)\n",
    "train_x = train_x.drop(group4, axis=1)\n",
    "train_x = train_x.drop(group5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a33d57fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dohyeong Seo\\AppData\\Local\\Temp\\ipykernel_17900\\658759966.py:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask = np.zeros_like(corr, dtype=np.bool)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Co-relation 매트릭스\n",
    "corr = train_x.corr()\n",
    "# 마스크 셋업\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "# 그래프 셋업\n",
    "plt.figure(figsize=(20, 12))\n",
    "# 그래프 타이틀\n",
    "plt.title('Overall Correlation of Titanic Features', fontsize=22)\n",
    "# Co-relation 매트릭스 런칭\n",
    "sns.heatmap(corr, mask=mask, annot=False,cmap='RdYlGn', linewidths=0.2, annot_kws={'size':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6aa03409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'min_child_samples': int(params['min_child_samples']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'subsample': '{:.3f}'.format(params['subsample']),\n",
    "        'min_split_gain': '{:.3f}'.format(params['min_split_gain']),\n",
    "        'scale_pos_weight': '{:.3f}'.format(params['scale_pos_weight']),\n",
    "        'reg_alpha': '{:.3f}'.format(params['reg_alpha']),\n",
    "        'reg_lambda': '{:.3f}'.format(params['reg_lambda']),\n",
    "        'learning_rate': '{:.3f}'.format(params['learning_rate']),\n",
    "        \n",
    "    }\n",
    "    \n",
    "    model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **params))\n",
    "    \n",
    "    loss = -cross_val_score(model, train_x, train_y, cv=10, scoring=make_scorer(lg_nrmse, greater_is_better=False)).mean()\n",
    "    print(\"NRMSE Loss {:.5f} params {}\".format(loss, params))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2148240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 1.94938 params {'n_estimators': 1350, 'max_depth': 47, 'num_leaves': 20, 'min_child_samples': 240, 'colsample_bytree': '0.715', 'subsample': '0.657', 'min_split_gain': '0.655', 'scale_pos_weight': '4.117', 'reg_alpha': '22.649', 'reg_lambda': '55.509', 'learning_rate': '0.042'}\n",
      "NRMSE Loss 1.94789 params {'n_estimators': 1500, 'max_depth': 13, 'num_leaves': 90, 'min_child_samples': 110, 'colsample_bytree': '0.538', 'subsample': '0.901', 'min_split_gain': '0.652', 'scale_pos_weight': '7.202', 'reg_alpha': '1.693', 'reg_lambda': '75.762', 'learning_rate': '0.159'}\n",
      "NRMSE Loss 1.95821 params {'n_estimators': 250, 'max_depth': 67, 'num_leaves': 80, 'min_child_samples': 170, 'colsample_bytree': '0.387', 'subsample': '0.902', 'min_split_gain': '0.436', 'scale_pos_weight': '8.879', 'reg_alpha': '86.379', 'reg_lambda': '88.854', 'learning_rate': '0.039'}\n",
      "NRMSE Loss 1.95636 params {'n_estimators': 600, 'max_depth': 27, 'num_leaves': 60, 'min_child_samples': 120, 'colsample_bytree': '0.746', 'subsample': '0.876', 'min_split_gain': '0.176', 'scale_pos_weight': '8.211', 'reg_alpha': '86.702', 'reg_lambda': '25.897', 'learning_rate': '0.367'}\n",
      "NRMSE Loss 1.95836 params {'n_estimators': 900, 'max_depth': 74, 'num_leaves': 40, 'min_child_samples': 240, 'colsample_bytree': '0.410', 'subsample': '0.422', 'min_split_gain': '0.621', 'scale_pos_weight': '6.373', 'reg_alpha': '69.258', 'reg_lambda': '78.324', 'learning_rate': '0.264'}\n",
      "NRMSE Loss 1.95883 params {'n_estimators': 1400, 'max_depth': 63, 'num_leaves': 90, 'min_child_samples': 90, 'colsample_bytree': '0.376', 'subsample': '0.722', 'min_split_gain': '0.193', 'scale_pos_weight': '8.946', 'reg_alpha': '99.473', 'reg_lambda': '1.047', 'learning_rate': '0.389'}\n",
      "NRMSE Loss 1.95299 params {'n_estimators': 550, 'max_depth': 22, 'num_leaves': 70, 'min_child_samples': 30, 'colsample_bytree': '0.405', 'subsample': '0.727', 'min_split_gain': '0.219', 'scale_pos_weight': '4.841', 'reg_alpha': '73.952', 'reg_lambda': '35.964', 'learning_rate': '0.135'}\n",
      "NRMSE Loss 1.94988 params {'n_estimators': 350, 'max_depth': 43, 'num_leaves': 30, 'min_child_samples': 110, 'colsample_bytree': '0.534', 'subsample': '0.533', 'min_split_gain': '0.334', 'scale_pos_weight': '6.948', 'reg_alpha': '45.064', 'reg_lambda': '65.236', 'learning_rate': '0.056'}\n",
      "NRMSE Loss 1.95516 params {'n_estimators': 1150, 'max_depth': 47, 'num_leaves': 60, 'min_child_samples': 120, 'colsample_bytree': '0.694', 'subsample': '0.717', 'min_split_gain': '0.533', 'scale_pos_weight': '6.427', 'reg_alpha': '82.742', 'reg_lambda': '45.374', 'learning_rate': '0.011'}\n",
      "NRMSE Loss 1.93567 params {'n_estimators': 450, 'max_depth': 75, 'num_leaves': 70, 'min_child_samples': 50, 'colsample_bytree': '0.788', 'subsample': '0.949', 'min_split_gain': '0.162', 'scale_pos_weight': '5.934', 'reg_alpha': '1.526', 'reg_lambda': '70.520', 'learning_rate': '0.045'}\n",
      "NRMSE Loss 1.94863 params {'n_estimators': 950, 'max_depth': 44, 'num_leaves': 90, 'min_child_samples': 260, 'colsample_bytree': '0.748', 'subsample': '0.794', 'min_split_gain': '0.340', 'scale_pos_weight': '5.407', 'reg_alpha': '8.407', 'reg_lambda': '22.070', 'learning_rate': '0.125'}\n",
      "NRMSE Loss 1.96011 params {'n_estimators': 1050, 'max_depth': 49, 'num_leaves': 50, 'min_child_samples': 140, 'colsample_bytree': '0.854', 'subsample': '0.658', 'min_split_gain': '0.409', 'scale_pos_weight': '9.229', 'reg_alpha': '33.783', 'reg_lambda': '56.004', 'learning_rate': '0.454'}\n",
      "NRMSE Loss 1.95588 params {'n_estimators': 750, 'max_depth': 12, 'num_leaves': 60, 'min_child_samples': 210, 'colsample_bytree': '0.533', 'subsample': '0.594', 'min_split_gain': '0.220', 'scale_pos_weight': '9.762', 'reg_alpha': '93.720', 'reg_lambda': '51.486', 'learning_rate': '0.101'}\n",
      "NRMSE Loss 1.94780 params {'n_estimators': 200, 'max_depth': 8, 'num_leaves': 60, 'min_child_samples': 140, 'colsample_bytree': '0.830', 'subsample': '0.735', 'min_split_gain': '0.008', 'scale_pos_weight': '5.962', 'reg_alpha': '76.454', 'reg_lambda': '36.735', 'learning_rate': '0.050'}\n",
      "NRMSE Loss 1.93745 params {'n_estimators': 900, 'max_depth': 75, 'num_leaves': 50, 'min_child_samples': 190, 'colsample_bytree': '0.757', 'subsample': '0.405', 'min_split_gain': '0.017', 'scale_pos_weight': '8.855', 'reg_alpha': '15.020', 'reg_lambda': '30.290', 'learning_rate': '0.022'}\n",
      "NRMSE Loss 1.96097 params {'n_estimators': 700, 'max_depth': 59, 'num_leaves': 50, 'min_child_samples': 260, 'colsample_bytree': '0.450', 'subsample': '0.447', 'min_split_gain': '0.645', 'scale_pos_weight': '7.572', 'reg_alpha': '92.295', 'reg_lambda': '46.259', 'learning_rate': '0.318'}\n",
      "NRMSE Loss 1.93755 params {'n_estimators': 500, 'max_depth': 52, 'num_leaves': 90, 'min_child_samples': 90, 'colsample_bytree': '0.758', 'subsample': '0.705', 'min_split_gain': '0.281', 'scale_pos_weight': '2.045', 'reg_alpha': '3.613', 'reg_lambda': '92.924', 'learning_rate': '0.023'}\n",
      "NRMSE Loss 1.94789 params {'n_estimators': 550, 'max_depth': 31, 'num_leaves': 40, 'min_child_samples': 20, 'colsample_bytree': '0.375', 'subsample': '0.744', 'min_split_gain': '0.396', 'scale_pos_weight': '7.031', 'reg_alpha': '33.102', 'reg_lambda': '99.326', 'learning_rate': '0.049'}\n",
      "NRMSE Loss 1.95737 params {'n_estimators': 950, 'max_depth': 74, 'num_leaves': 60, 'min_child_samples': 90, 'colsample_bytree': '0.518', 'subsample': '0.775', 'min_split_gain': '0.203', 'scale_pos_weight': '8.605', 'reg_alpha': '73.138', 'reg_lambda': '64.505', 'learning_rate': '0.403'}\n",
      "NRMSE Loss 1.93993 params {'n_estimators': 1450, 'max_depth': 65, 'num_leaves': 40, 'min_child_samples': 110, 'colsample_bytree': '0.370', 'subsample': '0.407', 'min_split_gain': '0.125', 'scale_pos_weight': '5.457', 'reg_alpha': '7.912', 'reg_lambda': '32.531', 'learning_rate': '0.034'}\n",
      "NRMSE Loss 1.93875 params {'n_estimators': 1200, 'max_depth': 94, 'num_leaves': 70, 'min_child_samples': 190, 'colsample_bytree': '0.922', 'subsample': '0.322', 'min_split_gain': '0.016', 'scale_pos_weight': '2.858', 'reg_alpha': '20.418', 'reg_lambda': '9.278', 'learning_rate': '0.013'}\n",
      "NRMSE Loss 1.94538 params {'n_estimators': 350, 'max_depth': 93, 'num_leaves': 70, 'min_child_samples': 50, 'colsample_bytree': '0.984', 'subsample': '0.995', 'min_split_gain': '0.072', 'scale_pos_weight': '3.872', 'reg_alpha': '54.399', 'reg_lambda': '14.354', 'learning_rate': '0.026'}\n",
      "NRMSE Loss 1.95594 params {'n_estimators': 100, 'max_depth': 85, 'num_leaves': 80, 'min_child_samples': 210, 'colsample_bytree': '0.652', 'subsample': '0.337', 'min_split_gain': '0.077', 'scale_pos_weight': '9.944', 'reg_alpha': '15.412', 'reg_lambda': '77.702', 'learning_rate': '0.019'}\n",
      "NRMSE Loss 1.94430 params {'n_estimators': 850, 'max_depth': 83, 'num_leaves': 50, 'min_child_samples': 290, 'colsample_bytree': '0.813', 'subsample': '0.512', 'min_split_gain': '0.089', 'scale_pos_weight': '1.271', 'reg_alpha': '33.035', 'reg_lambda': '68.691', 'learning_rate': '0.016'}\n",
      "NRMSE Loss 1.94670 params {'n_estimators': 400, 'max_depth': 81, 'num_leaves': 80, 'min_child_samples': 60, 'colsample_bytree': '0.923', 'subsample': '0.975', 'min_split_gain': '0.142', 'scale_pos_weight': '7.938', 'reg_alpha': '53.530', 'reg_lambda': '87.585', 'learning_rate': '0.077'}\n",
      "NRMSE Loss 1.93784 params {'n_estimators': 700, 'max_depth': 100, 'num_leaves': 100, 'min_child_samples': 170, 'colsample_bytree': '0.623', 'subsample': '0.577', 'min_split_gain': '0.024', 'scale_pos_weight': '3.271', 'reg_alpha': '16.888', 'reg_lambda': '41.513', 'learning_rate': '0.028'}\n",
      "NRMSE Loss 1.94387 params {'n_estimators': 1050, 'max_depth': 75, 'num_leaves': 30, 'min_child_samples': 200, 'colsample_bytree': '0.609', 'subsample': '0.831', 'min_split_gain': '0.004', 'scale_pos_weight': '4.701', 'reg_alpha': '42.157', 'reg_lambda': '24.109', 'learning_rate': '0.010'}\n",
      "NRMSE Loss 1.94875 params {'n_estimators': 1250, 'max_depth': 91, 'num_leaves': 50, 'min_child_samples': 160, 'colsample_bytree': '0.895', 'subsample': '0.385', 'min_split_gain': '0.130', 'scale_pos_weight': '9.743', 'reg_alpha': '62.019', 'reg_lambda': '13.727', 'learning_rate': '0.074'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 1.94610 params {'n_estimators': 800, 'max_depth': 55, 'num_leaves': 30, 'min_child_samples': 230, 'colsample_bytree': '0.990', 'subsample': '0.485', 'min_split_gain': '0.273', 'scale_pos_weight': '4.416', 'reg_alpha': '26.844', 'reg_lambda': '56.196', 'learning_rate': '0.021'}\n",
      "NRMSE Loss 1.93983 params {'n_estimators': 450, 'max_depth': 100, 'num_leaves': 70, 'min_child_samples': 290, 'colsample_bytree': '0.683', 'subsample': '0.645', 'min_split_gain': '0.279', 'scale_pos_weight': '3.718', 'reg_alpha': '0.281', 'reg_lambda': '2.920', 'learning_rate': '0.034'}\n",
      "NRMSE Loss 1.94707 params {'n_estimators': 650, 'max_depth': 38, 'num_leaves': 100, 'min_child_samples': 60, 'colsample_bytree': '0.312', 'subsample': '0.953', 'min_split_gain': '0.473', 'scale_pos_weight': '7.720', 'reg_alpha': '13.503', 'reg_lambda': '71.472', 'learning_rate': '0.094'}\n",
      "NRMSE Loss 1.94970 params {'n_estimators': 200, 'max_depth': 69, 'num_leaves': 80, 'min_child_samples': 190, 'colsample_bytree': '0.804', 'subsample': '0.361', 'min_split_gain': '0.051', 'scale_pos_weight': '1.039', 'reg_alpha': '25.464', 'reg_lambda': '60.150', 'learning_rate': '0.225'}\n",
      "NRMSE Loss 1.93936 params {'n_estimators': 1050, 'max_depth': 86, 'num_leaves': 20, 'min_child_samples': 10, 'colsample_bytree': '0.585', 'subsample': '0.930', 'min_split_gain': '0.156', 'scale_pos_weight': '2.138', 'reg_alpha': '7.122', 'reg_lambda': '83.915', 'learning_rate': '0.064'}\n",
      "NRMSE Loss 1.93952 params {'n_estimators': 1300, 'max_depth': 60, 'num_leaves': 40, 'min_child_samples': 150, 'colsample_bytree': '0.770', 'subsample': '0.827', 'min_split_gain': '0.237', 'scale_pos_weight': '8.281', 'reg_alpha': '0.338', 'reg_lambda': '29.563', 'learning_rate': '0.039'}\n",
      "NRMSE Loss 1.95299 params {'n_estimators': 300, 'max_depth': 78, 'num_leaves': 20, 'min_child_samples': 260, 'colsample_bytree': '0.884', 'subsample': '0.864', 'min_split_gain': '0.113', 'scale_pos_weight': '5.878', 'reg_alpha': '39.566', 'reg_lambda': '18.733', 'learning_rate': '0.013'}\n",
      "NRMSE Loss 1.94469 params {'n_estimators': 100, 'max_depth': 69, 'num_leaves': 70, 'min_child_samples': 230, 'colsample_bytree': '0.714', 'subsample': '0.451', 'min_split_gain': '0.053', 'scale_pos_weight': '9.445', 'reg_alpha': '11.030', 'reg_lambda': '41.910', 'learning_rate': '0.203'}\n",
      "NRMSE Loss 1.94659 params {'n_estimators': 850, 'max_depth': 88, 'num_leaves': 50, 'min_child_samples': 170, 'colsample_bytree': '0.788', 'subsample': '0.570', 'min_split_gain': '0.579', 'scale_pos_weight': '7.373', 'reg_alpha': '20.855', 'reg_lambda': '73.950', 'learning_rate': '0.017'}\n",
      "NRMSE Loss 1.93658 params {'n_estimators': 600, 'max_depth': 70, 'num_leaves': 80, 'min_child_samples': 40, 'colsample_bytree': '0.960', 'subsample': '0.654', 'min_split_gain': '0.169', 'scale_pos_weight': '6.452', 'reg_alpha': '2.795', 'reg_lambda': '99.087', 'learning_rate': '0.043'}\n",
      "NRMSE Loss 1.94987 params {'n_estimators': 600, 'max_depth': 37, 'num_leaves': 100, 'min_child_samples': 40, 'colsample_bytree': '0.952', 'subsample': '0.897', 'min_split_gain': '0.302', 'scale_pos_weight': '6.562', 'reg_alpha': '60.212', 'reg_lambda': '96.633', 'learning_rate': '0.149'}\n",
      "NRMSE Loss 1.94267 params {'n_estimators': 450, 'max_depth': 20, 'num_leaves': 80, 'min_child_samples': 80, 'colsample_bytree': '0.859', 'subsample': '0.660', 'min_split_gain': '0.367', 'scale_pos_weight': '5.027', 'reg_alpha': '3.383', 'reg_lambda': '85.112', 'learning_rate': '0.104'}\n",
      "NRMSE Loss 1.94695 params {'n_estimators': 250, 'max_depth': 55, 'num_leaves': 90, 'min_child_samples': 20, 'colsample_bytree': '0.997', 'subsample': '0.632', 'min_split_gain': '0.695', 'scale_pos_weight': '6.648', 'reg_alpha': '27.562', 'reg_lambda': '92.488', 'learning_rate': '0.048'}\n",
      "NRMSE Loss 1.94922 params {'n_estimators': 600, 'max_depth': 70, 'num_leaves': 90, 'min_child_samples': 80, 'colsample_bytree': '0.959', 'subsample': '0.783', 'min_split_gain': '0.482', 'scale_pos_weight': '5.827', 'reg_alpha': '47.774', 'reg_lambda': '78.971', 'learning_rate': '0.062'}\n",
      "NRMSE Loss 1.94901 params {'n_estimators': 150, 'max_depth': 63, 'num_leaves': 80, 'min_child_samples': 120, 'colsample_bytree': '0.849', 'subsample': '0.926', 'min_split_gain': '0.183', 'scale_pos_weight': '5.169', 'reg_alpha': '39.000', 'reg_lambda': '99.637', 'learning_rate': '0.029'}\n",
      "NRMSE Loss 1.94641 params {'n_estimators': 300, 'max_depth': 42, 'num_leaves': 70, 'min_child_samples': 40, 'colsample_bytree': '0.713', 'subsample': '0.838', 'min_split_gain': '0.234', 'scale_pos_weight': '4.403', 'reg_alpha': '22.501', 'reg_lambda': '63.139', 'learning_rate': '0.182'}\n",
      "NRMSE Loss 1.94341 params {'n_estimators': 500, 'max_depth': 79, 'num_leaves': 90, 'min_child_samples': 20, 'colsample_bytree': '0.895', 'subsample': '0.688', 'min_split_gain': '0.318', 'scale_pos_weight': '6.289', 'reg_alpha': '4.910', 'reg_lambda': '81.969', 'learning_rate': '0.125'}\n",
      "NRMSE Loss 1.95054 params {'n_estimators': 750, 'max_depth': 97, 'num_leaves': 60, 'min_child_samples': 60, 'colsample_bytree': '0.674', 'subsample': '0.533', 'min_split_gain': '0.365', 'scale_pos_weight': '7.103', 'reg_alpha': '65.428', 'reg_lambda': '52.594', 'learning_rate': '0.081'}\n",
      "NRMSE Loss 1.94197 params {'n_estimators': 400, 'max_depth': 50, 'num_leaves': 80, 'min_child_samples': 130, 'colsample_bytree': '0.458', 'subsample': '0.603', 'min_split_gain': '0.254', 'scale_pos_weight': '6.154', 'reg_alpha': '10.779', 'reg_lambda': '92.443', 'learning_rate': '0.045'}\n",
      "NRMSE Loss 1.95278 params {'n_estimators': 600, 'max_depth': 58, 'num_leaves': 100, 'min_child_samples': 100, 'colsample_bytree': '0.563', 'subsample': '0.998', 'min_split_gain': '0.178', 'scale_pos_weight': '8.106', 'reg_alpha': '83.801', 'reg_lambda': '71.384', 'learning_rate': '0.056'}\n",
      "NRMSE Loss 1.94150 params {'n_estimators': 700, 'max_depth': 72, 'num_leaves': 70, 'min_child_samples': 70, 'colsample_bytree': '0.964', 'subsample': '0.618', 'min_split_gain': '0.103', 'scale_pos_weight': '5.571', 'reg_alpha': '29.542', 'reg_lambda': '60.563', 'learning_rate': '0.034'}\n",
      "NRMSE Loss 1.94241 params {'n_estimators': 500, 'max_depth': 63, 'num_leaves': 60, 'min_child_samples': 10, 'colsample_bytree': '0.733', 'subsample': '0.880', 'min_split_gain': '0.419', 'scale_pos_weight': '2.904', 'reg_alpha': '18.676', 'reg_lambda': '87.869', 'learning_rate': '0.026'}\n",
      "NRMSE Loss 1.95293 params {'n_estimators': 950, 'max_depth': 90, 'num_leaves': 90, 'min_child_samples': 40, 'colsample_bytree': '0.931', 'subsample': '0.749', 'min_split_gain': '0.210', 'scale_pos_weight': '8.652', 'reg_alpha': '99.301', 'reg_lambda': '96.279', 'learning_rate': '0.091'}\n",
      "NRMSE Loss 1.94427 params {'n_estimators': 1100, 'max_depth': 46, 'num_leaves': 70, 'min_child_samples': 30, 'colsample_bytree': '0.496', 'subsample': '0.678', 'min_split_gain': '0.339', 'scale_pos_weight': '3.490', 'reg_alpha': '0.599', 'reg_lambda': '81.139', 'learning_rate': '0.119'}\n",
      "NRMSE Loss 1.94122 params {'n_estimators': 800, 'max_depth': 22, 'num_leaves': 80, 'min_child_samples': 100, 'colsample_bytree': '0.832', 'subsample': '0.548', 'min_split_gain': '0.149', 'scale_pos_weight': '6.816', 'reg_alpha': '11.896', 'reg_lambda': '66.998', 'learning_rate': '0.056'}\n",
      "NRMSE Loss 1.95313 params {'n_estimators': 650, 'max_depth': 27, 'num_leaves': 60, 'min_child_samples': 80, 'colsample_bytree': '0.654', 'subsample': '0.813', 'min_split_gain': '0.458', 'scale_pos_weight': '4.189', 'reg_alpha': '37.906', 'reg_lambda': '74.885', 'learning_rate': '0.274'}\n",
      "NRMSE Loss 1.94387 params {'n_estimators': 350, 'max_depth': 81, 'num_leaves': 70, 'min_child_samples': 140, 'colsample_bytree': '0.789', 'subsample': '0.447', 'min_split_gain': '0.042', 'scale_pos_weight': '4.737', 'reg_alpha': '48.155', 'reg_lambda': '50.289', 'learning_rate': '0.041'}\n",
      "NRMSE Loss 1.95284 params {'n_estimators': 550, 'max_depth': 66, 'num_leaves': 90, 'min_child_samples': 50, 'colsample_bytree': '0.877', 'subsample': '0.768', 'min_split_gain': '0.519', 'scale_pos_weight': '7.276', 'reg_alpha': '79.147', 'reg_lambda': '45.623', 'learning_rate': '0.024'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 1.95622 params {'n_estimators': 200, 'max_depth': 53, 'num_leaves': 100, 'min_child_samples': 110, 'colsample_bytree': '0.737', 'subsample': '0.477', 'min_split_gain': '0.171', 'scale_pos_weight': '5.243', 'reg_alpha': '52.753', 'reg_lambda': '36.577', 'learning_rate': '0.013'}\n",
      "NRMSE Loss 1.94556 params {'n_estimators': 900, 'max_depth': 96, 'num_leaves': 50, 'min_child_samples': 70, 'colsample_bytree': '0.827', 'subsample': '0.859', 'min_split_gain': '0.390', 'scale_pos_weight': '5.551', 'reg_alpha': '32.014', 'reg_lambda': '57.213', 'learning_rate': '0.032'}\n",
      "NRMSE Loss 1.94418 params {'n_estimators': 750, 'max_depth': 75, 'num_leaves': 90, 'min_child_samples': 130, 'colsample_bytree': '0.927', 'subsample': '0.970', 'min_split_gain': '0.301', 'scale_pos_weight': '2.202', 'reg_alpha': '23.902', 'reg_lambda': '95.999', 'learning_rate': '0.015'}\n",
      "NRMSE Loss 1.95405 params {'n_estimators': 400, 'max_depth': 41, 'num_leaves': 80, 'min_child_samples': 30, 'colsample_bytree': '0.616', 'subsample': '0.308', 'min_split_gain': '0.258', 'scale_pos_weight': '7.584', 'reg_alpha': '93.656', 'reg_lambda': '68.916', 'learning_rate': '0.020'}\n",
      "NRMSE Loss 1.94310 params {'n_estimators': 1000, 'max_depth': 32, 'num_leaves': 40, 'min_child_samples': 100, 'colsample_bytree': '0.771', 'subsample': '0.711', 'min_split_gain': '0.093', 'scale_pos_weight': '8.296', 'reg_alpha': '7.720', 'reg_lambda': '89.179', 'learning_rate': '0.107'}\n",
      "NRMSE Loss 1.95277 params {'n_estimators': 300, 'max_depth': 60, 'num_leaves': 60, 'min_child_samples': 50, 'colsample_bytree': '0.323', 'subsample': '0.913', 'min_split_gain': '0.208', 'scale_pos_weight': '9.299', 'reg_alpha': '70.910', 'reg_lambda': '79.339', 'learning_rate': '0.063'}\n",
      "NRMSE Loss 1.94091 params {'n_estimators': 650, 'max_depth': 84, 'num_leaves': 70, 'min_child_samples': 180, 'colsample_bytree': '0.905', 'subsample': '0.509', 'min_split_gain': '0.067', 'scale_pos_weight': '1.471', 'reg_alpha': '18.438', 'reg_lambda': '41.081', 'learning_rate': '0.011'}\n",
      "NRMSE Loss 1.95016 params {'n_estimators': 1400, 'max_depth': 66, 'num_leaves': 30, 'min_child_samples': 150, 'colsample_bytree': '0.971', 'subsample': '0.799', 'min_split_gain': '0.033', 'scale_pos_weight': '6.083', 'reg_alpha': '89.385', 'reg_lambda': '61.671', 'learning_rate': '0.087'}\n",
      "NRMSE Loss 1.96319 params {'n_estimators': 250, 'max_depth': 78, 'num_leaves': 80, 'min_child_samples': 120, 'colsample_bytree': '0.638', 'subsample': '0.949', 'min_split_gain': '0.130', 'scale_pos_weight': '6.761', 'reg_alpha': '43.741', 'reg_lambda': '54.417', 'learning_rate': '0.486'}\n",
      "NRMSE Loss 1.93860 params {'n_estimators': 1150, 'max_depth': 73, 'num_leaves': 50, 'min_child_samples': 210, 'colsample_bytree': '0.862', 'subsample': '0.404', 'min_split_gain': '0.017', 'scale_pos_weight': '8.980', 'reg_alpha': '4.923', 'reg_lambda': '28.628', 'learning_rate': '0.021'}\n",
      "NRMSE Loss 1.95076 params {'n_estimators': 850, 'max_depth': 3, 'num_leaves': 50, 'min_child_samples': 270, 'colsample_bytree': '0.699', 'subsample': '0.340', 'min_split_gain': '0.001', 'scale_pos_weight': '7.814', 'reg_alpha': '13.582', 'reg_lambda': '20.441', 'learning_rate': '0.016'}\n",
      "NRMSE Loss 1.94248 params {'n_estimators': 900, 'max_depth': 77, 'num_leaves': 60, 'min_child_samples': 230, 'colsample_bytree': '0.580', 'subsample': '0.386', 'min_split_gain': '0.154', 'scale_pos_weight': '8.560', 'reg_alpha': '14.951', 'reg_lambda': '4.776', 'learning_rate': '0.042'}\n",
      "NRMSE Loss 1.93925 params {'n_estimators': 450, 'max_depth': 89, 'num_leaves': 40, 'min_child_samples': 220, 'colsample_bytree': '0.668', 'subsample': '0.426', 'min_split_gain': '0.072', 'scale_pos_weight': '8.869', 'reg_alpha': '9.163', 'reg_lambda': '39.244', 'learning_rate': '0.029'}\n",
      "NRMSE Loss 1.93952 params {'n_estimators': 750, 'max_depth': 82, 'num_leaves': 40, 'min_child_samples': 250, 'colsample_bytree': '0.756', 'subsample': '0.569', 'min_split_gain': '0.197', 'scale_pos_weight': '6.478', 'reg_alpha': '1.958', 'reg_lambda': '16.472', 'learning_rate': '0.037'}\n",
      "NRMSE Loss 1.94522 params {'n_estimators': 1000, 'max_depth': 87, 'num_leaves': 30, 'min_child_samples': 160, 'colsample_bytree': '0.821', 'subsample': '0.484', 'min_split_gain': '0.121', 'scale_pos_weight': '9.901', 'reg_alpha': '34.729', 'reg_lambda': '32.792', 'learning_rate': '0.070'}\n",
      "NRMSE Loss 1.93972 params {'n_estimators': 550, 'max_depth': 57, 'num_leaves': 70, 'min_child_samples': 190, 'colsample_bytree': '0.805', 'subsample': '0.757', 'min_split_gain': '0.088', 'scale_pos_weight': '5.771', 'reg_alpha': '17.620', 'reg_lambda': '9.603', 'learning_rate': '0.023'}\n",
      "NRMSE Loss 1.94274 params {'n_estimators': 700, 'max_depth': 93, 'num_leaves': 60, 'min_child_samples': 280, 'colsample_bytree': '0.779', 'subsample': '0.725', 'min_split_gain': '0.296', 'scale_pos_weight': '7.426', 'reg_alpha': '5.680', 'reg_lambda': '32.409', 'learning_rate': '0.052'}\n",
      "NRMSE Loss 1.94909 params {'n_estimators': 1200, 'max_depth': 68, 'num_leaves': 50, 'min_child_samples': 180, 'colsample_bytree': '0.938', 'subsample': '0.540', 'min_split_gain': '0.231', 'scale_pos_weight': '9.586', 'reg_alpha': '58.460', 'reg_lambda': '25.685', 'learning_rate': '0.036'}\n",
      "NRMSE Loss 1.95771 params {'n_estimators': 150, 'max_depth': 63, 'num_leaves': 70, 'min_child_samples': 220, 'colsample_bytree': '0.730', 'subsample': '0.589', 'min_split_gain': '0.165', 'scale_pos_weight': '4.905', 'reg_alpha': '21.773', 'reg_lambda': '47.700', 'learning_rate': '0.012'}\n",
      "NRMSE Loss 1.94173 params {'n_estimators': 1500, 'max_depth': 72, 'num_leaves': 60, 'min_child_samples': 200, 'colsample_bytree': '0.592', 'subsample': '0.692', 'min_split_gain': '0.055', 'scale_pos_weight': '6.964', 'reg_alpha': '30.502', 'reg_lambda': '23.945', 'learning_rate': '0.015'}\n",
      "NRMSE Loss 1.94617 params {'n_estimators': 1100, 'max_depth': 80, 'num_leaves': 80, 'min_child_samples': 250, 'colsample_bytree': '0.695', 'subsample': '0.364', 'min_split_gain': '0.247', 'scale_pos_weight': '4.037', 'reg_alpha': '35.295', 'reg_lambda': '58.450', 'learning_rate': '0.018'}\n",
      "NRMSE Loss 1.93884 params {'n_estimators': 550, 'max_depth': 47, 'num_leaves': 50, 'min_child_samples': 90, 'colsample_bytree': '0.840', 'subsample': '0.468', 'min_split_gain': '0.324', 'scale_pos_weight': '4.489', 'reg_alpha': '2.213', 'reg_lambda': '28.847', 'learning_rate': '0.045'}\n",
      "NRMSE Loss 1.93869 params {'n_estimators': 1000, 'max_depth': 76, 'num_leaves': 40, 'min_child_samples': 160, 'colsample_bytree': '0.902', 'subsample': '0.300', 'min_split_gain': '0.000', 'scale_pos_weight': '2.931', 'reg_alpha': '24.638', 'reg_lambda': '10.790', 'learning_rate': '0.026'}\n",
      "NRMSE Loss 1.94297 params {'n_estimators': 800, 'max_depth': 85, 'num_leaves': 80, 'min_child_samples': 130, 'colsample_bytree': '0.869', 'subsample': '0.512', 'min_split_gain': '0.109', 'scale_pos_weight': '7.990', 'reg_alpha': '9.802', 'reg_lambda': '5.230', 'learning_rate': '0.071'}\n",
      "NRMSE Loss 1.94215 params {'n_estimators': 1300, 'max_depth': 71, 'num_leaves': 70, 'min_child_samples': 70, 'colsample_bytree': '0.547', 'subsample': '0.620', 'min_split_gain': '0.131', 'scale_pos_weight': '6.329', 'reg_alpha': '27.469', 'reg_lambda': '43.706', 'learning_rate': '0.032'}\n",
      "NRMSE Loss 1.95081 params {'n_estimators': 650, 'max_depth': 98, 'num_leaves': 100, 'min_child_samples': 180, 'colsample_bytree': '0.492', 'subsample': '0.652', 'min_split_gain': '0.276', 'scale_pos_weight': '5.337', 'reg_alpha': '14.988', 'reg_lambda': '48.175', 'learning_rate': '0.167'}\n",
      "NRMSE Loss 1.94029 params {'n_estimators': 900, 'max_depth': 52, 'num_leaves': 30, 'min_child_samples': 10, 'colsample_bytree': '0.751', 'subsample': '0.848', 'min_split_gain': '0.590', 'scale_pos_weight': '9.011', 'reg_alpha': '0.151', 'reg_lambda': '34.112', 'learning_rate': '0.022'}\n",
      "NRMSE Loss 1.94193 params {'n_estimators': 450, 'max_depth': 62, 'num_leaves': 20, 'min_child_samples': 20, 'colsample_bytree': '0.797', 'subsample': '0.430', 'min_split_gain': '0.364', 'scale_pos_weight': '2.493', 'reg_alpha': '7.540', 'reg_lambda': '53.241', 'learning_rate': '0.048'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 1.94296 params {'n_estimators': 700, 'max_depth': 54, 'num_leaves': 50, 'min_child_samples': 200, 'colsample_bytree': '0.716', 'subsample': '0.340', 'min_split_gain': '0.190', 'scale_pos_weight': '8.413', 'reg_alpha': '19.972', 'reg_lambda': '72.227', 'learning_rate': '0.053'}\n",
      "NRMSE Loss 1.93964 params {'n_estimators': 350, 'max_depth': 95, 'num_leaves': 90, 'min_child_samples': 170, 'colsample_bytree': '0.987', 'subsample': '0.671', 'min_split_gain': '0.031', 'scale_pos_weight': '7.174', 'reg_alpha': '12.984', 'reg_lambda': '64.856', 'learning_rate': '0.067'}\n",
      "NRMSE Loss 1.95094 params {'n_estimators': 850, 'max_depth': 92, 'num_leaves': 60, 'min_child_samples': 240, 'colsample_bytree': '0.419', 'subsample': '0.812', 'min_split_gain': '0.226', 'scale_pos_weight': '3.318', 'reg_alpha': '41.932', 'reg_lambda': '85.430', 'learning_rate': '0.138'}\n",
      "NRMSE Loss 1.94846 params {'n_estimators': 500, 'max_depth': 68, 'num_leaves': 70, 'min_child_samples': 140, 'colsample_bytree': '0.947', 'subsample': '0.734', 'min_split_gain': '0.091', 'scale_pos_weight': '3.730', 'reg_alpha': '65.994', 'reg_lambda': '38.084', 'learning_rate': '0.078'}\n",
      "NRMSE Loss 1.94179 params {'n_estimators': 950, 'max_depth': 49, 'num_leaves': 80, 'min_child_samples': 60, 'colsample_bytree': '0.632', 'subsample': '0.893', 'min_split_gain': '0.390', 'scale_pos_weight': '5.633', 'reg_alpha': '4.052', 'reg_lambda': '0.930', 'learning_rate': '0.059'}\n",
      "NRMSE Loss 1.94590 params {'n_estimators': 600, 'max_depth': 56, 'num_leaves': 70, 'min_child_samples': 30, 'colsample_bytree': '0.815', 'subsample': '0.555', 'min_split_gain': '0.432', 'scale_pos_weight': '6.046', 'reg_alpha': '37.753', 'reg_lambda': '90.028', 'learning_rate': '0.028'}\n",
      "NRMSE Loss 1.94245 params {'n_estimators': 400, 'max_depth': 61, 'num_leaves': 40, 'min_child_samples': 110, 'colsample_bytree': '0.848', 'subsample': '0.973', 'min_split_gain': '0.148', 'scale_pos_weight': '5.027', 'reg_alpha': '16.402', 'reg_lambda': '77.168', 'learning_rate': '0.113'}\n",
      "NRMSE Loss 1.94184 params {'n_estimators': 750, 'max_depth': 100, 'num_leaves': 90, 'min_child_samples': 150, 'colsample_bytree': '0.918', 'subsample': '0.403', 'min_split_gain': '0.056', 'scale_pos_weight': '7.620', 'reg_alpha': '28.935', 'reg_lambda': '99.870', 'learning_rate': '0.014'}\n",
      "NRMSE Loss 1.95512 params {'n_estimators': 450, 'max_depth': 65, 'num_leaves': 60, 'min_child_samples': 80, 'colsample_bytree': '0.663', 'subsample': '0.604', 'min_split_gain': '0.266', 'scale_pos_weight': '4.608', 'reg_alpha': '97.483', 'reg_lambda': '67.519', 'learning_rate': '0.019'}\n",
      "NRMSE Loss 1.94153 params {'n_estimators': 800, 'max_depth': 74, 'num_leaves': 80, 'min_child_samples': 40, 'colsample_bytree': '0.887', 'subsample': '0.497', 'min_split_gain': '0.166', 'scale_pos_weight': '6.692', 'reg_alpha': '6.373', 'reg_lambda': '94.345', 'learning_rate': '0.095'}\n",
      "NRMSE Loss 1.95136 params {'n_estimators': 500, 'max_depth': 16, 'num_leaves': 60, 'min_child_samples': 300, 'colsample_bytree': '0.596', 'subsample': '0.635', 'min_split_gain': '0.350', 'scale_pos_weight': '4.165', 'reg_alpha': '46.648', 'reg_lambda': '15.024', 'learning_rate': '0.017'}\n",
      "NRMSE Loss 1.95019 params {'n_estimators': 300, 'max_depth': 39, 'num_leaves': 50, 'min_child_samples': 220, 'colsample_bytree': '0.973', 'subsample': '0.314', 'min_split_gain': '0.289', 'scale_pos_weight': '1.732', 'reg_alpha': '50.204', 'reg_lambda': '50.874', 'learning_rate': '0.031'}\n",
      "NRMSE Loss 1.94564 params {'n_estimators': 600, 'max_depth': 59, 'num_leaves': 100, 'min_child_samples': 90, 'colsample_bytree': '0.769', 'subsample': '0.457', 'min_split_gain': '0.525', 'scale_pos_weight': '6.907', 'reg_alpha': '26.035', 'reg_lambda': '19.802', 'learning_rate': '0.040'}\n",
      "NRMSE Loss 1.94752 params {'n_estimators': 1100, 'max_depth': 83, 'num_leaves': 80, 'min_child_samples': 100, 'colsample_bytree': '0.683', 'subsample': '0.877', 'min_split_gain': '0.184', 'scale_pos_weight': '8.075', 'reg_alpha': '56.493', 'reg_lambda': '43.922', 'learning_rate': '0.045'}\n",
      "NRMSE Loss 1.94480 params {'n_estimators': 100, 'max_depth': 44, 'num_leaves': 70, 'min_child_samples': 120, 'colsample_bytree': '0.911', 'subsample': '0.525', 'min_split_gain': '0.209', 'scale_pos_weight': '7.806', 'reg_alpha': '11.205', 'reg_lambda': '82.314', 'learning_rate': '0.037'}\n",
      "NRMSE Loss 1.94628 params {'n_estimators': 650, 'max_depth': 79, 'num_leaves': 90, 'min_child_samples': 50, 'colsample_bytree': '0.710', 'subsample': '0.702', 'min_split_gain': '0.681', 'scale_pos_weight': '9.260', 'reg_alpha': '23.015', 'reg_lambda': '63.017', 'learning_rate': '0.012'}\n",
      "NRMSE Loss 1.93935 params {'n_estimators': 250, 'max_depth': 33, 'num_leaves': 50, 'min_child_samples': 20, 'colsample_bytree': '0.646', 'subsample': '0.364', 'min_split_gain': '0.317', 'scale_pos_weight': '6.209', 'reg_alpha': '2.810', 'reg_lambda': '22.415', 'learning_rate': '0.023'}\n",
      "NRMSE Loss 1.95293 params {'n_estimators': 150, 'max_depth': 70, 'num_leaves': 40, 'min_child_samples': 190, 'colsample_bytree': '0.523', 'subsample': '0.937', 'min_split_gain': '0.136', 'scale_pos_weight': '7.450', 'reg_alpha': '19.671', 'reg_lambda': '90.660', 'learning_rate': '0.341'}\n",
      "NRMSE Loss 1.95038 params {'n_estimators': 400, 'max_depth': 50, 'num_leaves': 60, 'min_child_samples': 210, 'colsample_bytree': '0.566', 'subsample': '0.785', 'min_split_gain': '0.013', 'scale_pos_weight': '9.985', 'reg_alpha': '80.152', 'reg_lambda': '30.638', 'learning_rate': '0.026'}\n",
      "NRMSE Loss 1.93802 params {'n_estimators': 1050, 'max_depth': 88, 'num_leaves': 70, 'min_child_samples': 170, 'colsample_bytree': '0.873', 'subsample': '0.380', 'min_split_gain': '0.113', 'scale_pos_weight': '8.710', 'reg_alpha': '9.728', 'reg_lambda': '70.038', 'learning_rate': '0.021'}\n",
      "NRMSE Loss 1.94339 params {'n_estimators': 550, 'max_depth': 91, 'num_leaves': 20, 'min_child_samples': 250, 'colsample_bytree': '0.733', 'subsample': '0.326', 'min_split_gain': '0.040', 'scale_pos_weight': '5.892', 'reg_alpha': '0.331', 'reg_lambda': '58.751', 'learning_rate': '0.083'}\n",
      "NRMSE Loss 1.95475 params {'n_estimators': 1450, 'max_depth': 35, 'num_leaves': 90, 'min_child_samples': 130, 'colsample_bytree': '0.846', 'subsample': '0.563', 'min_split_gain': '0.082', 'scale_pos_weight': '6.402', 'reg_alpha': '14.885', 'reg_lambda': '86.408', 'learning_rate': '0.243'}\n",
      "NRMSE Loss 1.94087 params {'n_estimators': 1150, 'max_depth': 76, 'num_leaves': 70, 'min_child_samples': 270, 'colsample_bytree': '0.787', 'subsample': '0.909', 'min_split_gain': '0.064', 'scale_pos_weight': '9.546', 'reg_alpha': '12.917', 'reg_lambda': '12.337', 'learning_rate': '0.034'}\n",
      "NRMSE Loss 1.94487 params {'n_estimators': 850, 'max_depth': 67, 'num_leaves': 80, 'min_child_samples': 60, 'colsample_bytree': '0.999', 'subsample': '0.996', 'min_split_gain': '0.097', 'scale_pos_weight': '6.601', 'reg_alpha': '50.555', 'reg_lambda': '7.429', 'learning_rate': '0.014'}\n",
      "NRMSE Loss 1.94576 params {'n_estimators': 350, 'max_depth': 64, 'num_leaves': 30, 'min_child_samples': 70, 'colsample_bytree': '0.617', 'subsample': '0.587', 'min_split_gain': '0.218', 'scale_pos_weight': '5.432', 'reg_alpha': '32.362', 'reg_lambda': '27.051', 'learning_rate': '0.030'}\n",
      "NRMSE Loss 1.94652 params {'n_estimators': 1250, 'max_depth': 86, 'num_leaves': 50, 'min_child_samples': 30, 'colsample_bytree': '0.834', 'subsample': '0.761', 'min_split_gain': '0.490', 'scale_pos_weight': '7.265', 'reg_alpha': '35.500', 'reg_lambda': '98.223', 'learning_rate': '0.061'}\n",
      "NRMSE Loss 1.95067 params {'n_estimators': 500, 'max_depth': 98, 'num_leaves': 60, 'min_child_samples': 140, 'colsample_bytree': '0.333', 'subsample': '0.433', 'min_split_gain': '0.021', 'scale_pos_weight': '5.679', 'reg_alpha': '75.527', 'reg_lambda': '55.198', 'learning_rate': '0.101'}\n",
      "NRMSE Loss 1.94189 params {'n_estimators': 700, 'max_depth': 81, 'num_leaves': 40, 'min_child_samples': 80, 'colsample_bytree': '0.746', 'subsample': '0.497', 'min_split_gain': '0.241', 'scale_pos_weight': '4.328', 'reg_alpha': '17.059', 'reg_lambda': '73.799', 'learning_rate': '0.056'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 1.94437 params {'n_estimators': 750, 'max_depth': 73, 'num_leaves': 90, 'min_child_samples': 10, 'colsample_bytree': '0.767', 'subsample': '0.666', 'min_split_gain': '0.262', 'scale_pos_weight': '9.755', 'reg_alpha': '41.195', 'reg_lambda': '34.372', 'learning_rate': '0.010'}\n",
      "NRMSE Loss 1.95020 params {'n_estimators': 900, 'max_depth': 58, 'num_leaves': 100, 'min_child_samples': 160, 'colsample_bytree': '0.470', 'subsample': '0.823', 'min_split_gain': '0.409', 'scale_pos_weight': '5.103', 'reg_alpha': '44.457', 'reg_lambda': '17.190', 'learning_rate': '0.043'}\n",
      "NRMSE Loss 1.94349 params {'n_estimators': 600, 'max_depth': 28, 'num_leaves': 60, 'min_child_samples': 110, 'colsample_bytree': '0.679', 'subsample': '0.958', 'min_split_gain': '0.454', 'scale_pos_weight': '8.419', 'reg_alpha': '6.954', 'reg_lambda': '40.022', 'learning_rate': '0.074'}\n",
      "NRMSE Loss 1.94537 params {'n_estimators': 250, 'max_depth': 84, 'num_leaves': 80, 'min_child_samples': 240, 'colsample_bytree': '0.809', 'subsample': '0.851', 'min_split_gain': '0.175', 'scale_pos_weight': '2.614', 'reg_alpha': '21.373', 'reg_lambda': '80.109', 'learning_rate': '0.022'}\n",
      "NRMSE Loss 1.93842 params {'n_estimators': 800, 'max_depth': 45, 'num_leaves': 70, 'min_child_samples': 50, 'colsample_bytree': '0.940', 'subsample': '0.684', 'min_split_gain': '0.119', 'scale_pos_weight': '9.100', 'reg_alpha': '0.063', 'reg_lambda': '43.809', 'learning_rate': '0.050'}\n",
      "NRMSE Loss 1.94814 params {'n_estimators': 950, 'max_depth': 78, 'num_leaves': 80, 'min_child_samples': 40, 'colsample_bytree': '0.893', 'subsample': '0.620', 'min_split_gain': '0.197', 'scale_pos_weight': '4.817', 'reg_alpha': '4.338', 'reg_lambda': '76.651', 'learning_rate': '0.184'}\n",
      "NRMSE Loss 1.94342 params {'n_estimators': 1000, 'max_depth': 70, 'num_leaves': 50, 'min_child_samples': 150, 'colsample_bytree': '0.862', 'subsample': '0.922', 'min_split_gain': '0.000', 'scale_pos_weight': '8.790', 'reg_alpha': '61.440', 'reg_lambda': '47.334', 'learning_rate': '0.024'}\n",
      "NRMSE Loss 1.95113 params {'n_estimators': 200, 'max_depth': 94, 'num_leaves': 60, 'min_child_samples': 200, 'colsample_bytree': '0.795', 'subsample': '0.888', 'min_split_gain': '0.073', 'scale_pos_weight': '4.014', 'reg_alpha': '30.735', 'reg_lambda': '66.326', 'learning_rate': '0.016'}\n",
      "NRMSE Loss 1.95456 params {'n_estimators': 700, 'max_depth': 89, 'num_leaves': 50, 'min_child_samples': 180, 'colsample_bytree': '0.957', 'subsample': '0.796', 'min_split_gain': '0.636', 'scale_pos_weight': '8.182', 'reg_alpha': '64.553', 'reg_lambda': '48.953', 'learning_rate': '0.138'}\n",
      "NRMSE Loss 1.93905 params {'n_estimators': 1200, 'max_depth': 65, 'num_leaves': 70, 'min_child_samples': 230, 'colsample_bytree': '0.704', 'subsample': '0.718', 'min_split_gain': '0.160', 'scale_pos_weight': '3.557', 'reg_alpha': '8.401', 'reg_lambda': '82.659', 'learning_rate': '0.018'}\n",
      "NRMSE Loss 1.95397 params {'n_estimators': 850, 'max_depth': 55, 'num_leaves': 100, 'min_child_samples': 100, 'colsample_bytree': '0.427', 'subsample': '0.736', 'min_split_gain': '0.141', 'scale_pos_weight': '7.099', 'reg_alpha': '86.607', 'reg_lambda': '36.687', 'learning_rate': '0.011'}\n",
      "NRMSE Loss 1.93978 params {'n_estimators': 550, 'max_depth': 48, 'num_leaves': 70, 'min_child_samples': 120, 'colsample_bytree': '0.727', 'subsample': '0.412', 'min_split_gain': '0.045', 'scale_pos_weight': '7.931', 'reg_alpha': '24.580', 'reg_lambda': '93.530', 'learning_rate': '0.038'}\n",
      "NRMSE Loss 1.96350 params {'n_estimators': 650, 'max_depth': 51, 'num_leaves': 30, 'min_child_samples': 20, 'colsample_bytree': '0.506', 'subsample': '0.350', 'min_split_gain': '0.354', 'scale_pos_weight': '6.839', 'reg_alpha': '11.095', 'reg_lambda': '24.457', 'learning_rate': '0.422'}\n",
      "NRMSE Loss 1.94594 params {'n_estimators': 450, 'max_depth': 8, 'num_leaves': 40, 'min_child_samples': 90, 'colsample_bytree': '0.545', 'subsample': '0.529', 'min_split_gain': '0.311', 'scale_pos_weight': '5.985', 'reg_alpha': '28.199', 'reg_lambda': '53.250', 'learning_rate': '0.034'}\n",
      "NRMSE Loss 1.95471 params {'n_estimators': 300, 'max_depth': 61, 'num_leaves': 80, 'min_child_samples': 190, 'colsample_bytree': '0.821', 'subsample': '0.866', 'min_split_gain': '0.584', 'scale_pos_weight': '3.161', 'reg_alpha': '69.465', 'reg_lambda': '57.101', 'learning_rate': '0.029'}\n",
      "NRMSE Loss 1.94237 params {'n_estimators': 1350, 'max_depth': 75, 'num_leaves': 80, 'min_child_samples': 70, 'colsample_bytree': '0.928', 'subsample': '0.986', 'min_split_gain': '0.328', 'scale_pos_weight': '8.487', 'reg_alpha': '1.952', 'reg_lambda': '61.484', 'learning_rate': '0.065'}\n",
      "NRMSE Loss 1.94694 params {'n_estimators': 900, 'max_depth': 41, 'num_leaves': 60, 'min_child_samples': 130, 'colsample_bytree': '0.755', 'subsample': '0.645', 'min_split_gain': '0.248', 'scale_pos_weight': '4.643', 'reg_alpha': '5.684', 'reg_lambda': '97.633', 'learning_rate': '0.153'}\n",
      "NRMSE Loss 1.94470 params {'n_estimators': 950, 'max_depth': 72, 'num_leaves': 60, 'min_child_samples': 210, 'colsample_bytree': '0.983', 'subsample': '0.384', 'min_split_gain': '0.287', 'scale_pos_weight': '5.345', 'reg_alpha': '17.684', 'reg_lambda': '87.693', 'learning_rate': '0.047'}\n",
      "NRMSE Loss 1.94348 params {'n_estimators': 750, 'max_depth': 82, 'num_leaves': 90, 'min_child_samples': 110, 'colsample_bytree': '0.654', 'subsample': '0.468', 'min_split_gain': '0.500', 'scale_pos_weight': '7.631', 'reg_alpha': '13.711', 'reg_lambda': '72.966', 'learning_rate': '0.013'}\n",
      "NRMSE Loss 1.94667 params {'n_estimators': 350, 'max_depth': 53, 'num_leaves': 70, 'min_child_samples': 290, 'colsample_bytree': '0.633', 'subsample': '0.549', 'min_split_gain': '0.381', 'scale_pos_weight': '9.408', 'reg_alpha': '22.562', 'reg_lambda': '75.403', 'learning_rate': '0.053'}\n",
      "NRMSE Loss 1.94383 params {'n_estimators': 600, 'max_depth': 80, 'num_leaves': 20, 'min_child_samples': 30, 'colsample_bytree': '0.395', 'subsample': '0.778', 'min_split_gain': '0.104', 'scale_pos_weight': '3.875', 'reg_alpha': '26.145', 'reg_lambda': '21.569', 'learning_rate': '0.040'}\n",
      "NRMSE Loss 1.94725 params {'n_estimators': 1050, 'max_depth': 67, 'num_leaves': 50, 'min_child_samples': 60, 'colsample_bytree': '0.778', 'subsample': '0.837', 'min_split_gain': '0.551', 'scale_pos_weight': '4.904', 'reg_alpha': '36.355', 'reg_lambda': '31.508', 'learning_rate': '0.027'}\n",
      "NRMSE Loss 1.94376 params {'n_estimators': 150, 'max_depth': 86, 'num_leaves': 70, 'min_child_samples': 220, 'colsample_bytree': '0.603', 'subsample': '0.604', 'min_split_gain': '0.220', 'scale_pos_weight': '7.403', 'reg_alpha': '3.227', 'reg_lambda': '27.193', 'learning_rate': '0.025'}\n",
      "NRMSE Loss 1.94496 params {'n_estimators': 700, 'max_depth': 90, 'num_leaves': 80, 'min_child_samples': 270, 'colsample_bytree': '0.567', 'subsample': '0.695', 'min_split_gain': '0.028', 'scale_pos_weight': '1.069', 'reg_alpha': '19.030', 'reg_lambda': '34.554', 'learning_rate': '0.086'}\n",
      "NRMSE Loss 1.94920 params {'n_estimators': 550, 'max_depth': 69, 'num_leaves': 90, 'min_child_samples': 170, 'colsample_bytree': '0.689', 'subsample': '0.440', 'min_split_gain': '0.151', 'scale_pos_weight': '6.434', 'reg_alpha': '53.004', 'reg_lambda': '63.767', 'learning_rate': '0.120'}\n",
      "NRMSE Loss 1.94716 params {'n_estimators': 200, 'max_depth': 100, 'num_leaves': 60, 'min_child_samples': 10, 'colsample_bytree': '0.720', 'subsample': '0.495', 'min_split_gain': '0.063', 'scale_pos_weight': '6.170', 'reg_alpha': '40.294', 'reg_lambda': '70.245', 'learning_rate': '0.020'}\n",
      "NRMSE Loss 1.93867 params {'n_estimators': 500, 'max_depth': 77, 'num_leaves': 40, 'min_child_samples': 80, 'colsample_bytree': '0.905', 'subsample': '0.745', 'min_split_gain': '0.082', 'scale_pos_weight': '7.043', 'reg_alpha': '9.180', 'reg_lambda': '41.772', 'learning_rate': '0.016'}\n",
      "NRMSE Loss 1.94199 params {'n_estimators': 400, 'max_depth': 59, 'num_leaves': 100, 'min_child_samples': 260, 'colsample_bytree': '0.880', 'subsample': '0.805', 'min_split_gain': '0.336', 'scale_pos_weight': '5.205', 'reg_alpha': '0.167', 'reg_lambda': '91.153', 'learning_rate': '0.069'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 1.93898 params {'n_estimators': 800, 'max_depth': 97, 'num_leaves': 50, 'min_child_samples': 90, 'colsample_bytree': '0.853', 'subsample': '0.415', 'min_split_gain': '0.126', 'scale_pos_weight': '6.619', 'reg_alpha': '12.457', 'reg_lambda': '50.166', 'learning_rate': '0.044'}\n",
      "NRMSE Loss 1.95105 params {'n_estimators': 1150, 'max_depth': 74, 'num_leaves': 70, 'min_child_samples': 40, 'colsample_bytree': '0.975', 'subsample': '0.943', 'min_split_gain': '0.187', 'scale_pos_weight': '5.763', 'reg_alpha': '89.318', 'reg_lambda': '38.008', 'learning_rate': '0.032'}\n",
      "NRMSE Loss 1.94605 params {'n_estimators': 650, 'max_depth': 24, 'num_leaves': 30, 'min_child_samples': 280, 'colsample_bytree': '0.665', 'subsample': '0.632', 'min_split_gain': '0.007', 'scale_pos_weight': '5.519', 'reg_alpha': '55.523', 'reg_lambda': '2.869', 'learning_rate': '0.058'}\n",
      "NRMSE Loss 1.94344 params {'n_estimators': 450, 'max_depth': 57, 'num_leaves': 80, 'min_child_samples': 150, 'colsample_bytree': '0.743', 'subsample': '0.582', 'min_split_gain': '0.279', 'scale_pos_weight': '7.828', 'reg_alpha': '14.719', 'reg_lambda': '95.126', 'learning_rate': '0.014'}\n",
      "NRMSE Loss 1.95048 params {'n_estimators': 1100, 'max_depth': 63, 'num_leaves': 60, 'min_child_samples': 50, 'colsample_bytree': '0.834', 'subsample': '0.961', 'min_split_gain': '0.302', 'scale_pos_weight': '9.112', 'reg_alpha': '72.978', 'reg_lambda': '18.083', 'learning_rate': '0.078'}\n",
      "NRMSE Loss 1.93817 params {'n_estimators': 350, 'max_depth': 46, 'num_leaves': 90, 'min_child_samples': 70, 'colsample_bytree': '0.802', 'subsample': '0.671', 'min_split_gain': '0.262', 'scale_pos_weight': '1.387', 'reg_alpha': '4.474', 'reg_lambda': '99.395', 'learning_rate': '0.022'}\n",
      "NRMSE Loss 1.93726 params {'n_estimators': 550, 'max_depth': 37, 'num_leaves': 100, 'min_child_samples': 50, 'colsample_bytree': '0.762', 'subsample': '0.596', 'min_split_gain': '0.234', 'scale_pos_weight': '1.613', 'reg_alpha': '6.940', 'reg_lambda': '86.033', 'learning_rate': '0.035'}\n",
      "NRMSE Loss 1.93649 params {'n_estimators': 600, 'max_depth': 17, 'num_leaves': 100, 'min_child_samples': 40, 'colsample_bytree': '0.781', 'subsample': '0.395', 'min_split_gain': '0.233', 'scale_pos_weight': '3.738', 'reg_alpha': '5.963', 'reg_lambda': '84.526', 'learning_rate': '0.031'}\n",
      "NRMSE Loss 1.93489 params {'n_estimators': 500, 'max_depth': 18, 'num_leaves': 100, 'min_child_samples': 20, 'colsample_bytree': '0.792', 'subsample': '0.453', 'min_split_gain': '0.224', 'scale_pos_weight': '2.663', 'reg_alpha': '2.257', 'reg_lambda': '84.337', 'learning_rate': '0.036'}\n",
      "NRMSE Loss 1.93497 params {'n_estimators': 300, 'max_depth': 16, 'num_leaves': 90, 'min_child_samples': 30, 'colsample_bytree': '0.784', 'subsample': '0.324', 'min_split_gain': '0.205', 'scale_pos_weight': '2.257', 'reg_alpha': '0.617', 'reg_lambda': '77.966', 'learning_rate': '0.031'}\n",
      "NRMSE Loss 1.93473 params {'n_estimators': 300, 'max_depth': 15, 'num_leaves': 100, 'min_child_samples': 20, 'colsample_bytree': '0.822', 'subsample': '0.328', 'min_split_gain': '0.207', 'scale_pos_weight': '2.038', 'reg_alpha': '2.217', 'reg_lambda': '78.799', 'learning_rate': '0.031'}\n",
      "NRMSE Loss 1.94679 params {'n_estimators': 250, 'max_depth': 4, 'num_leaves': 100, 'min_child_samples': 20, 'colsample_bytree': '0.822', 'subsample': '0.304', 'min_split_gain': '0.205', 'scale_pos_weight': '2.348', 'reg_alpha': '1.673', 'reg_lambda': '68.338', 'learning_rate': '0.039'}\n",
      "NRMSE Loss 1.93875 params {'n_estimators': 300, 'max_depth': 9, 'num_leaves': 100, 'min_child_samples': 30, 'colsample_bytree': '0.810', 'subsample': '0.319', 'min_split_gain': '0.175', 'scale_pos_weight': '1.887', 'reg_alpha': '16.074', 'reg_lambda': '78.874', 'learning_rate': '0.051'}\n",
      "NRMSE Loss 1.94510 params {'n_estimators': 100, 'max_depth': 11, 'num_leaves': 100, 'min_child_samples': 10, 'colsample_bytree': '0.863', 'subsample': '0.351', 'min_split_gain': '0.251', 'scale_pos_weight': '2.744', 'reg_alpha': '10.170', 'reg_lambda': '80.828', 'learning_rate': '0.027'}\n",
      "NRMSE Loss 1.93835 params {'n_estimators': 200, 'max_depth': 15, 'num_leaves': 90, 'min_child_samples': 20, 'colsample_bytree': '0.884', 'subsample': '0.330', 'min_split_gain': '0.309', 'scale_pos_weight': '3.138', 'reg_alpha': '8.588', 'reg_lambda': '77.326', 'learning_rate': '0.046'}\n",
      "NRMSE Loss 1.93702 params {'n_estimators': 150, 'max_depth': 19, 'num_leaves': 100, 'min_child_samples': 60, 'colsample_bytree': '0.700', 'subsample': '0.374', 'min_split_gain': '0.192', 'scale_pos_weight': '1.024', 'reg_alpha': '0.204', 'reg_lambda': '71.368', 'learning_rate': '0.033'}\n",
      "NRMSE Loss 1.94181 params {'n_estimators': 250, 'max_depth': 23, 'num_leaves': 90, 'min_child_samples': 30, 'colsample_bytree': '0.794', 'subsample': '0.450', 'min_split_gain': '0.271', 'scale_pos_weight': '2.041', 'reg_alpha': '11.272', 'reg_lambda': '83.395', 'learning_rate': '0.017'}\n",
      "NRMSE Loss 1.94776 params {'n_estimators': 400, 'max_depth': 4, 'num_leaves': 100, 'min_child_samples': 20, 'colsample_bytree': '0.721', 'subsample': '0.352', 'min_split_gain': '0.213', 'scale_pos_weight': '1.214', 'reg_alpha': '2.604', 'reg_lambda': '65.632', 'learning_rate': '0.020'}\n",
      "NRMSE Loss 1.94133 params {'n_estimators': 350, 'max_depth': 30, 'num_leaves': 100, 'min_child_samples': 10, 'colsample_bytree': '0.740', 'subsample': '0.372', 'min_split_gain': '0.379', 'scale_pos_weight': '2.253', 'reg_alpha': '20.606', 'reg_lambda': '74.476', 'learning_rate': '0.042'}\n",
      "NRMSE Loss 1.94926 params {'n_estimators': 100, 'max_depth': 6, 'num_leaves': 90, 'min_child_samples': 40, 'colsample_bytree': '0.844', 'subsample': '0.395', 'min_split_gain': '0.161', 'scale_pos_weight': '1.801', 'reg_alpha': '4.699', 'reg_lambda': '59.490', 'learning_rate': '0.026'}\n",
      "NRMSE Loss 1.94026 params {'n_estimators': 300, 'max_depth': 13, 'num_leaves': 90, 'min_child_samples': 50, 'colsample_bytree': '0.919', 'subsample': '0.465', 'min_split_gain': '0.223', 'scale_pos_weight': '3.512', 'reg_alpha': '16.283', 'reg_lambda': '88.946', 'learning_rate': '0.030'}\n",
      "NRMSE Loss 1.93903 params {'n_estimators': 400, 'max_depth': 26, 'num_leaves': 100, 'min_child_samples': 60, 'colsample_bytree': '0.770', 'subsample': '0.300', 'min_split_gain': '0.414', 'scale_pos_weight': '2.520', 'reg_alpha': '0.184', 'reg_lambda': '92.351', 'learning_rate': '0.062'}\n",
      "NRMSE Loss 1.93887 params {'n_estimators': 150, 'max_depth': 20, 'num_leaves': 100, 'min_child_samples': 20, 'colsample_bytree': '0.869', 'subsample': '0.344', 'min_split_gain': '0.287', 'scale_pos_weight': '3.030', 'reg_alpha': '7.343', 'reg_lambda': '78.411', 'learning_rate': '0.092'}\n",
      "NRMSE Loss 1.94141 params {'n_estimators': 450, 'max_depth': 14, 'num_leaves': 90, 'min_child_samples': 30, 'colsample_bytree': '0.827', 'subsample': '0.424', 'min_split_gain': '0.134', 'scale_pos_weight': '1.458', 'reg_alpha': '33.182', 'reg_lambda': '76.094', 'learning_rate': '0.038'}\n",
      "NRMSE Loss 1.93924 params {'n_estimators': 500, 'max_depth': 11, 'num_leaves': 90, 'min_child_samples': 60, 'colsample_bytree': '0.786', 'subsample': '0.319', 'min_split_gain': '0.197', 'scale_pos_weight': '2.025', 'reg_alpha': '12.780', 'reg_lambda': '69.919', 'learning_rate': '0.053'}\n",
      "NRMSE Loss 1.94546 params {'n_estimators': 200, 'max_depth': 18, 'num_leaves': 100, 'min_child_samples': 80, 'colsample_bytree': '0.898', 'subsample': '0.483', 'min_split_gain': '0.357', 'scale_pos_weight': '2.812', 'reg_alpha': '20.025', 'reg_lambda': '87.161', 'learning_rate': '0.023'}\n",
      "NRMSE Loss 1.93933 params {'n_estimators': 300, 'max_depth': 30, 'num_leaves': 100, 'min_child_samples': 10, 'colsample_bytree': '0.755', 'subsample': '0.517', 'min_split_gain': '0.111', 'scale_pos_weight': '3.333', 'reg_alpha': '23.155', 'reg_lambda': '62.554', 'learning_rate': '0.070'}\n",
      "NRMSE Loss 1.94641 params {'n_estimators': 250, 'max_depth': 35, 'num_leaves': 90, 'min_child_samples': 70, 'colsample_bytree': '0.645', 'subsample': '0.336', 'min_split_gain': '0.443', 'scale_pos_weight': '1.635', 'reg_alpha': '30.642', 'reg_lambda': '81.747', 'learning_rate': '0.036'}\n",
      "NRMSE Loss 1.95332 params {'n_estimators': 400, 'max_depth': 26, 'num_leaves': 90, 'min_child_samples': 30, 'colsample_bytree': '0.677', 'subsample': '0.369', 'min_split_gain': '0.343', 'scale_pos_weight': '1.161', 'reg_alpha': '83.619', 'reg_lambda': '72.617', 'learning_rate': '0.018'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 1.93947 params {'n_estimators': 200, 'max_depth': 21, 'num_leaves': 100, 'min_child_samples': 40, 'colsample_bytree': '0.626', 'subsample': '0.305', 'min_split_gain': '0.143', 'scale_pos_weight': '2.333', 'reg_alpha': '17.808', 'reg_lambda': '67.156', 'learning_rate': '0.048'}\n",
      "NRMSE Loss 1.96222 params {'n_estimators': 100, 'max_depth': 7, 'num_leaves': 90, 'min_child_samples': 10, 'colsample_bytree': '0.354', 'subsample': '0.439', 'min_split_gain': '0.326', 'scale_pos_weight': '4.361', 'reg_alpha': '1.877', 'reg_lambda': '80.320', 'learning_rate': '0.015'}\n",
      "NRMSE Loss 1.94126 params {'n_estimators': 450, 'max_depth': 10, 'num_leaves': 100, 'min_child_samples': 50, 'colsample_bytree': '0.694', 'subsample': '0.394', 'min_split_gain': '0.176', 'scale_pos_weight': '2.641', 'reg_alpha': '9.432', 'reg_lambda': '96.250', 'learning_rate': '0.104'}\n",
      "NRMSE Loss 1.95459 params {'n_estimators': 350, 'max_depth': 6, 'num_leaves': 80, 'min_child_samples': 100, 'colsample_bytree': '0.808', 'subsample': '0.411', 'min_split_gain': '0.241', 'scale_pos_weight': '3.937', 'reg_alpha': '95.623', 'reg_lambda': '84.353', 'learning_rate': '0.056'}\n",
      "NRMSE Loss 1.93732 params {'n_estimators': 500, 'max_depth': 33, 'num_leaves': 100, 'min_child_samples': 70, 'colsample_bytree': '0.944', 'subsample': '0.357', 'min_split_gain': '0.260', 'scale_pos_weight': '1.932', 'reg_alpha': '3.898', 'reg_lambda': '92.733', 'learning_rate': '0.021'}\n",
      "NRMSE Loss 1.94379 params {'n_estimators': 150, 'max_depth': 24, 'num_leaves': 80, 'min_child_samples': 20, 'colsample_bytree': '0.848', 'subsample': '0.422', 'min_split_gain': '0.100', 'scale_pos_weight': '3.387', 'reg_alpha': '26.685', 'reg_lambda': '89.505', 'learning_rate': '0.028'}\n",
      " 88%|██████████████████████████████████████▌     | 175/200 [3:25:06<29:18, 70.32s/trial, best loss: 1.9347259371731504]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m space \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m : hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1500\u001b[39m, \u001b[38;5;241m50\u001b[39m),\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m0.01\u001b[39m), np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m0.5\u001b[39m)),\n\u001b[0;32m     13\u001b[0m }\n\u001b[1;32m---> 15\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_rng\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      2\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \n\u001b[0;32m     15\u001b[0m }\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiOutputRegressor(LGBMRegressor(n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams))\n\u001b[1;32m---> 19\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlg_nrmse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNRMSE Loss \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m params \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss, params))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\multioutput.py:202\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    200\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\multioutput.py:44\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     42\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py:895\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y,\n\u001b[0;32m    889\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    890\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    891\u001b[0m         eval_init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    892\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    893\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 895\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    285\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m    286\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    287\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[0;32m    288\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[0;32m    289\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[0;32m    290\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m--> 292\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m evaluation_result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 3021\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 100, 1500, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 100, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 100, 10),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 10, 300, 10),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'subsample': hp.uniform('subsample', 0.3, 1.0),\n",
    "    'min_split_gain': hp.uniform('min_split_gain', 0, 0.7),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 10),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 100),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 100),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "}\n",
    "\n",
    "best = fmin(fn = objective,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 200,\n",
    "            rstate=np.random.default_rng(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a5d9134",
   "metadata": {},
   "outputs": [
    {
     "ename": "LightGBMError",
     "evalue": "Parameter num_iterations should be of type int, got \"1100.0\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiOutputRegressor(LGBMRegressor(n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_x)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\multioutput.py:202\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    200\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\sklearn\\multioutput.py:44\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     42\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py:895\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y,\n\u001b[0;32m    889\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    890\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    891\u001b[0m         eval_init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    892\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    893\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 895\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    273\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[0;32m   2599\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[0;32m   2600\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   2601\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[0;32m   2602\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2603\u001b[0m     )\n\u001b[0;32m   2604\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 2605\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2606\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   2607\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[1;32m-> 1815\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1816\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1817\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1818\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[0;32m   1821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py:1538\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_csc(data, params_str, ref_dataset)\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m-> 1538\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__init_from_np2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py:1659\u001b[0m, in \u001b[0;36mDataset.__init_from_np2d\u001b[1;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[0;32m   1656\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(mat\u001b[38;5;241m.\u001b[39mreshape(mat\u001b[38;5;241m.\u001b[39msize), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m   1658\u001b[0m ptr_data, type_ptr_data, _ \u001b[38;5;241m=\u001b[39m c_float_array(data)\n\u001b[1;32m-> 1659\u001b[0m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_DatasetCreateFromMat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_ptr_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC_API_IS_ROW_MAJOR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\ai\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    The return value from C API calls.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mLightGBMError\u001b[0m: Parameter num_iterations should be of type int, got \"1100.0\""
     ]
    }
   ],
   "source": [
    "model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **best))\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a1a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "for idx, col in enumerate(submit.columns):\n",
    "    if col=='ID':\n",
    "        continue\n",
    "    submit[col] = preds[:,idx-1]\n",
    "submit.to_csv('./submission_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff53b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
